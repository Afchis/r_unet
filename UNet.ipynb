{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images_val', 'labels_val', 'test', 'labels', 'images']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import scipy.ndimage.morphology as morph\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "os.listdir('../r_unet/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cell_model = {\n",
    "    'Rnn' : ConvRnnCell(in_channels, out_channels), \n",
    "    'Gru' : ConvGruCell(in_channels, out_channels), \n",
    "    'Rrn' : ConvRrnCell(in_channels, out_channels), \n",
    "    'Sru' : ConvSruCell(in_channels, out_channels), \n",
    "    'Dru' : ConvDruCell(in_channels, out_channels)\n",
    "}\n",
    "\"\"\"\n",
    "RECURRENT = False\n",
    "PARAMETERS = {\n",
    "    'd1':False, \n",
    "    'd2':False, \n",
    "    'd3':False, \n",
    "    'b_':False, \n",
    "    'u1':False, \n",
    "    'u2':False, \n",
    "    'u3':False, \n",
    "    'cell_model':'Rnn'\n",
    "}\n",
    "\n",
    "DEVICE = \"cuda:1\"\n",
    "# arguments\n",
    "TIMESTEPS = 3\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 200\n",
    "INPUT_SIZE = 128\n",
    "INPUT_CHANNELS = 1\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                              transforms.Resize((INPUT_SIZE, INPUT_SIZE), interpolation = 0),\n",
    "                              transforms.ToTensor()\n",
    "                              ])\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# decive\n",
    "device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way to the data folders\n",
    "FOLDER_DATA = \"../r_unet/data/images\"\n",
    "FOLDER_MASK = \"../r_unet/data/labels\"\n",
    "FOLDER_TEST = \"../r_unet/data/test\"\n",
    "FOLDER_DATA_VAL = \"../r_unet/data/images_val\"\n",
    "FOLDER_MASK_VAL = \"../r_unet/data/labels_val\"\n",
    "\n",
    "FILE_NAMES = sorted(os.listdir('../r_unet/data/images'))\n",
    "FILE_NAMES_VAL = sorted(os.listdir('../r_unet/data/images_val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(object):\n",
    "    label1 = (object==0).float()\n",
    "    label2 = (label1==0).float()\n",
    "    labels = torch.stack([label1, label2], dim=1).squeeze()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_data = FOLDER_DATA\n",
    "        self.folder_mask = FOLDER_MASK\n",
    "        self.file_names = FILE_NAMES\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + self.file_names[idx+i])))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(get_labels(transform(Image.open(self.folder_mask + '/' + self.file_names[idx+i]))))\n",
    "        gif_mask = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            img = Image.open(self.folder_mask + '/' + self.file_names[idx+i])\n",
    "            img = img.resize((INPUT_SIZE, INPUT_SIZE), resample=Image.NEAREST)\n",
    "            gif_list.append(to_tensor(morph.distance_transform_edt(np.asarray(img)/255)))\n",
    "        gif_depth = torch.stack(gif_list)\n",
    "        return gif_data, gif_mask, gif_depth\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "\n",
    "\n",
    "class ValMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_data = FOLDER_DATA_VAL\n",
    "        self.folder_mask = FOLDER_MASK_VAL\n",
    "        self.file_names = FILE_NAMES_VAL\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + self.file_names[idx+i])))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(get_labels(transform(Image.open(self.folder_mask + '/' + self.file_names[idx+i]))))\n",
    "        gif_mask = torch.stack(gif_list).squeeze(dim=2)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            img = Image.open(self.folder_mask + '/' + self.file_names[idx+i])\n",
    "            img = img.resize((INPUT_SIZE, INPUT_SIZE), resample=Image.NEAREST)\n",
    "            gif_list.append(to_tensor(morph.distance_transform_edt(np.asarray(img)/255)))\n",
    "        gif_depth = torch.stack(gif_list)\n",
    "        return gif_data, gif_mask, gif_depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "\n",
    "\n",
    "class TestMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_test = FOLDER_TEST\n",
    "        self.file_names = FILE_NAMES + FILE_NAMES_VAL\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_test + '/' + self.file_names[idx+i])))\n",
    "        gif_test = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        return gif_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TrainMedData(Dataset):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.time = TIMESTEPS\n",
    "#         self.folder_data = FOLDER_DATA\n",
    "#         self.folder_mask = FOLDER_MASK\n",
    "#         self.file_names = FILE_NAMES\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         gif_list = []\n",
    "#         for i in range(self.time):\n",
    "#             gif_list.append(transform(Image.open(self.folder_data + '/' + self.file_names[idx+i])))\n",
    "#         gif_data = torch.stack(gif_list)\n",
    "#         gif_list.clear()\n",
    "#         for i in range(self.time):\n",
    "#             gif_list.append(get_labels(transform(Image.open(self.folder_mask + '/' + self.file_names[idx+i]))))\n",
    "#             depth_list = morph.distance_transform_edt(gif_list)\n",
    "#         gif_mask = torch.stack(gif_list)\n",
    "#         gif_depth = torch.stack(depth_list)\n",
    "#         gif_list.clear()\n",
    "#         depth_list.clear()\n",
    "\n",
    "#         return gif_data, gif_mask, gif_depth\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.file_names) - self.time + 1\n",
    "\n",
    "\n",
    "# class ValMedData(Dataset):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.time = TIMESTEPS\n",
    "#         self.folder_data = FOLDER_DATA_VAL\n",
    "#         self.folder_mask = FOLDER_MASK_VAL\n",
    "#         self.file_names = FILE_NAMES_VAL\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         gif_list = []\n",
    "#         for i in range(self.time):\n",
    "#             gif_list.append(transform(Image.open(self.folder_data + '/' + self.file_names[idx+i])))\n",
    "#         gif_data = torch.stack(gif_list)\n",
    "#         gif_list.clear()\n",
    "#         for i in range(self.time):\n",
    "#             gif_list.append(get_labels(transform(Image.open(self.folder_mask + '/' + self.file_names[idx+i]))))\n",
    "#         gif_mask = torch.stack(gif_list).squeeze(dim=2)\n",
    "#         gif_list.clear()\n",
    "#         for i in range(self.time):\n",
    "#             img = Image.open(self.folder_mask + '/' + self.file_names[idx+i])\n",
    "#             img = img.resize((INPUT_SIZE, INPUT_SIZE), resample=Image.NEAREST)\n",
    "#             gif_list.append(to_tensor(morph.distance_transform_edt(np.asarray(img)/255)))\n",
    "#         gif_depth = torch.stack(gif_list)\n",
    "#         return gif_data, gif_mask, gif_depth\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.file_names) - self.time + 1\n",
    "\n",
    "\n",
    "# class TestMedData(Dataset):\n",
    "#     def __init__(self):\n",
    "#         super().__init__\n",
    "#         self.time = TIMESTEPS\n",
    "#         self.folder_test = FOLDER_TEST\n",
    "#         self.file_names = FILE_NAMES + FILE_NAMES_VAL\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         gif_list = []\n",
    "#         for i in range(self.time):\n",
    "#             gif_list.append(transform(Image.open(self.folder_test + '/' + self.file_names[idx+i])))\n",
    "#         gif_test = torch.stack(gif_list)\n",
    "#         gif_list.clear()\n",
    "#         return gif_test\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.file_names) - self.time + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainMedData()\n",
    "valid_dataset = ValMedData()\n",
    "test_dataset = TestMedData()\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=1,\n",
    "                          shuffle=False)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=1,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=1,\n",
    "                         num_workers=1,\n",
    "                         shuffle=False)\n",
    "\n",
    "data_loaders = {\n",
    "    'train' : train_loader,\n",
    "    'valid' : valid_loader,\n",
    "    'test' : test_loader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'valid': len(valid_dataset),\n",
    "    'test': len(test_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, d = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_pil((depth!=0).float())\n",
    "# depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, d = train_dataset[0]\n",
    "# depth = d[0]\n",
    "# for dim_0 in depth:\n",
    "#     for dim_1 in dim_0:\n",
    "#         Dim_2 = torch.tensor([])\n",
    "#         for dim_2 in dim_1:\n",
    "#             if dim_2 == 0:\n",
    "#                 dim_2 = torch.ones_like(dim_2)\n",
    "#             torch.cat(dim_2)\n",
    "# print(Dim_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRnnCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRnnCell, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "             \n",
    "    def forward(self, x, hidden):\n",
    "        out = torch.cat([x, hidden],dim=1)\n",
    "        out = self.conv1(out)\n",
    "        hidden = out\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGruCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvGruCell, self).__init__()\n",
    "        self.conv_for_input = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_for_hidden = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_2x_update = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        self.conv_2x_reset = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_2x_update(input)\n",
    "        update_gate = self.sig((update_gate)) ### output after update gate\n",
    "        reset_gate = self.conv_2x_reset(input)\n",
    "        reset_gate = self.sig((reset_gate)) ### output after reset gate\n",
    "        \n",
    "        \n",
    "        memory_for_input = self.conv_for_input(x)\n",
    "        memory_for_hidden = self.conv_for_hidden(hidden)# просто хидден\n",
    "\n",
    "        memory_content = memory_for_input + (reset_gate * memory_for_hidden) ### output for reset gate(affects how the reset gate do work)\n",
    "        memory_content = self.relu(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRrnCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRrnCell, self).__init__()\n",
    "        self.conv_for_input = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_for_hidden = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_2x_update = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        self.conv_2x_reset = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_2x_update(input)\n",
    "        update_gate = self.sig((update_gate)) \n",
    "        \n",
    "        memory_for_input = self.conv_for_input(x)\n",
    "        memory_for_hidden = hidden\n",
    "\n",
    "        memory_content = memory_for_input + memory_for_hidden\n",
    "        memory_content = self.relu(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSruCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvSruCell, self).__init__()\n",
    "        self.update_gate = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.backbone = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        z = self.update_gate(x)\n",
    "        z = self.sig(z)\n",
    "        \n",
    "        h_ = self.backbone(x)\n",
    "        h_ = self.tanh(h_)\n",
    "        \n",
    "        h_prev = hidden * z\n",
    "        h = (1 - z) * h_\n",
    "        out = h + h_prev\n",
    "        return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDruCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvDruCell, self).__init__()\n",
    "        self.update_gate = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.reset_gate = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.backbone = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        z = self.update_gate(x)\n",
    "        z = self.sig(z)\n",
    "        \n",
    "        r = self.reset_gate(x)\n",
    "        r = self.sig(r)\n",
    "        rx = r * x\n",
    "        h_ = self.backbone(rx)\n",
    "        h_ = self.tanh(h_)\n",
    "        \n",
    "        h_prev = hidden * z\n",
    "        h = (1 - z) * h_\n",
    "        out = h + h_prev\n",
    "        return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRnn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, ConvRnn_input_size, cell_model, reccurent=RECURRENT): # arg for ConvRnn layer\n",
    "        super(ConvRnn, self).__init__()\n",
    "        self.cell_dict = {\n",
    "            'Rnn' : ConvRnnCell(in_channels, out_channels), \n",
    "            'Gru' : ConvGruCell(in_channels, out_channels), \n",
    "            'Rrn' : ConvRrnCell(in_channels, out_channels), \n",
    "            'Sru' : ConvSruCell(in_channels, out_channels), \n",
    "            'Dru' : ConvDruCell(in_channels, out_channels)\n",
    "        }\n",
    "        self.rec = reccurent\n",
    "        self.cell_model = cell_model\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.timesteps = TIMESTEPS\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_size = ConvRnn_input_size\n",
    "        self.hidden_size = (self.batch_size, self.out_channels, self.input_size, self.input_size)\n",
    "        \n",
    "        self.ConvRnn_layer = self.cell_dict[self.cell_model]\n",
    "        self.init_hidden = torch.zeros(self.hidden_size).to(device)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_cells = None\n",
    "        x_list = []\n",
    "\n",
    "        x = x.reshape(self.batch_size, self.timesteps, self.in_channels, self.input_size, self.input_size)\n",
    "        x = x.permute(1, 0, 2, 3, 4)\n",
    "        if self.rec == True:\n",
    "            for i in range(self.timesteps):\n",
    "                if x_cells is None:\n",
    "                    x_cells, hidden = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_cells)\n",
    "                else:\n",
    "                    x_i, hidden = self.ConvRnn_layer(x[i], hidden)\n",
    "                    x_list.append(x_i)\n",
    "        elif self.rec == False:\n",
    "            for i in range(self.timesteps):\n",
    "                if x_cells is None:\n",
    "                    x_cells, _ = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_cells)\n",
    "                else:\n",
    "                    x_i, _ = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_i)\n",
    "        else:\n",
    "            print('RECURRENT can be only True or False')\n",
    "            quit()\n",
    "        x_cells = torch.stack(x_list)\n",
    "        x_cells = x_cells.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        x_cells = x_cells.reshape(-1, self.out_channels, self.input_size, self.input_size)\n",
    "        return x_cells  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRnnRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels ,ConvRnn_input_size, cell_model):\n",
    "        super(ConvRnnRelu, self).__init__()\n",
    "        self.cell_model = cell_model\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_size = ConvRnn_input_size\n",
    "        self.convrnnrelu = nn.Sequential(ConvRnn(self.in_channels, self.out_channels, \n",
    "                                                 self.input_size, self.cell_model),\n",
    "                                         nn.ReLU()\n",
    "                                         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convrnnrelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRelu, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.convrelu = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "                                      nn.ReLU()\n",
    "                                      )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convrelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaxPool, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.maxpool(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpAndCat(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(UpAndCat, self).__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x_up, x_cat):\n",
    "        out = self.up(x_up)\n",
    "        out = torch.cat([out, x_cat], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDesigner(nn.Module):    \n",
    "    def __init__(self, d1, d2, d3, b_, u1, u2, u3, cell_model,\n",
    "                 input_size=INPUT_SIZE, input_channels=INPUT_CHANNELS, num_classes=NUM_CLASSES):\n",
    "        super(UNetDesigner, self).__init__()\n",
    "        self.cell_model = cell_model\n",
    "        self.num_classes = NUM_CLASSES\n",
    "        self.d1, self.d2, self.d3, self.b, self.u1, self.u2, self.u3 = d1, d2, d3, b_, u1, u2, u3\n",
    "        self.input_size = input_size\n",
    "        self.input_chennels = input_channels\n",
    "        self.ch_list = [self.input_chennels, 32, 64, 128, 256]\n",
    "        self.input_x2 = int(self.input_size / 2)\n",
    "        self.input_x4 = int(self.input_size / 4)\n",
    "        self.input_x8 = int(self.input_size / 8)\n",
    "\n",
    "         ##### Down_1 layer ##### input_size = 128\n",
    "        if self.d1 == True:\n",
    "            self.down1 = nn.Sequential(ConvRnnRelu(self.ch_list[0], self.ch_list[1],    # Channels\n",
    "                                                   self.input_size, self.cell_model),               \n",
    "                                       ConvRelu(self.ch_list[1], self.ch_list[1])                   \n",
    "                                       )                                                # 1  -->32\n",
    "        else:                                                                           # 32 -->32\n",
    "            self.down1 = nn.Sequential(ConvRelu(self.ch_list[0], self.ch_list[1]),\n",
    "                                       ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                       )\n",
    "        self.down1_pool = MaxPool()\n",
    "\n",
    "         ##### Down_2 layer ##### input_size = 64\n",
    "        if self.d2 == True:\n",
    "            self.down2 = nn.Sequential(ConvRnnRelu(self.ch_list[1], self.ch_list[2],\n",
    "                                                   self.input_x2, self.cell_model),\n",
    "                                       ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                       )                                                # 32 -->64\n",
    "        else:                                                                           # 64 -->64\n",
    "            self.down2 = nn.Sequential(ConvRelu(self.ch_list[1], self.ch_list[2]),\n",
    "                                       ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                       )\n",
    "        self.down2_pool = MaxPool()\n",
    "\n",
    "         ##### Down_3 layer ##### input_size = 32\n",
    "        if self.d3 == True:\n",
    "            self.down3 = nn.Sequential(ConvRnnRelu(self.ch_list[2], self.ch_list[3], \n",
    "                                                   self.input_x4, self.cell_model),\n",
    "                                       ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                       )                                                # 64 -->128\n",
    "        else:                                                                           # 128-->128\n",
    "            self.down3 = nn.Sequential(ConvRelu(self.ch_list[2], self.ch_list[3]),\n",
    "                                       ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                       )\n",
    "        self.down3_pool = MaxPool()\n",
    "\n",
    "         ##### Bottom layer ##### input_size = 16\n",
    "        if self.b == True:\n",
    "            self.bottom = nn.Sequential(ConvRnnRelu(self.ch_list[3], self.ch_list[4], \n",
    "                                                    self.input_x8, self.cell_model),\n",
    "                                        ConvRelu(self.ch_list[4], self.ch_list[4])\n",
    "                                        )                                               # 128-->256\n",
    "        else:                                                                           # 256-->256\n",
    "            self.bottom = nn.Sequential(ConvRelu(self.ch_list[3], self.ch_list[4]),\n",
    "                                        ConvRelu(self.ch_list[4], self.ch_list[4])\n",
    "                                        )\n",
    "\n",
    "         ##### Up_3 layer #####\n",
    "        self.up_cat_3 = UpAndCat()\n",
    "        if self.u3 == True:\n",
    "            self.up_conv_3 = nn.Sequential(ConvRnnRelu(self.ch_list[4]+self.ch_list[3], \n",
    "                                                       self.ch_list[3], \n",
    "                                                       self.input_x4, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                           )                                            # 394-->128\n",
    "        else:                                                                           # 128-->128\n",
    "            self.up_conv_3 = nn.Sequential(ConvRelu(self.ch_list[4]+self.ch_list[3], \n",
    "                                                    self.ch_list[3]),\n",
    "                                           ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                           )\n",
    "\n",
    "         ##### Up_2 layer #####\n",
    "        self.up_cat_2 = UpAndCat()\n",
    "        if self.u2 == True:\n",
    "            self.up_conv_2 = nn.Sequential(ConvRnnRelu(self.ch_list[3]+self.ch_list[2], \n",
    "                                                       self.ch_list[2], \n",
    "                                                       self.input_x2, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                           )                                            # 192-->64\n",
    "        else:                                                                           # 64 -->64\n",
    "            self.up_conv_2 = nn.Sequential(ConvRelu(self.ch_list[3]+self.ch_list[2], \n",
    "                                                    self.ch_list[2]),\n",
    "                                           ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                           )\n",
    "\n",
    "         ##### Up_1 layer #####\n",
    "        self.up_cat_1 = UpAndCat()\n",
    "        if self.u1 == True:\n",
    "            self.up_conv_1 = nn.Sequential(ConvRnnRelu(self.ch_list[2]+self.ch_list[1], \n",
    "                                                       self.ch_list[1], \n",
    "                                                       self.input_size, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                           )                                            # 96 -->32\n",
    "        else:                                                                           # 32 -->32\n",
    "            self.up_conv_1 = nn.Sequential(ConvRelu(self.ch_list[2]+self.ch_list[1], \n",
    "                                                    self.ch_list[1]),\n",
    "                                           ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                           )\n",
    "\n",
    "         ##### Final layer #####\n",
    "        self.final = nn.Sequential(nn.Conv2d(self.ch_list[1], self.num_classes, kernel_size=1),\n",
    "\n",
    "                                   )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, self.input_chennels, self.input_size, self.input_size)\n",
    "        # print(x.shape)\n",
    "        down1_feat = self.down1(x)\n",
    "        pool1 = self.down1_pool(down1_feat)\n",
    "        # print(pool1.shape)\n",
    "        down2_feat = self.down2(pool1)\n",
    "        pool2 = self.down2_pool(down2_feat)\n",
    "        # print(pool2.shape)\n",
    "        down3_feat = self.down3(pool2)\n",
    "        pool3 = self.down3_pool(down3_feat)\n",
    "        # print(pool3.shape)\n",
    "        bottom_feat = self.bottom(pool3)\n",
    "        # print(bottom_feat.shape)\n",
    "        up_feat3 = self.up_cat_3(bottom_feat, down3_feat)\n",
    "        up_feat3 = self.up_conv_3(up_feat3)\n",
    "        \n",
    "        up_feat2 = self.up_cat_2(up_feat3, down2_feat)\n",
    "        up_feat2 = self.up_conv_2(up_feat2)\n",
    "        \n",
    "        up_feat1 = self.up_cat_1(up_feat2, down1_feat)\n",
    "        up_feat1 = self.up_conv_1(up_feat1)\n",
    "        \n",
    "        out = self.final(up_feat1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetDesigner(d1=PARAMETERS['d1'], \n",
    "                     d2=PARAMETERS['d2'], \n",
    "                     d3=PARAMETERS['d3'], \n",
    "                     b_=PARAMETERS['b_'], \n",
    "                     u1=PARAMETERS['u1'], \n",
    "                     u2=PARAMETERS['u2'], \n",
    "                     u3=PARAMETERS['u3'], \n",
    "                     cell_model=PARAMETERS['cell_model']\n",
    "                     )\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss(x, y):\n",
    "    y = y.reshape(x.shape)\n",
    "    x = F.sigmoid(x)\n",
    "    out = ((x - y)**2).sum()\n",
    "    return out\n",
    "\n",
    "def bce_loss(x, y):\n",
    "    y = y.reshape(x.shape)\n",
    "    return F.binary_cross_entropy_with_logits(x, y)\n",
    "\n",
    "def dice_loss(x, y):\n",
    "    y = y.reshape(x.shape)\n",
    "    x = F.sigmoid(x)\n",
    "    intersection = (x * y).sum(dim=2).sum(dim=2)\n",
    "    x_sum = x.sum(dim=2).sum(dim=2)\n",
    "    y_sum = y.sum(dim=2).sum(dim=2)\n",
    "    dice_loss = 1 - (2*intersection / (x_sum + y_sum))\n",
    "    return dice_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combo_loss(x, y, bce_weight=0.7):\n",
    "    combo_loss = bce_weight * bce_loss(x, y) + (1 - bce_weight) * dice_loss(x, y)\n",
    "    return combo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU_metric(x, y):\n",
    "    y = y.reshape(x.shape)\n",
    "    x = F.sigmoid(x)\n",
    "    intersection = (x * y).sum(dim=2).sum(dim=2)\n",
    "    x_sum = x.sum(dim=2).sum(dim=2)\n",
    "    y_sum = y.sum(dim=2).sum(dim=2)\n",
    "    IoU_metric = intersection / (x_sum + y_sum - intersection)\n",
    "    return IoU_metric.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** epoch:  0 **********\n",
      "train l2_norm:  0.9675632552667097\n",
      "val l2_norm:  0.7232312262058258\n",
      "Maximum Valid metric:  0.7232312262058258\n"
     ]
    }
   ],
   "source": [
    "val_loss = []\n",
    "for epoch in range(1):\n",
    "    print('*'*10, 'epoch: ', epoch, '*'*10)\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            loss_list = []\n",
    "            model.train()\n",
    "            for i, data in enumerate(data_loaders[phase]):\n",
    "                input, label, depth = data\n",
    "                input = input.to(device)\n",
    "                label = label.to(device)\n",
    "                depth = depth.to(device)\n",
    "                output = model(input)\n",
    "                loss = combo_loss(output, label)\n",
    "                metric = IoU_metric(output, label)\n",
    "                loss_list.append(metric.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            mean_loss = sum(loss_list) / len(loss_list)\n",
    "            print(\"train l2_norm: \", mean_loss)\n",
    "        elif phase == 'valid':\n",
    "            loss_list = []\n",
    "            model.eval()\n",
    "            for i, data in enumerate(data_loaders[phase]):\n",
    "                input, label, depth = data\n",
    "                input = input.to(device)\n",
    "                label = label.to(device)\n",
    "                depth = depth.to(device)\n",
    "                output = model(input)\n",
    "                loss = combo_loss(output, label)\n",
    "                metric = IoU_metric(output, label)\n",
    "                loss_list.append(metric.item())\n",
    "            mean_loss = sum(loss_list) / len(loss_list)\n",
    "            print(\"val l2_norm: \", mean_loss)\n",
    "            val_loss.append(mean_loss)\n",
    "print('Maximum Valid metric: ', max(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.5744e-03, 4.1069e-08, 1.3035e-04, 9.9377e-01, 3.3664e-08, 4.9485e-08,\n",
       "        1.6379e-05, 3.2565e-07, 1.0370e-07, 1.4981e-05, 1.5260e-04, 4.1498e-06,\n",
       "        3.1515e-04, 9.4129e-01, 9.9999e-01, 3.1900e-01, 4.4292e-02, 1.3533e-05,\n",
       "        5.8315e-10, 2.0249e-12, 2.6012e-12, 8.2777e-11, 1.3718e-07, 3.6563e-05,\n",
       "        4.9031e-04, 1.4759e-01, 1.6839e-01, 6.9871e-05, 4.2509e-05, 9.6579e-01,\n",
       "        8.6396e-01, 2.3698e-03, 2.8024e-04, 7.9260e-06, 9.5869e-01, 9.1327e-01,\n",
       "        4.3281e-02, 1.4000e-03, 4.1146e-07, 1.3488e-09, 1.2995e-09, 5.3114e-07,\n",
       "        1.4341e-06, 5.0619e-05, 4.0442e-03, 3.4320e-01, 7.7201e-03, 7.4873e-06,\n",
       "        1.2051e-02, 5.7172e-02, 5.7791e-07, 8.1633e-11, 1.6689e-09, 5.6140e-03,\n",
       "        9.9668e-01, 1.6989e-03, 6.0726e-06, 4.8631e-03, 1.5766e-01, 3.1090e-07,\n",
       "        3.6138e-10, 3.6080e-09, 6.7405e-09, 6.2810e-06, 3.6996e-02, 9.2955e-01,\n",
       "        8.4658e-01, 2.6887e-03, 9.0019e-08, 3.6343e-11, 1.9191e-12, 3.5130e-13,\n",
       "        1.8338e-12, 3.2777e-10, 1.0481e-06, 7.5859e-11, 1.1646e-11, 9.5186e-06,\n",
       "        7.4187e-05, 3.7354e-05, 1.4949e-08, 7.4058e-08, 1.0738e-07, 5.1983e-06,\n",
       "        5.1474e-04, 8.2133e-01, 9.9999e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "        9.9954e-01, 9.9833e-01, 9.9526e-01, 9.9959e-01, 9.9997e-01, 7.4530e-01,\n",
       "        6.6996e-02, 9.4714e-02, 6.0301e-01, 9.0740e-01, 5.2948e-05, 3.8891e-05,\n",
       "        3.4121e-05, 9.9999e-01, 4.2136e-01, 2.1009e-02, 2.4978e-04, 1.6363e-03,\n",
       "        5.4749e-01, 1.1818e-04, 3.5004e-06, 3.7724e-01, 2.1745e-05, 2.4521e-10,\n",
       "        2.4744e-10, 7.6864e-05, 3.8350e-01, 7.9258e-01, 2.2949e-01, 4.3721e-02,\n",
       "        3.4188e-01, 1.4976e-03, 1.6977e-06, 2.3770e-04, 8.9392e-02, 6.3341e-01,\n",
       "        2.5084e-04, 1.1624e-06], device='cuda:1', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(output[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF762237D0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil((output[0][0].cpu()>0).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF75190950>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil(F.sigmoid(output[0][1].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_inp = []\n",
    "list_out = []\n",
    "for i, data in enumerate(test_loader):\n",
    "    input = data\n",
    "    input = input.to(device)\n",
    "    test_output = model(input)\n",
    "    list_inp.append(input)\n",
    "    list_out.append(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 128, 128])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_inp[0].shape\n",
    "list_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showw(object, i):\n",
    "    imgs = object[i].cpu()\n",
    "    img = F.sigmoid(imgs[2][1])\n",
    "    return to_pil(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF75101250>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showw(list_out, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageSequence\n",
    "index = 3 \n",
    "for i in range(len(list_out)):\n",
    "    test_out = showw(list_out, i)\n",
    "    test_out.save(\"../r_unet/data/test_output/frame%d.png\" % index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
