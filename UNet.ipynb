{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_output', 'images_val', 'labels_val', 'test', 'labels', 'images']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import scipy.ndimage.morphology as morph\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "os.listdir('../r_unet/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Parameters\n",
    "'''\n",
    "\"\"\"\n",
    "cell_model = {\n",
    "    'Rnn' : ConvRnnCell(in_channels, out_channels), \n",
    "    'Gru' : ConvGruCell(in_channels, out_channels), \n",
    "    'Rrn' : ConvRrnCell(in_channels, out_channels), \n",
    "    'Sru' : ConvSruCell(in_channels, out_channels), \n",
    "    'Dru' : ConvDruCell(in_channels, out_channels)\n",
    "}\n",
    "\"\"\"\n",
    "RECURRENT = False\n",
    "PARAMETERS = {\n",
    "    'd1':False, \n",
    "    'd2':False, \n",
    "    'd3':False, \n",
    "    'b_':False, \n",
    "    'u1':False, \n",
    "    'u2':False, \n",
    "    'u3':False, \n",
    "    'cell_model':'Rnn'\n",
    "}\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "# arguments\n",
    "TIMESTEPS = 3\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 200\n",
    "INPUT_SIZE = 128\n",
    "INPUT_CHANNELS = 1\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                              transforms.Resize((INPUT_SIZE, INPUT_SIZE), interpolation = 0),\n",
    "                              transforms.ToTensor()\n",
    "                              ])\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# decive\n",
    "device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way to the data folders\n",
    "FOLDER_DATA = \"../r_unet/data/images\"\n",
    "FOLDER_MASK = \"../r_unet/data/labels\"\n",
    "FOLDER_TEST = \"../r_unet/data/test\"\n",
    "FOLDER_DATA_VAL = \"../r_unet/data/images_val\"\n",
    "FOLDER_MASK_VAL = \"../r_unet/data/labels_val\"\n",
    "\n",
    "FILE_NAMES = sorted(os.listdir('../r_unet/data/images'))\n",
    "FILE_NAMES_VAL = sorted(os.listdir('../r_unet/data/images_val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataloader\n",
    "'''\n",
    "def get_labels(object):\n",
    "    label1 = (object==0).float()\n",
    "    depth1 = to_tensor(morph.distance_transform_edt(np.asarray(label1[0])))\n",
    "    label2 = (label1==0).float()\n",
    "    depth2 = to_tensor(morph.distance_transform_edt(np.asarray(label2[0])))\n",
    "    labels = torch.stack([label1, label2], dim=1).squeeze()\n",
    "    depths = torch.stack([depth1, depth2], dim=1).squeeze()\n",
    "    return labels, depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_data = FOLDER_DATA\n",
    "        self.folder_mask = FOLDER_MASK\n",
    "        self.file_names = FILE_NAMES\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        gif_list_depth = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + self.file_names[idx+i])))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            label, depth = get_labels(transform(Image.open(self.folder_mask + '/' + self.file_names[idx+i])))\n",
    "            gif_list.append(label)\n",
    "            gif_list_depth.append(depth)\n",
    "        gif_mask = torch.stack(gif_list)\n",
    "        gif_depth = torch.stack(gif_list_depth)\n",
    "        gif_list.clear()\n",
    "        gif_list_depth.clear()\n",
    "        return gif_data, gif_mask, gif_depth\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "\n",
    "\n",
    "class ValMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_data = FOLDER_DATA_VAL\n",
    "        self.folder_mask = FOLDER_MASK_VAL\n",
    "        self.file_names = FILE_NAMES_VAL\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        gif_list_depth = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + self.file_names[idx+i])))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            label, depth = get_labels(transform(Image.open(self.folder_mask + '/' + self.file_names[idx+i])))\n",
    "            gif_list.append(label)\n",
    "            gif_list_depth.append(depth)\n",
    "        gif_mask = torch.stack(gif_list)\n",
    "        gif_depth = torch.stack(gif_list_depth)\n",
    "        gif_list.clear()\n",
    "        gif_list_depth.clear()\n",
    "        return gif_data, gif_mask, gif_depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "\n",
    "\n",
    "class TestMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_test = FOLDER_TEST\n",
    "        self.file_names = FILE_NAMES + FILE_NAMES_VAL\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_test + '/' + self.file_names[idx+i])))\n",
    "        gif_test = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        return gif_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainMedData()\n",
    "valid_dataset = ValMedData()\n",
    "test_dataset = TestMedData()\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=1,\n",
    "                          shuffle=False)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=1,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=1,\n",
    "                         num_workers=1,\n",
    "                         shuffle=False)\n",
    "\n",
    "data_loaders = {\n",
    "    'train' : train_loader,\n",
    "    'valid' : valid_loader,\n",
    "    'test' : test_loader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'valid': len(valid_dataset),\n",
    "    'test': len(test_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Recurrent cell\n",
    "'''\n",
    "class ConvRnnCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRnnCell, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "             \n",
    "    def forward(self, x, hidden):\n",
    "        out = torch.cat([x, hidden],dim=1)\n",
    "        out = self.conv1(out)\n",
    "        hidden = out\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGruCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvGruCell, self).__init__()\n",
    "        self.conv_for_input = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_for_hidden = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_2x_update = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        self.conv_2x_reset = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_2x_update(input)\n",
    "        update_gate = self.sig((update_gate)) ### output after update gate\n",
    "        reset_gate = self.conv_2x_reset(input)\n",
    "        reset_gate = self.sig((reset_gate)) ### output after reset gate\n",
    "        \n",
    "        \n",
    "        memory_for_input = self.conv_for_input(x)\n",
    "        memory_for_hidden = self.conv_for_hidden(hidden)# просто хидден\n",
    "\n",
    "        memory_content = memory_for_input + (reset_gate * memory_for_hidden) ### output for reset gate(affects how the reset gate do work)\n",
    "        memory_content = self.relu(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRrnCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRrnCell, self).__init__()\n",
    "        self.conv_for_input = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_for_hidden = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_2x_update = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        self.conv_2x_reset = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_2x_update(input)\n",
    "        update_gate = self.sig((update_gate)) \n",
    "        \n",
    "        memory_for_input = self.conv_for_input(x)\n",
    "        memory_for_hidden = hidden\n",
    "\n",
    "        memory_content = memory_for_input + memory_for_hidden\n",
    "        memory_content = self.relu(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSruCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvSruCell, self).__init__()\n",
    "        self.update_gate = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.backbone = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        z = self.update_gate(x)\n",
    "        z = self.sig(z)\n",
    "        \n",
    "        h_ = self.backbone(x)\n",
    "        h_ = self.tanh(h_)\n",
    "        \n",
    "        h_prev = hidden * z\n",
    "        h = (1 - z) * h_\n",
    "        out = h + h_prev\n",
    "        return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDruCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvDruCell, self).__init__()\n",
    "        self.update_gate = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.reset_gate = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.backbone = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        z = self.update_gate(x)\n",
    "        z = self.sig(z)\n",
    "        \n",
    "        r = self.reset_gate(x)\n",
    "        r = self.sig(r)\n",
    "        rx = r * x\n",
    "        h_ = self.backbone(rx)\n",
    "        h_ = self.tanh(h_)\n",
    "        \n",
    "        h_prev = hidden * z\n",
    "        h = (1 - z) * h_\n",
    "        out = h + h_prev\n",
    "        return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model paths\n",
    "'''\n",
    "class ConvRnn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, ConvRnn_input_size, cell_model, reccurent=RECURRENT): # arg for ConvRnn layer\n",
    "        super(ConvRnn, self).__init__()\n",
    "        self.cell_dict = {\n",
    "            'Rnn' : ConvRnnCell(in_channels, out_channels), \n",
    "            'Gru' : ConvGruCell(in_channels, out_channels), \n",
    "            'Rrn' : ConvRrnCell(in_channels, out_channels), \n",
    "            'Sru' : ConvSruCell(in_channels, out_channels), \n",
    "            'Dru' : ConvDruCell(in_channels, out_channels)\n",
    "        }\n",
    "        self.rec = reccurent\n",
    "        self.cell_model = cell_model\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.timesteps = TIMESTEPS\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_size = ConvRnn_input_size\n",
    "        self.hidden_size = (self.batch_size, self.out_channels, self.input_size, self.input_size)\n",
    "        \n",
    "        self.ConvRnn_layer = self.cell_dict[self.cell_model]\n",
    "        self.init_hidden = torch.zeros(self.hidden_size).to(device)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_cells = None\n",
    "        x_list = []\n",
    "\n",
    "        x = x.reshape(self.batch_size, self.timesteps, self.in_channels, self.input_size, self.input_size)\n",
    "        x = x.permute(1, 0, 2, 3, 4)\n",
    "        if self.rec == True:\n",
    "            for i in range(self.timesteps):\n",
    "                if x_cells is None:\n",
    "                    x_cells, hidden = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_cells)\n",
    "                else:\n",
    "                    x_i, hidden = self.ConvRnn_layer(x[i], hidden)\n",
    "                    x_list.append(x_i)\n",
    "        elif self.rec == False:\n",
    "            for i in range(self.timesteps):\n",
    "                if x_cells is None:\n",
    "                    x_cells, _ = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_cells)\n",
    "                else:\n",
    "                    x_i, _ = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_i)\n",
    "        else:\n",
    "            print('RECURRENT can be only True or False')\n",
    "            quit()\n",
    "        x_cells = torch.stack(x_list)\n",
    "        x_cells = x_cells.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        x_cells = x_cells.reshape(-1, self.out_channels, self.input_size, self.input_size)\n",
    "        return x_cells  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRnnRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels ,ConvRnn_input_size, cell_model):\n",
    "        super(ConvRnnRelu, self).__init__()\n",
    "        self.cell_model = cell_model\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_size = ConvRnn_input_size\n",
    "        self.convrnnrelu = nn.Sequential(ConvRnn(self.in_channels, self.out_channels, \n",
    "                                                 self.input_size, self.cell_model),\n",
    "                                         nn.ReLU()\n",
    "                                         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convrnnrelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRelu, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.convrelu = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "                                      nn.ReLU()\n",
    "                                      )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convrelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaxPool, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.maxpool(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpAndCat(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(UpAndCat, self).__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x_up, x_cat):\n",
    "        out = self.up(x_up)\n",
    "        out = torch.cat([out, x_cat], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model head\n",
    "'''\n",
    "class UNetDesigner(nn.Module):    \n",
    "    def __init__(self, d1, d2, d3, b_, u1, u2, u3, cell_model,\n",
    "                 input_size=INPUT_SIZE, input_channels=INPUT_CHANNELS, num_classes=NUM_CLASSES):\n",
    "        super(UNetDesigner, self).__init__()\n",
    "        self.cell_model = cell_model\n",
    "        self.num_classes = NUM_CLASSES\n",
    "        self.d1, self.d2, self.d3, self.b, self.u1, self.u2, self.u3 = d1, d2, d3, b_, u1, u2, u3\n",
    "        self.input_size = input_size\n",
    "        self.input_chennels = input_channels\n",
    "        self.ch_list = [self.input_chennels, 32, 64, 128, 256]\n",
    "        self.input_x2 = int(self.input_size / 2)\n",
    "        self.input_x4 = int(self.input_size / 4)\n",
    "        self.input_x8 = int(self.input_size / 8)\n",
    "\n",
    "         ##### Down_1 layer ##### input_size = 128\n",
    "        if self.d1 == True:\n",
    "            self.down1 = nn.Sequential(ConvRnnRelu(self.ch_list[0], self.ch_list[1],    # Channels\n",
    "                                                   self.input_size, self.cell_model),               \n",
    "                                       ConvRelu(self.ch_list[1], self.ch_list[1])                   \n",
    "                                       )                                                # 1  -->32\n",
    "        else:                                                                           # 32 -->32\n",
    "            self.down1 = nn.Sequential(ConvRelu(self.ch_list[0], self.ch_list[1]),\n",
    "                                       ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                       )\n",
    "        self.down1_pool = MaxPool()\n",
    "\n",
    "         ##### Down_2 layer ##### input_size = 64\n",
    "        if self.d2 == True:\n",
    "            self.down2 = nn.Sequential(ConvRnnRelu(self.ch_list[1], self.ch_list[2],\n",
    "                                                   self.input_x2, self.cell_model),\n",
    "                                       ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                       )                                                # 32 -->64\n",
    "        else:                                                                           # 64 -->64\n",
    "            self.down2 = nn.Sequential(ConvRelu(self.ch_list[1], self.ch_list[2]),\n",
    "                                       ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                       )\n",
    "        self.down2_pool = MaxPool()\n",
    "\n",
    "         ##### Down_3 layer ##### input_size = 32\n",
    "        if self.d3 == True:\n",
    "            self.down3 = nn.Sequential(ConvRnnRelu(self.ch_list[2], self.ch_list[3], \n",
    "                                                   self.input_x4, self.cell_model),\n",
    "                                       ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                       )                                                # 64 -->128\n",
    "        else:                                                                           # 128-->128\n",
    "            self.down3 = nn.Sequential(ConvRelu(self.ch_list[2], self.ch_list[3]),\n",
    "                                       ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                       )\n",
    "        self.down3_pool = MaxPool()\n",
    "\n",
    "         ##### Bottom layer ##### input_size = 16\n",
    "        if self.b == True:\n",
    "            self.bottom = nn.Sequential(ConvRnnRelu(self.ch_list[3], self.ch_list[4], \n",
    "                                                    self.input_x8, self.cell_model),\n",
    "                                        ConvRelu(self.ch_list[4], self.ch_list[4])\n",
    "                                        )                                               # 128-->256\n",
    "        else:                                                                           # 256-->256\n",
    "            self.bottom = nn.Sequential(ConvRelu(self.ch_list[3], self.ch_list[4]),\n",
    "                                        ConvRelu(self.ch_list[4], self.ch_list[4])\n",
    "                                        )\n",
    "\n",
    "         ##### Up_3 layer #####\n",
    "        self.up_cat_3 = UpAndCat()\n",
    "        if self.u3 == True:\n",
    "            self.up_conv_3 = nn.Sequential(ConvRnnRelu(self.ch_list[4]+self.ch_list[3], \n",
    "                                                       self.ch_list[3], \n",
    "                                                       self.input_x4, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                           )                                            # 394-->128\n",
    "        else:                                                                           # 128-->128\n",
    "            self.up_conv_3 = nn.Sequential(ConvRelu(self.ch_list[4]+self.ch_list[3], \n",
    "                                                    self.ch_list[3]),\n",
    "                                           ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                           )\n",
    "\n",
    "         ##### Up_2 layer #####\n",
    "        self.up_cat_2 = UpAndCat()\n",
    "        if self.u2 == True:\n",
    "            self.up_conv_2 = nn.Sequential(ConvRnnRelu(self.ch_list[3]+self.ch_list[2], \n",
    "                                                       self.ch_list[2], \n",
    "                                                       self.input_x2, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                           )                                            # 192-->64\n",
    "        else:                                                                           # 64 -->64\n",
    "            self.up_conv_2 = nn.Sequential(ConvRelu(self.ch_list[3]+self.ch_list[2], \n",
    "                                                    self.ch_list[2]),\n",
    "                                           ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                           )\n",
    "\n",
    "         ##### Up_1 layer #####\n",
    "        self.up_cat_1 = UpAndCat()\n",
    "        if self.u1 == True:\n",
    "            self.up_conv_1 = nn.Sequential(ConvRnnRelu(self.ch_list[2]+self.ch_list[1], \n",
    "                                                       self.ch_list[1], \n",
    "                                                       self.input_size, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                           )                                            # 96 -->32\n",
    "        else:                                                                           # 32 -->32\n",
    "            self.up_conv_1 = nn.Sequential(ConvRelu(self.ch_list[2]+self.ch_list[1], \n",
    "                                                    self.ch_list[1]),\n",
    "                                           ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                           )\n",
    "\n",
    "         ##### Final layer #####\n",
    "        self.final = nn.Sequential(nn.Conv2d(self.ch_list[1], self.num_classes, kernel_size=1),\n",
    "\n",
    "                                   )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, self.input_chennels, self.input_size, self.input_size)\n",
    "        # print(x.shape)\n",
    "        down1_feat = self.down1(x)\n",
    "        pool1 = self.down1_pool(down1_feat)\n",
    "        # print(pool1.shape)\n",
    "        down2_feat = self.down2(pool1)\n",
    "        pool2 = self.down2_pool(down2_feat)\n",
    "        # print(pool2.shape)\n",
    "        down3_feat = self.down3(pool2)\n",
    "        pool3 = self.down3_pool(down3_feat)\n",
    "        # print(pool3.shape)\n",
    "        bottom_feat = self.bottom(pool3)\n",
    "        # print(bottom_feat.shape)\n",
    "        up_feat3 = self.up_cat_3(bottom_feat, down3_feat)\n",
    "        up_feat3 = self.up_conv_3(up_feat3)\n",
    "        \n",
    "        up_feat2 = self.up_cat_2(up_feat3, down2_feat)\n",
    "        up_feat2 = self.up_conv_2(up_feat2)\n",
    "        \n",
    "        up_feat1 = self.up_cat_1(up_feat2, down1_feat)\n",
    "        up_feat1 = self.up_conv_1(up_feat1)\n",
    "        \n",
    "        out = self.final(up_feat1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetDesigner(d1=PARAMETERS['d1'], \n",
    "                     d2=PARAMETERS['d2'], \n",
    "                     d3=PARAMETERS['d3'], \n",
    "                     b_=PARAMETERS['b_'], \n",
    "                     u1=PARAMETERS['u1'], \n",
    "                     u2=PARAMETERS['u2'], \n",
    "                     u3=PARAMETERS['u3'], \n",
    "                     cell_model=PARAMETERS['cell_model']\n",
    "                     )\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loss\n",
    "'''\n",
    "def l2_loss(x, y, d):\n",
    "    d = d.reshape(x.shape)\n",
    "    y = y.reshape(x.shape)\n",
    "    x = torch.sigmoid(x)\n",
    "    out = ((x - y*d**2)**2).sum()\n",
    "    return out\n",
    "\n",
    "def bce_loss(x, y, d):\n",
    "    y = y.reshape(x.shape)\n",
    "    return F.binary_cross_entropy_with_logits(x, y)\n",
    "\n",
    "def dice_loss(x, y, d):\n",
    "    d = d.reshape(x.shape)\n",
    "    y = y.reshape(x.shape)\n",
    "    x = torch.sigmoid(x)\n",
    "    intersection = (x * y*d**2).sum(dim=2).sum(dim=2)\n",
    "    x_sum = (x*d**2).sum(dim=2).sum(dim=2)\n",
    "    y_sum = (y*d**2).sum(dim=2).sum(dim=2)\n",
    "    dice_loss = 1 - (2*intersection / (x_sum + y_sum))\n",
    "    return dice_loss.mean()\n",
    "\n",
    "def combo_loss(x, y, d, bce_weight=0.5):\n",
    "    combo_loss = bce_weight * bce_loss(x, y, d) + (1 - bce_weight) * dice_loss(x, y, d)\n",
    "    return combo_loss\n",
    "\n",
    "def l2_combo_loss(x, y, d):\n",
    "    l2_combo_loss = l2_loss(x, y, d) * bce_loss(x, y, d)\n",
    "    return l2_combo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Metric\n",
    "'''\n",
    "def IoU_metric(x, y):\n",
    "    y = y.reshape(x.shape)\n",
    "    x = torch.sigmoid(x)\n",
    "    intersection = (x * y).sum(dim=2).sum(dim=2)\n",
    "    x_sum = x.sum(dim=2).sum(dim=2)\n",
    "    y_sum = y.sum(dim=2).sum(dim=2)\n",
    "    IoU_metric = intersection / (x_sum + y_sum - intersection)\n",
    "    return IoU_metric.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** epoch:  0 **********\n",
      "train l2_norm:  0.35749688202684576\n",
      "val l2_norm:  0.3896566778421402\n",
      "********** epoch:  1 **********\n",
      "train l2_norm:  0.3905845731496811\n",
      "val l2_norm:  0.4003892292579015\n",
      "********** epoch:  2 **********\n",
      "train l2_norm:  0.40641744434833527\n",
      "val l2_norm:  0.41460492213567096\n",
      "********** epoch:  3 **********\n",
      "train l2_norm:  0.4464434629136866\n",
      "val l2_norm:  0.4549226413170497\n",
      "********** epoch:  4 **********\n",
      "train l2_norm:  0.47229821709069336\n",
      "val l2_norm:  0.4641411503156026\n",
      "********** epoch:  5 **********\n",
      "train l2_norm:  0.5068259835243225\n",
      "val l2_norm:  0.5272087852160136\n",
      "********** epoch:  6 **********\n",
      "train l2_norm:  0.5416720753366296\n",
      "val l2_norm:  0.5218403041362762\n",
      "********** epoch:  7 **********\n",
      "train l2_norm:  0.534205593846061\n",
      "val l2_norm:  0.528707484404246\n",
      "********** epoch:  8 **********\n",
      "train l2_norm:  0.5479365533048456\n",
      "val l2_norm:  0.5271260142326355\n",
      "********** epoch:  9 **********\n",
      "train l2_norm:  0.5594126744703813\n",
      "val l2_norm:  0.553249309460322\n",
      "********** epoch:  10 **********\n",
      "train l2_norm:  0.5556920875202526\n",
      "val l2_norm:  0.5454198122024536\n",
      "********** epoch:  11 **********\n",
      "train l2_norm:  0.5589204159649935\n",
      "val l2_norm:  0.547583152850469\n",
      "********** epoch:  12 **********\n",
      "train l2_norm:  0.569055671041662\n",
      "val l2_norm:  0.5454201598962148\n",
      "********** epoch:  13 **********\n",
      "train l2_norm:  0.5670022937384519\n",
      "val l2_norm:  0.5489073495070139\n",
      "********** epoch:  14 **********\n",
      "train l2_norm:  0.5724614370952953\n",
      "val l2_norm:  0.5498701930046082\n",
      "********** epoch:  15 **********\n",
      "train l2_norm:  0.5732700743458488\n",
      "val l2_norm:  0.5609561105569204\n",
      "********** epoch:  16 **********\n",
      "train l2_norm:  0.5827011520212347\n",
      "val l2_norm:  0.5711229840914408\n",
      "********** epoch:  17 **********\n",
      "train l2_norm:  0.5829593945633281\n",
      "val l2_norm:  0.5744918286800385\n",
      "********** epoch:  18 **********\n",
      "train l2_norm:  0.590383377942172\n",
      "val l2_norm:  0.5520327786604563\n",
      "********** epoch:  19 **********\n",
      "train l2_norm:  0.580139851028269\n",
      "val l2_norm:  0.5794372856616974\n",
      "********** epoch:  20 **********\n",
      "train l2_norm:  0.5983877344564958\n",
      "val l2_norm:  0.5907634794712067\n",
      "********** epoch:  21 **********\n",
      "train l2_norm:  0.5955764759670604\n",
      "val l2_norm:  0.57241091132164\n",
      "********** epoch:  22 **********\n",
      "train l2_norm:  0.5921710973436182\n",
      "val l2_norm:  0.5682519276936849\n",
      "********** epoch:  23 **********\n",
      "train l2_norm:  0.5955987545576963\n",
      "val l2_norm:  0.5779787798722585\n",
      "********** epoch:  24 **********\n",
      "train l2_norm:  0.5973030545494773\n",
      "val l2_norm:  0.5832122961680094\n",
      "********** epoch:  25 **********\n",
      "train l2_norm:  0.6061845421791077\n",
      "val l2_norm:  0.587627649307251\n",
      "********** epoch:  26 **********\n",
      "train l2_norm:  0.6031665178862485\n",
      "val l2_norm:  0.5821535984675089\n",
      "********** epoch:  27 **********\n",
      "train l2_norm:  0.6041056730530479\n",
      "val l2_norm:  0.5808637936909994\n",
      "********** epoch:  28 **********\n",
      "train l2_norm:  0.6045764088630676\n",
      "val l2_norm:  0.582549512386322\n",
      "********** epoch:  29 **********\n",
      "train l2_norm:  0.6131282150745392\n",
      "val l2_norm:  0.5964283148447672\n",
      "********** epoch:  30 **********\n",
      "train l2_norm:  0.6198846806179393\n",
      "val l2_norm:  0.6069628894329071\n",
      "********** epoch:  31 **********\n",
      "train l2_norm:  0.6187147200107574\n",
      "val l2_norm:  0.5999234616756439\n",
      "********** epoch:  32 **********\n",
      "train l2_norm:  0.6245034228671681\n",
      "val l2_norm:  0.6065990825494131\n",
      "********** epoch:  33 **********\n",
      "train l2_norm:  0.6218307126652111\n",
      "val l2_norm:  0.5993599891662598\n",
      "********** epoch:  34 **********\n",
      "train l2_norm:  0.6276792992245067\n",
      "val l2_norm:  0.5999196271101633\n",
      "********** epoch:  35 **********\n",
      "train l2_norm:  0.628215258771723\n",
      "val l2_norm:  0.6016474962234497\n",
      "********** epoch:  36 **********\n",
      "train l2_norm:  0.6258287754925814\n",
      "val l2_norm:  0.6027045945326487\n",
      "********** epoch:  37 **********\n",
      "train l2_norm:  0.631702718409625\n",
      "val l2_norm:  0.6080675919850668\n",
      "********** epoch:  38 **********\n",
      "train l2_norm:  0.6401874125003815\n",
      "val l2_norm:  0.6215072671572367\n",
      "********** epoch:  39 **********\n",
      "train l2_norm:  0.6355429806492545\n",
      "val l2_norm:  0.6097167829672495\n",
      "********** epoch:  40 **********\n",
      "train l2_norm:  0.6438140191815116\n",
      "val l2_norm:  0.6213057637214661\n",
      "********** epoch:  41 **********\n",
      "train l2_norm:  0.6472230038859628\n",
      "val l2_norm:  0.6188430587450663\n",
      "********** epoch:  42 **********\n",
      "train l2_norm:  0.6413590068166907\n",
      "val l2_norm:  0.613436222076416\n",
      "********** epoch:  43 **********\n",
      "train l2_norm:  0.6448346999558535\n",
      "val l2_norm:  0.6213999688625336\n",
      "********** epoch:  44 **********\n",
      "train l2_norm:  0.6484547745097767\n",
      "val l2_norm:  0.6290955046812693\n",
      "********** epoch:  45 **********\n",
      "train l2_norm:  0.6569480787624012\n",
      "val l2_norm:  0.6311642428239187\n",
      "********** epoch:  46 **********\n",
      "train l2_norm:  0.6586591411720623\n",
      "val l2_norm:  0.6339185138543447\n",
      "********** epoch:  47 **********\n",
      "train l2_norm:  0.6633301512761549\n",
      "val l2_norm:  0.6379516323407491\n",
      "********** epoch:  48 **********\n",
      "train l2_norm:  0.6690159440040588\n",
      "val l2_norm:  0.6406459410985311\n",
      "********** epoch:  49 **********\n",
      "train l2_norm:  0.6727745316245339\n",
      "val l2_norm:  0.6394284268220266\n",
      "********** epoch:  50 **********\n",
      "train l2_norm:  0.6749872375618328\n",
      "val l2_norm:  0.6423935194810232\n",
      "********** epoch:  51 **********\n",
      "train l2_norm:  0.6766555688597939\n",
      "val l2_norm:  0.6483356654644012\n",
      "********** epoch:  52 **********\n",
      "train l2_norm:  0.6823068694634871\n",
      "val l2_norm:  0.6458378235499064\n",
      "********** epoch:  53 **********\n",
      "train l2_norm:  0.6886169043454257\n",
      "val l2_norm:  0.6458715299765269\n",
      "********** epoch:  54 **********\n",
      "train l2_norm:  0.6908815015446056\n",
      "val l2_norm:  0.6475880841414133\n",
      "********** epoch:  55 **********\n",
      "train l2_norm:  0.693383517590436\n",
      "val l2_norm:  0.6446981330712637\n",
      "********** epoch:  56 **********\n",
      "train l2_norm:  0.6987352181564678\n",
      "val l2_norm:  0.6536830961704254\n",
      "********** epoch:  57 **********\n",
      "train l2_norm:  0.7017383494160392\n",
      "val l2_norm:  0.6543799440066019\n",
      "********** epoch:  58 **********\n",
      "train l2_norm:  0.7054258259859952\n",
      "val l2_norm:  0.6566521227359772\n",
      "********** epoch:  59 **********\n",
      "train l2_norm:  0.7093453271822496\n",
      "val l2_norm:  0.6617576082547506\n",
      "********** epoch:  60 **********\n",
      "train l2_norm:  0.712194564667615\n",
      "val l2_norm:  0.6654091874758402\n",
      "********** epoch:  61 **********\n",
      "train l2_norm:  0.7151253954930739\n",
      "val l2_norm:  0.6666678190231323\n",
      "********** epoch:  62 **********\n",
      "train l2_norm:  0.7188878709619696\n",
      "val l2_norm:  0.6671234667301178\n",
      "********** epoch:  63 **********\n",
      "train l2_norm:  0.7216740223494443\n",
      "val l2_norm:  0.6628649135430654\n",
      "********** epoch:  64 **********\n",
      "train l2_norm:  0.7230435311794281\n",
      "val l2_norm:  0.6618176400661469\n",
      "********** epoch:  65 **********\n",
      "train l2_norm:  0.7219772420146249\n",
      "val l2_norm:  0.6678840021292368\n",
      "********** epoch:  66 **********\n",
      "train l2_norm:  0.7232678072019056\n",
      "val l2_norm:  0.6679193079471588\n",
      "********** epoch:  67 **********\n",
      "train l2_norm:  0.7312508984045549\n",
      "val l2_norm:  0.6763052741686503\n",
      "********** epoch:  68 **********\n",
      "train l2_norm:  0.7339646057649092\n",
      "val l2_norm:  0.6797894140084585\n",
      "********** epoch:  69 **********\n",
      "train l2_norm:  0.7392552847212012\n",
      "val l2_norm:  0.6745898127555847\n",
      "********** epoch:  70 **********\n",
      "train l2_norm:  0.7434720532460646\n",
      "val l2_norm:  0.67128253976504\n",
      "********** epoch:  71 **********\n",
      "train l2_norm:  0.748666064305739\n",
      "val l2_norm:  0.6724797884623209\n",
      "********** epoch:  72 **********\n",
      "train l2_norm:  0.7518035173416138\n",
      "val l2_norm:  0.6737481156984965\n",
      "********** epoch:  73 **********\n",
      "train l2_norm:  0.7541469416835092\n",
      "val l2_norm:  0.6749875843524933\n",
      "********** epoch:  74 **********\n",
      "train l2_norm:  0.7539803819222883\n",
      "val l2_norm:  0.6774485011895498\n",
      "********** epoch:  75 **********\n",
      "train l2_norm:  0.7538451796228235\n",
      "val l2_norm:  0.6729079286257426\n",
      "********** epoch:  76 **********\n",
      "train l2_norm:  0.7563957517797296\n",
      "val l2_norm:  0.6769321958223978\n",
      "********** epoch:  77 **********\n",
      "train l2_norm:  0.7594953369010579\n",
      "val l2_norm:  0.6800011098384857\n",
      "********** epoch:  78 **********\n",
      "train l2_norm:  0.7630025717345151\n",
      "val l2_norm:  0.6826395690441132\n",
      "********** epoch:  79 **********\n",
      "train l2_norm:  0.7594499533826654\n",
      "val l2_norm:  0.6847938895225525\n",
      "********** epoch:  80 **********\n",
      "train l2_norm:  0.7612966380336068\n",
      "val l2_norm:  0.6834386388460795\n",
      "********** epoch:  81 **********\n",
      "train l2_norm:  0.7696278095245361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val l2_norm:  0.6841561297575632\n",
      "********** epoch:  82 **********\n",
      "train l2_norm:  0.7763204059817574\n",
      "val l2_norm:  0.6872813105583191\n",
      "********** epoch:  83 **********\n",
      "train l2_norm:  0.7744707681915977\n",
      "val l2_norm:  0.6848389605681101\n",
      "********** epoch:  84 **********\n",
      "train l2_norm:  0.7726312604817477\n",
      "val l2_norm:  0.6850652098655701\n",
      "********** epoch:  85 **********\n",
      "train l2_norm:  0.7808686874129556\n",
      "val l2_norm:  0.681628535191218\n",
      "********** epoch:  86 **********\n",
      "train l2_norm:  0.7866600101644342\n",
      "val l2_norm:  0.6852313280105591\n",
      "********** epoch:  87 **********\n",
      "train l2_norm:  0.790577931837602\n",
      "val l2_norm:  0.6875245869159698\n",
      "********** epoch:  88 **********\n",
      "train l2_norm:  0.7938678562641144\n",
      "val l2_norm:  0.6867292821407318\n",
      "********** epoch:  89 **********\n",
      "train l2_norm:  0.7928775738586079\n",
      "val l2_norm:  0.6870651543140411\n",
      "********** epoch:  90 **********\n",
      "train l2_norm:  0.791100106456063\n",
      "val l2_norm:  0.6876640220483144\n",
      "********** epoch:  91 **********\n",
      "train l2_norm:  0.7911398817192424\n",
      "val l2_norm:  0.6866005758444468\n",
      "********** epoch:  92 **********\n",
      "train l2_norm:  0.7909187593243339\n",
      "val l2_norm:  0.6845172047615051\n",
      "********** epoch:  93 **********\n",
      "train l2_norm:  0.7878211249004711\n",
      "val l2_norm:  0.6742935379346212\n",
      "********** epoch:  94 **********\n",
      "train l2_norm:  0.7830502363768491\n",
      "val l2_norm:  0.6721842885017395\n",
      "********** epoch:  95 **********\n",
      "train l2_norm:  0.7839228835972872\n",
      "val l2_norm:  0.6851952970027924\n",
      "********** epoch:  96 **********\n",
      "train l2_norm:  0.7929994355548512\n",
      "val l2_norm:  0.6913542449474335\n",
      "********** epoch:  97 **********\n",
      "train l2_norm:  0.8048471076921984\n",
      "val l2_norm:  0.6965472797552744\n",
      "********** epoch:  98 **********\n",
      "train l2_norm:  0.8147067942402579\n",
      "val l2_norm:  0.6968137621879578\n",
      "********** epoch:  99 **********\n",
      "train l2_norm:  0.8185688365589489\n",
      "val l2_norm:  0.6958824694156647\n",
      "********** epoch:  100 **********\n",
      "train l2_norm:  0.8184940625320781\n",
      "val l2_norm:  0.6954998771349589\n",
      "********** epoch:  101 **********\n",
      "train l2_norm:  0.8172746842557733\n",
      "val l2_norm:  0.6940165062745413\n",
      "********** epoch:  102 **********\n",
      "train l2_norm:  0.8209023042158647\n",
      "val l2_norm:  0.69533638159434\n",
      "********** epoch:  103 **********\n",
      "train l2_norm:  0.8257455094294115\n",
      "val l2_norm:  0.693232923746109\n",
      "********** epoch:  104 **********\n",
      "train l2_norm:  0.8317010673609647\n",
      "val l2_norm:  0.6933655738830566\n",
      "********** epoch:  105 **********\n",
      "train l2_norm:  0.8384697274728254\n",
      "val l2_norm:  0.6942359507083893\n",
      "********** epoch:  106 **********\n",
      "train l2_norm:  0.8435800129717047\n",
      "val l2_norm:  0.6938992142677307\n",
      "********** epoch:  107 **********\n",
      "train l2_norm:  0.8447288112206892\n",
      "val l2_norm:  0.6964739660422007\n",
      "********** epoch:  108 **********\n",
      "train l2_norm:  0.8458251736380837\n",
      "val l2_norm:  0.6979634761810303\n",
      "********** epoch:  109 **********\n",
      "train l2_norm:  0.8460194116288965\n",
      "val l2_norm:  0.6955605745315552\n",
      "********** epoch:  110 **********\n",
      "train l2_norm:  0.843506783246994\n",
      "val l2_norm:  0.6934721171855927\n",
      "********** epoch:  111 **********\n",
      "train l2_norm:  0.8442265933210199\n",
      "val l2_norm:  0.6954988241195679\n",
      "********** epoch:  112 **********\n",
      "train l2_norm:  0.8440610874782909\n",
      "val l2_norm:  0.6984061400095621\n",
      "********** epoch:  113 **********\n",
      "train l2_norm:  0.8440431004220789\n",
      "val l2_norm:  0.6990975936253866\n",
      "********** epoch:  114 **********\n",
      "train l2_norm:  0.8487985946915366\n",
      "val l2_norm:  0.6965623001257578\n",
      "********** epoch:  115 **********\n",
      "train l2_norm:  0.8512712039730765\n",
      "val l2_norm:  0.6978112061818441\n",
      "********** epoch:  116 **********\n",
      "train l2_norm:  0.8548752313310449\n",
      "val l2_norm:  0.6984106600284576\n",
      "********** epoch:  117 **********\n",
      "train l2_norm:  0.8553150648420508\n",
      "val l2_norm:  0.6983663737773895\n",
      "********** epoch:  118 **********\n",
      "train l2_norm:  0.8540437953038649\n",
      "val l2_norm:  0.6949747602144877\n",
      "********** epoch:  119 **********\n",
      "train l2_norm:  0.8521896411072124\n",
      "val l2_norm:  0.6941578288873037\n",
      "********** epoch:  120 **********\n",
      "train l2_norm:  0.8525892225178805\n",
      "val l2_norm:  0.6891583899656931\n",
      "********** epoch:  121 **********\n",
      "train l2_norm:  0.8544890582561493\n",
      "val l2_norm:  0.6878897845745087\n",
      "********** epoch:  122 **********\n",
      "train l2_norm:  0.8575688708912242\n",
      "val l2_norm:  0.6896870136260986\n",
      "********** epoch:  123 **********\n",
      "train l2_norm:  0.8617198250510476\n",
      "val l2_norm:  0.693162590265274\n",
      "********** epoch:  124 **********\n",
      "train l2_norm:  0.8644964667883787\n",
      "val l2_norm:  0.6948185861110687\n",
      "********** epoch:  125 **********\n",
      "train l2_norm:  0.8643566261638295\n",
      "val l2_norm:  0.6978112359841665\n",
      "********** epoch:  126 **********\n",
      "train l2_norm:  0.8654874942519448\n",
      "val l2_norm:  0.6951885720094045\n",
      "********** epoch:  127 **********\n",
      "train l2_norm:  0.8665884028781544\n",
      "val l2_norm:  0.6909353037675222\n",
      "********** epoch:  128 **********\n",
      "train l2_norm:  0.8657922040332447\n",
      "val l2_norm:  0.6936357021331787\n",
      "********** epoch:  129 **********\n",
      "train l2_norm:  0.8667151467366652\n",
      "val l2_norm:  0.6957612037658691\n",
      "********** epoch:  130 **********\n",
      "train l2_norm:  0.869377924637361\n",
      "val l2_norm:  0.6961450179417928\n",
      "********** epoch:  131 **********\n",
      "train l2_norm:  0.8699792217124592\n",
      "val l2_norm:  0.6981955170631409\n",
      "********** epoch:  132 **********\n",
      "train l2_norm:  0.8731060515750538\n",
      "val l2_norm:  0.6975101431210836\n",
      "********** epoch:  133 **********\n",
      "train l2_norm:  0.873925962231376\n",
      "val l2_norm:  0.6957607765992483\n",
      "********** epoch:  134 **********\n",
      "train l2_norm:  0.8738772598179904\n",
      "val l2_norm:  0.6932775775591532\n",
      "********** epoch:  135 **********\n",
      "train l2_norm:  0.8715845265171744\n",
      "val l2_norm:  0.6950054268042246\n",
      "********** epoch:  136 **********\n",
      "train l2_norm:  0.875380199063908\n",
      "val l2_norm:  0.6975715557734171\n",
      "********** epoch:  137 **********\n",
      "train l2_norm:  0.8786774792454459\n",
      "val l2_norm:  0.6997360984484354\n",
      "********** epoch:  138 **********\n",
      "train l2_norm:  0.8783248310739343\n",
      "val l2_norm:  0.7009252607822418\n",
      "********** epoch:  139 **********\n",
      "train l2_norm:  0.8786930306391283\n",
      "val l2_norm:  0.7002258996168772\n",
      "********** epoch:  140 **********\n",
      "train l2_norm:  0.8781872500072826\n",
      "val l2_norm:  0.6996770004431406\n",
      "********** epoch:  141 **********\n",
      "train l2_norm:  0.8802706707607616\n",
      "val l2_norm:  0.6962117254734039\n",
      "********** epoch:  142 **********\n",
      "train l2_norm:  0.8792866658080708\n",
      "val l2_norm:  0.6916546026865641\n",
      "********** epoch:  143 **********\n",
      "train l2_norm:  0.8737529218196869\n",
      "val l2_norm:  0.6998700102170309\n",
      "********** epoch:  144 **********\n",
      "train l2_norm:  0.8713017187335275\n",
      "val l2_norm:  0.6979695757230123\n",
      "********** epoch:  145 **********\n",
      "train l2_norm:  0.8703033463521437\n",
      "val l2_norm:  0.6885545154412588\n",
      "********** epoch:  146 **********\n",
      "train l2_norm:  0.865249818021601\n",
      "val l2_norm:  0.688296765089035\n",
      "********** epoch:  147 **********\n",
      "train l2_norm:  0.8479867442087694\n",
      "val l2_norm:  0.6880210836728414\n",
      "********** epoch:  148 **********\n",
      "train l2_norm:  0.8357901789925315\n",
      "val l2_norm:  0.6821150581041971\n",
      "********** epoch:  149 **********\n",
      "train l2_norm:  0.833613785830411\n",
      "val l2_norm:  0.6800436476866404\n",
      "********** epoch:  150 **********\n",
      "train l2_norm:  0.8329769237474962\n",
      "val l2_norm:  0.6902475456396738\n",
      "********** epoch:  151 **********\n",
      "train l2_norm:  0.833551824092865\n",
      "val l2_norm:  0.6958267986774445\n",
      "********** epoch:  152 **********\n",
      "train l2_norm:  0.8345638838681307\n",
      "val l2_norm:  0.6941640873750051\n",
      "********** epoch:  153 **********\n",
      "train l2_norm:  0.8441536128520966\n",
      "val l2_norm:  0.6965811550617218\n",
      "********** epoch:  154 **********\n",
      "train l2_norm:  0.8577136857943102\n",
      "val l2_norm:  0.6940944294134775\n",
      "********** epoch:  155 **********\n",
      "train l2_norm:  0.8677001974799416\n",
      "val l2_norm:  0.6906831562519073\n",
      "********** epoch:  156 **********\n",
      "train l2_norm:  0.8753067661415447\n",
      "val l2_norm:  0.6958261430263519\n",
      "********** epoch:  157 **********\n",
      "train l2_norm:  0.8828307390213013\n",
      "val l2_norm:  0.6987415750821432\n",
      "********** epoch:  158 **********\n",
      "train l2_norm:  0.8874414427713915\n",
      "val l2_norm:  0.6997962792714437\n",
      "********** epoch:  159 **********\n",
      "train l2_norm:  0.8902320645072244\n",
      "val l2_norm:  0.7023550570011139\n",
      "********** epoch:  160 **********\n",
      "train l2_norm:  0.8928831571882422\n",
      "val l2_norm:  0.7063751419385275\n",
      "********** epoch:  161 **********\n",
      "train l2_norm:  0.8959791741587899\n",
      "val l2_norm:  0.7061473727226257\n",
      "********** epoch:  162 **********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train l2_norm:  0.8994656855409796\n",
      "val l2_norm:  0.703633983929952\n",
      "********** epoch:  163 **********\n",
      "train l2_norm:  0.901961169459603\n",
      "val l2_norm:  0.7017524739106497\n",
      "********** epoch:  164 **********\n",
      "train l2_norm:  0.9037285907702013\n",
      "val l2_norm:  0.7021828691164652\n",
      "********** epoch:  165 **********\n",
      "train l2_norm:  0.9046330885453657\n",
      "val l2_norm:  0.7046947181224823\n",
      "********** epoch:  166 **********\n",
      "train l2_norm:  0.9057405157522722\n",
      "val l2_norm:  0.7067766586939493\n",
      "********** epoch:  167 **********\n",
      "train l2_norm:  0.9073129702698101\n",
      "val l2_norm:  0.7076823612054189\n",
      "********** epoch:  168 **********\n",
      "train l2_norm:  0.9072065868160941\n",
      "val l2_norm:  0.7075291176637014\n",
      "********** epoch:  169 **********\n",
      "train l2_norm:  0.9074450270696119\n",
      "val l2_norm:  0.7035839458306631\n",
      "********** epoch:  170 **********\n",
      "train l2_norm:  0.9086251746524464\n",
      "val l2_norm:  0.7038164138793945\n",
      "********** epoch:  171 **********\n",
      "train l2_norm:  0.9089334634217349\n",
      "val l2_norm:  0.7073098917802175\n",
      "********** epoch:  172 **********\n",
      "train l2_norm:  0.9077231260863218\n",
      "val l2_norm:  0.7086043159166971\n",
      "********** epoch:  173 **********\n",
      "train l2_norm:  0.9053814492442391\n",
      "val l2_norm:  0.7034083803494772\n",
      "********** epoch:  174 **********\n",
      "train l2_norm:  0.904499663548036\n",
      "val l2_norm:  0.7006680965423584\n",
      "********** epoch:  175 **********\n",
      "train l2_norm:  0.9041026695208116\n",
      "val l2_norm:  0.6989759703477224\n",
      "********** epoch:  176 **********\n",
      "train l2_norm:  0.9046175236051733\n",
      "val l2_norm:  0.7026790579160055\n",
      "********** epoch:  177 **********\n",
      "train l2_norm:  0.903643935918808\n",
      "val l2_norm:  0.697971890370051\n",
      "********** epoch:  178 **********\n",
      "train l2_norm:  0.9018930250948126\n",
      "val l2_norm:  0.6947421729564667\n",
      "********** epoch:  179 **********\n",
      "train l2_norm:  0.9007456302642822\n",
      "val l2_norm:  0.6978892882664999\n",
      "********** epoch:  180 **********\n",
      "train l2_norm:  0.8976827778599479\n",
      "val l2_norm:  0.6960126459598541\n",
      "********** epoch:  181 **********\n",
      "train l2_norm:  0.8941053368828513\n",
      "val l2_norm:  0.6952963670094808\n",
      "********** epoch:  182 **********\n",
      "train l2_norm:  0.8936352811076425\n",
      "val l2_norm:  0.6953056553999583\n",
      "********** epoch:  183 **********\n",
      "train l2_norm:  0.895207329229875\n",
      "val l2_norm:  0.6951454679171244\n",
      "********** epoch:  184 **********\n",
      "train l2_norm:  0.8918922435153614\n",
      "val l2_norm:  0.6958447694778442\n",
      "********** epoch:  185 **********\n",
      "train l2_norm:  0.8869916227730837\n",
      "val l2_norm:  0.6970283587773641\n",
      "********** epoch:  186 **********\n",
      "train l2_norm:  0.8861887725916776\n",
      "val l2_norm:  0.7017119328180949\n",
      "********** epoch:  187 **********\n",
      "train l2_norm:  0.8895627124743029\n",
      "val l2_norm:  0.7057652473449707\n",
      "********** epoch:  188 **********\n",
      "train l2_norm:  0.9008086540482261\n",
      "val l2_norm:  0.707705001036326\n",
      "********** epoch:  189 **********\n",
      "train l2_norm:  0.914222614331679\n",
      "val l2_norm:  0.7082089781761169\n",
      "********** epoch:  190 **********\n",
      "train l2_norm:  0.9230052584951575\n",
      "val l2_norm:  0.7104987104733785\n",
      "********** epoch:  191 **********\n",
      "train l2_norm:  0.9315071349794214\n",
      "val l2_norm:  0.7125543157259623\n",
      "********** epoch:  192 **********\n",
      "train l2_norm:  0.9370329515500502\n",
      "val l2_norm:  0.712128609418869\n",
      "********** epoch:  193 **********\n",
      "train l2_norm:  0.9398181438446045\n",
      "val l2_norm:  0.710736095905304\n",
      "********** epoch:  194 **********\n",
      "train l2_norm:  0.9410988634282892\n",
      "val l2_norm:  0.7095146477222443\n",
      "********** epoch:  195 **********\n",
      "train l2_norm:  0.9407314278862693\n",
      "val l2_norm:  0.7087952097256979\n",
      "********** epoch:  196 **********\n",
      "train l2_norm:  0.9398904388601129\n",
      "val l2_norm:  0.7068938314914703\n",
      "********** epoch:  197 **********\n",
      "train l2_norm:  0.9391006393866106\n",
      "val l2_norm:  0.7056137224038442\n",
      "********** epoch:  198 **********\n",
      "train l2_norm:  0.9365162090821699\n",
      "val l2_norm:  0.7044921020666758\n",
      "********** epoch:  199 **********\n",
      "train l2_norm:  0.9334688999436118\n",
      "val l2_norm:  0.7063558995723724\n",
      "Maximum Valid metric:  0.7125543157259623\n"
     ]
    }
   ],
   "source": [
    "'''Train'''\n",
    "val_loss = []\n",
    "for epoch in range(NUM_EPOCHS):# NUM_EPOCHS = 125\n",
    "    print('*'*10, 'epoch: ', epoch, '*'*10)\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            loss_list = []\n",
    "            model.train()\n",
    "            for i, data in enumerate(data_loaders[phase]):\n",
    "                input, label, depth = data\n",
    "                input = input.to(device)\n",
    "                label = label.to(device)\n",
    "                depth = depth.to(device)\n",
    "                output = model(input)\n",
    "                loss = l2_combo_loss(output, label, depth)\n",
    "                metric = IoU_metric(output, label)\n",
    "                loss_list.append(metric.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            mean_loss = sum(loss_list) / len(loss_list)\n",
    "            print(\"train l2_norm: \", mean_loss)\n",
    "        elif phase == 'valid':\n",
    "            loss_list = []\n",
    "            model.eval()\n",
    "            for i, data in enumerate(data_loaders[phase]):\n",
    "                input, label, depth = data\n",
    "                input = input.to(device)\n",
    "                label = label.to(device)\n",
    "                depth = depth.to(device)\n",
    "                output = model(input)\n",
    "                loss = l2_combo_loss(output, label, depth)\n",
    "                metric = IoU_metric(output, label)\n",
    "                loss_list.append(metric.item())\n",
    "            mean_loss = sum(loss_list) / len(loss_list)\n",
    "            print(\"val l2_norm: \", mean_loss)\n",
    "            val_loss.append(mean_loss)\n",
    "print('Maximum Valid metric: ', max(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/headless/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([9.1546e-01, 9.6056e-05, 2.2037e-10, 1.0661e-09, 2.2670e-07, 9.8617e-03,\n",
       "        5.2378e-01, 4.0637e-05, 1.4220e-06, 1.5416e-04, 1.1113e-04, 6.0003e-03,\n",
       "        7.3951e-03, 9.8635e-01, 9.9998e-01, 9.8036e-01, 3.3454e-04, 3.9039e-06,\n",
       "        1.3288e-06, 2.2586e-09, 5.1978e-13, 3.2548e-11, 8.8867e-09, 1.1348e-05,\n",
       "        4.2070e-03, 1.3294e-01, 1.6883e-01, 2.3664e-03, 8.9282e-05, 2.2575e-02,\n",
       "        9.9139e-01, 1.8716e-01, 4.1477e-05, 7.5537e-05, 4.1075e-01, 9.3523e-01,\n",
       "        9.8086e-01, 9.9940e-01, 9.9884e-01, 1.7010e-01, 3.6294e-05, 6.6969e-06,\n",
       "        1.9921e-07, 1.1320e-04, 1.5920e-03, 1.6015e-04, 4.7291e-04, 8.5328e-06,\n",
       "        2.4419e-05, 1.5598e-04, 5.2366e-05, 3.6150e-06, 3.5446e-05, 3.6543e-01,\n",
       "        9.8830e-01, 3.8045e-03, 2.2895e-07, 4.4345e-08, 9.5990e-09, 1.7471e-09,\n",
       "        3.7741e-09, 3.7085e-07, 1.6080e-04, 1.1767e-02, 1.8711e-01, 8.1891e-01,\n",
       "        9.7362e-01, 9.7717e-01, 8.3596e-01, 4.5613e-03, 3.6135e-05, 1.4488e-05,\n",
       "        6.2485e-05, 8.9752e-01, 1.0000e+00, 1.0000e+00, 9.9999e-01, 9.9909e-01,\n",
       "        7.4367e-01, 1.7264e-04, 8.5424e-06, 1.1192e-04, 4.8258e-04, 6.4180e-04,\n",
       "        5.8099e-04, 8.3345e-01, 9.9501e-01, 9.9860e-01, 9.9999e-01, 1.0000e+00,\n",
       "        9.9999e-01, 9.9961e-01, 9.9964e-01, 1.0000e+00, 1.0000e+00, 9.9966e-01,\n",
       "        9.2243e-01, 7.7208e-01, 2.8551e-01, 3.2212e-03, 9.0777e-04, 6.6483e-04,\n",
       "        3.9103e-07, 3.4970e-06, 3.3409e-05, 3.5871e-06, 1.0254e-04, 2.0702e-01,\n",
       "        6.3054e-01, 2.2047e-01, 6.0189e-02, 9.9510e-01, 1.6557e-04, 3.2132e-12,\n",
       "        2.2458e-16, 2.2960e-13, 1.8139e-06, 2.4727e-03, 6.8676e-02, 8.4382e-01,\n",
       "        4.8503e-01, 4.8040e-03, 2.0855e-06, 2.0775e-03, 9.8840e-01, 9.9998e-01,\n",
       "        9.9504e-01, 8.4314e-01], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(output[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF76229910>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil((output[0][0].cpu()>0).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF7627B350>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil(F.sigmoid(output[0][1].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_inp = []\n",
    "list_out = []\n",
    "for i, data in enumerate(test_loader):\n",
    "    input = data\n",
    "    input = input.to(device)\n",
    "    test_output = model(input)\n",
    "    list_inp.append(input)\n",
    "    list_out.append(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 128, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_inp[0].shape\n",
    "list_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showw(object, i):\n",
    "    imgs = object[i].cpu()\n",
    "    img = F.sigmoid(imgs[2][1])\n",
    "    return to_pil(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF7615A750>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showw(list_out, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageSequence\n",
    "index = 3 \n",
    "for i in range(len(list_out)):\n",
    "    test_out = showw(list_out, i)\n",
    "    test_out.save(\"../r_unet/data/test_output/frame%d.png\" % index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
