{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_output', 'images_val', 'labels_val', 'test', 'labels', 'images']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import scipy.ndimage.morphology as morph\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "os.listdir('../r_unet/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Parameters\n",
    "'''\n",
    "\"\"\"\n",
    "cell_model = {\n",
    "    'Rnn' : ConvRnnCell(in_channels, out_channels), \n",
    "    'Gru' : ConvGruCell(in_channels, out_channels), \n",
    "    'Rrn' : ConvRrnCell(in_channels, out_channels), \n",
    "    'Sru' : ConvSruCell(in_channels, out_channels), \n",
    "    'Dru' : ConvDruCell(in_channels, out_channels)\n",
    "}\n",
    "\"\"\"\n",
    "RECURRENT = True\n",
    "PARAMETERS = {\n",
    "    'd1':False, \n",
    "    'd2':False, \n",
    "    'd3':False, \n",
    "    'b_':True, \n",
    "    'u1':False, \n",
    "    'u2':False, \n",
    "    'u3':False, \n",
    "    'cell_model':'Sru'\n",
    "}\n",
    "\n",
    "DEVICE = \"cuda:1\"\n",
    "# arguments\n",
    "TIMESTEPS = 3\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 200\n",
    "INPUT_SIZE = 128\n",
    "INPUT_CHANNELS = 1\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                              transforms.Resize((INPUT_SIZE, INPUT_SIZE), interpolation = 0),\n",
    "                              transforms.ToTensor()\n",
    "                              ])\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# decive\n",
    "device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way to the data folders\n",
    "FOLDER_DATA = \"../r_unet/data/images\"\n",
    "FOLDER_MASK = \"../r_unet/data/labels\"\n",
    "FOLDER_TEST = \"../r_unet/data/test\"\n",
    "FOLDER_DATA_VAL = \"../r_unet/data/images_val\"\n",
    "FOLDER_MASK_VAL = \"../r_unet/data/labels_val\"\n",
    "\n",
    "FILE_NAMES = sorted(os.listdir('../r_unet/data/images'))\n",
    "FILE_NAMES_VAL = sorted(os.listdir('../r_unet/data/images_val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataloader\n",
    "'''\n",
    "def get_labels(object):\n",
    "    label1 = (object==0).float()\n",
    "    depth1 = to_tensor(morph.distance_transform_edt(np.asarray(label1[0])))\n",
    "    label2 = (label1==0).float()\n",
    "    depth2 = to_tensor(morph.distance_transform_edt(np.asarray(label2[0])))\n",
    "    labels = torch.stack([label1, label2], dim=1).squeeze()\n",
    "    depths = torch.stack([depth1, depth2], dim=1).squeeze()\n",
    "    return labels, depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_data = FOLDER_DATA\n",
    "        self.folder_mask = FOLDER_MASK\n",
    "        self.file_names = FILE_NAMES\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        gif_list_depth = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + self.file_names[idx+i])))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            label, depth = get_labels(transform(Image.open(self.folder_mask + '/' + self.file_names[idx+i])))\n",
    "            gif_list.append(label)\n",
    "            gif_list_depth.append(depth)\n",
    "        gif_mask = torch.stack(gif_list)\n",
    "        gif_depth = torch.stack(gif_list_depth)\n",
    "        gif_list.clear()\n",
    "        gif_list_depth.clear()\n",
    "        return gif_data, gif_mask, gif_depth\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "\n",
    "\n",
    "class ValMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_data = FOLDER_DATA_VAL\n",
    "        self.folder_mask = FOLDER_MASK_VAL\n",
    "        self.file_names = FILE_NAMES_VAL\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        gif_list_depth = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + self.file_names[idx+i])))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            label, depth = get_labels(transform(Image.open(self.folder_mask + '/' + self.file_names[idx+i])))\n",
    "            gif_list.append(label)\n",
    "            gif_list_depth.append(depth)\n",
    "        gif_mask = torch.stack(gif_list)\n",
    "        gif_depth = torch.stack(gif_list_depth)\n",
    "        gif_list.clear()\n",
    "        gif_list_depth.clear()\n",
    "        return gif_data, gif_mask, gif_depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "\n",
    "\n",
    "class TestMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_test = FOLDER_TEST\n",
    "        self.file_names = FILE_NAMES + FILE_NAMES_VAL\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_test + '/' + self.file_names[idx+i])))\n",
    "        gif_test = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        return gif_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainMedData()\n",
    "valid_dataset = ValMedData()\n",
    "test_dataset = TestMedData()\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=1,\n",
    "                          shuffle=False)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=1,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=1,\n",
    "                         num_workers=1,\n",
    "                         shuffle=False)\n",
    "\n",
    "data_loaders = {\n",
    "    'train' : train_loader,\n",
    "    'valid' : valid_loader,\n",
    "    'test' : test_loader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'valid': len(valid_dataset),\n",
    "    'test': len(test_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Recurrent cell\n",
    "'''\n",
    "class ConvRnnCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRnnCell, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "             \n",
    "    def forward(self, x, hidden):\n",
    "        out = torch.cat([x, hidden],dim=1)\n",
    "        out = self.conv1(out)\n",
    "        hidden = out\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGruCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvGruCell, self).__init__()\n",
    "        self.conv_for_input = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_for_hidden = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_2x_update = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        self.conv_2x_reset = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_2x_update(input)\n",
    "        update_gate = self.sig((update_gate)) ### output after update gate\n",
    "        reset_gate = self.conv_2x_reset(input)\n",
    "        reset_gate = self.sig((reset_gate)) ### output after reset gate\n",
    "        \n",
    "        \n",
    "        memory_for_input = self.conv_for_input(x)\n",
    "        memory_for_hidden = self.conv_for_hidden(hidden)# просто хидден\n",
    "\n",
    "        memory_content = memory_for_input + (reset_gate * memory_for_hidden) ### output for reset gate(affects how the reset gate do work)\n",
    "        memory_content = self.relu(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRrnCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRrnCell, self).__init__()\n",
    "        self.conv_for_input = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_for_hidden = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_2x_update = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        self.conv_2x_reset = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_2x_update(input)\n",
    "        update_gate = self.sig((update_gate)) \n",
    "        \n",
    "        memory_for_input = self.conv_for_input(x)\n",
    "        memory_for_hidden = hidden\n",
    "\n",
    "        memory_content = memory_for_input + memory_for_hidden\n",
    "        memory_content = self.relu(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSruCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvSruCell, self).__init__()\n",
    "        self.update_gate = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.backbone = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        z = self.update_gate(x)\n",
    "        z = self.sig(z)\n",
    "        \n",
    "        h_ = self.backbone(x)\n",
    "        h_ = self.tanh(h_)\n",
    "        \n",
    "        h_prev = hidden * z\n",
    "        h = (1 - z) * h_\n",
    "        out = h + h_prev\n",
    "        return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDruCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvDruCell, self).__init__()\n",
    "        self.update_gate = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.reset_gate = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.backbone = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        z = self.update_gate(x)\n",
    "        z = self.sig(z)\n",
    "        \n",
    "        r = self.reset_gate(x)\n",
    "        r = self.sig(r)\n",
    "        rx = r * x\n",
    "        h_ = self.backbone(rx)\n",
    "        h_ = self.tanh(h_)\n",
    "        \n",
    "        h_prev = hidden * z\n",
    "        h = (1 - z) * h_\n",
    "        out = h + h_prev\n",
    "        return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model paths\n",
    "'''\n",
    "class ConvRnn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, ConvRnn_input_size, cell_model, reccurent=RECURRENT): # arg for ConvRnn layer\n",
    "        super(ConvRnn, self).__init__()\n",
    "        self.cell_dict = {\n",
    "            'Rnn' : ConvRnnCell(in_channels, out_channels), \n",
    "            'Gru' : ConvGruCell(in_channels, out_channels), \n",
    "            'Rrn' : ConvRrnCell(in_channels, out_channels), \n",
    "            'Sru' : ConvSruCell(in_channels, out_channels), \n",
    "            'Dru' : ConvDruCell(in_channels, out_channels)\n",
    "        }\n",
    "        self.rec = reccurent\n",
    "        self.cell_model = cell_model\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.timesteps = TIMESTEPS\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_size = ConvRnn_input_size\n",
    "        self.hidden_size = (self.batch_size, self.out_channels, self.input_size, self.input_size)\n",
    "        \n",
    "        self.ConvRnn_layer = self.cell_dict[self.cell_model]\n",
    "        self.init_hidden = torch.zeros(self.hidden_size).to(device)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_cells = None\n",
    "        x_list = []\n",
    "\n",
    "        x = x.reshape(self.batch_size, self.timesteps, self.in_channels, self.input_size, self.input_size)\n",
    "        x = x.permute(1, 0, 2, 3, 4)\n",
    "        if self.rec == True:\n",
    "            for i in range(self.timesteps):\n",
    "                if x_cells is None:\n",
    "                    x_cells, hidden = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_cells)\n",
    "                else:\n",
    "                    x_i, hidden = self.ConvRnn_layer(x[i], hidden)\n",
    "                    x_list.append(x_i)\n",
    "        elif self.rec == False:\n",
    "            for i in range(self.timesteps):\n",
    "                if x_cells is None:\n",
    "                    x_cells, _ = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_cells)\n",
    "                else:\n",
    "                    x_i, _ = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_i)\n",
    "        else:\n",
    "            print('RECURRENT can be only True or False')\n",
    "            quit()\n",
    "        x_cells = torch.stack(x_list)\n",
    "        x_cells = x_cells.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        x_cells = x_cells.reshape(-1, self.out_channels, self.input_size, self.input_size)\n",
    "        return x_cells  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRnnRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels ,ConvRnn_input_size, cell_model):\n",
    "        super(ConvRnnRelu, self).__init__()\n",
    "        self.cell_model = cell_model\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_size = ConvRnn_input_size\n",
    "        self.convrnnrelu = nn.Sequential(ConvRnn(self.in_channels, self.out_channels, \n",
    "                                                 self.input_size, self.cell_model),\n",
    "                                         nn.ReLU()\n",
    "                                         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convrnnrelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRelu, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.convrelu = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "                                      nn.ReLU()\n",
    "                                      )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convrelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaxPool, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.maxpool(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpAndCat(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(UpAndCat, self).__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x_up, x_cat):\n",
    "        out = self.up(x_up)\n",
    "        out = torch.cat([out, x_cat], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model head\n",
    "'''\n",
    "class UNetDesigner(nn.Module):    \n",
    "    def __init__(self, d1, d2, d3, b_, u1, u2, u3, cell_model,\n",
    "                 input_size=INPUT_SIZE, input_channels=INPUT_CHANNELS, num_classes=NUM_CLASSES):\n",
    "        super(UNetDesigner, self).__init__()\n",
    "        self.cell_model = cell_model\n",
    "        self.num_classes = NUM_CLASSES\n",
    "        self.d1, self.d2, self.d3, self.b, self.u1, self.u2, self.u3 = d1, d2, d3, b_, u1, u2, u3\n",
    "        self.input_size = input_size\n",
    "        self.input_chennels = input_channels\n",
    "        self.ch_list = [self.input_chennels, 32, 64, 128, 256]\n",
    "        self.input_x2 = int(self.input_size / 2)\n",
    "        self.input_x4 = int(self.input_size / 4)\n",
    "        self.input_x8 = int(self.input_size / 8)\n",
    "\n",
    "         ##### Down_1 layer ##### input_size = 128\n",
    "        if self.d1 == True:\n",
    "            self.down1 = nn.Sequential(ConvRnnRelu(self.ch_list[0], self.ch_list[1],    # Channels\n",
    "                                                   self.input_size, self.cell_model),               \n",
    "                                       ConvRelu(self.ch_list[1], self.ch_list[1])                   \n",
    "                                       )                                                # 1  -->32\n",
    "        else:                                                                           # 32 -->32\n",
    "            self.down1 = nn.Sequential(ConvRelu(self.ch_list[0], self.ch_list[1]),\n",
    "                                       ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                       )\n",
    "        self.down1_pool = MaxPool()\n",
    "\n",
    "         ##### Down_2 layer ##### input_size = 64\n",
    "        if self.d2 == True:\n",
    "            self.down2 = nn.Sequential(ConvRnnRelu(self.ch_list[1], self.ch_list[2],\n",
    "                                                   self.input_x2, self.cell_model),\n",
    "                                       ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                       )                                                # 32 -->64\n",
    "        else:                                                                           # 64 -->64\n",
    "            self.down2 = nn.Sequential(ConvRelu(self.ch_list[1], self.ch_list[2]),\n",
    "                                       ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                       )\n",
    "        self.down2_pool = MaxPool()\n",
    "\n",
    "         ##### Down_3 layer ##### input_size = 32\n",
    "        if self.d3 == True:\n",
    "            self.down3 = nn.Sequential(ConvRnnRelu(self.ch_list[2], self.ch_list[3], \n",
    "                                                   self.input_x4, self.cell_model),\n",
    "                                       ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                       )                                                # 64 -->128\n",
    "        else:                                                                           # 128-->128\n",
    "            self.down3 = nn.Sequential(ConvRelu(self.ch_list[2], self.ch_list[3]),\n",
    "                                       ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                       )\n",
    "        self.down3_pool = MaxPool()\n",
    "\n",
    "         ##### Bottom layer ##### input_size = 16\n",
    "        if self.b == True:\n",
    "            self.bottom = nn.Sequential(ConvRnnRelu(self.ch_list[3], self.ch_list[4], \n",
    "                                                    self.input_x8, self.cell_model),\n",
    "                                        ConvRelu(self.ch_list[4], self.ch_list[4])\n",
    "                                        )                                               # 128-->256\n",
    "        else:                                                                           # 256-->256\n",
    "            self.bottom = nn.Sequential(ConvRelu(self.ch_list[3], self.ch_list[4]),\n",
    "                                        ConvRelu(self.ch_list[4], self.ch_list[4])\n",
    "                                        )\n",
    "\n",
    "         ##### Up_3 layer #####\n",
    "        self.up_cat_3 = UpAndCat()\n",
    "        if self.u3 == True:\n",
    "            self.up_conv_3 = nn.Sequential(ConvRnnRelu(self.ch_list[4]+self.ch_list[3], \n",
    "                                                       self.ch_list[3], \n",
    "                                                       self.input_x4, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                           )                                            # 394-->128\n",
    "        else:                                                                           # 128-->128\n",
    "            self.up_conv_3 = nn.Sequential(ConvRelu(self.ch_list[4]+self.ch_list[3], \n",
    "                                                    self.ch_list[3]),\n",
    "                                           ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                           )\n",
    "\n",
    "         ##### Up_2 layer #####\n",
    "        self.up_cat_2 = UpAndCat()\n",
    "        if self.u2 == True:\n",
    "            self.up_conv_2 = nn.Sequential(ConvRnnRelu(self.ch_list[3]+self.ch_list[2], \n",
    "                                                       self.ch_list[2], \n",
    "                                                       self.input_x2, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                           )                                            # 192-->64\n",
    "        else:                                                                           # 64 -->64\n",
    "            self.up_conv_2 = nn.Sequential(ConvRelu(self.ch_list[3]+self.ch_list[2], \n",
    "                                                    self.ch_list[2]),\n",
    "                                           ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                           )\n",
    "\n",
    "         ##### Up_1 layer #####\n",
    "        self.up_cat_1 = UpAndCat()\n",
    "        if self.u1 == True:\n",
    "            self.up_conv_1 = nn.Sequential(ConvRnnRelu(self.ch_list[2]+self.ch_list[1], \n",
    "                                                       self.ch_list[1], \n",
    "                                                       self.input_size, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                           )                                            # 96 -->32\n",
    "        else:                                                                           # 32 -->32\n",
    "            self.up_conv_1 = nn.Sequential(ConvRelu(self.ch_list[2]+self.ch_list[1], \n",
    "                                                    self.ch_list[1]),\n",
    "                                           ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                           )\n",
    "\n",
    "         ##### Final layer #####\n",
    "        self.final = nn.Sequential(nn.Conv2d(self.ch_list[1], self.num_classes, kernel_size=1),\n",
    "\n",
    "                                   )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, self.input_chennels, self.input_size, self.input_size)\n",
    "        # print(x.shape)\n",
    "        down1_feat = self.down1(x)\n",
    "        pool1 = self.down1_pool(down1_feat)\n",
    "        # print(pool1.shape)\n",
    "        down2_feat = self.down2(pool1)\n",
    "        pool2 = self.down2_pool(down2_feat)\n",
    "        # print(pool2.shape)\n",
    "        down3_feat = self.down3(pool2)\n",
    "        pool3 = self.down3_pool(down3_feat)\n",
    "        # print(pool3.shape)\n",
    "        bottom_feat = self.bottom(pool3)\n",
    "        # print(bottom_feat.shape)\n",
    "        up_feat3 = self.up_cat_3(bottom_feat, down3_feat)\n",
    "        up_feat3 = self.up_conv_3(up_feat3)\n",
    "        \n",
    "        up_feat2 = self.up_cat_2(up_feat3, down2_feat)\n",
    "        up_feat2 = self.up_conv_2(up_feat2)\n",
    "        \n",
    "        up_feat1 = self.up_cat_1(up_feat2, down1_feat)\n",
    "        up_feat1 = self.up_conv_1(up_feat1)\n",
    "        \n",
    "        out = self.final(up_feat1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetDesigner(d1=PARAMETERS['d1'], \n",
    "                     d2=PARAMETERS['d2'], \n",
    "                     d3=PARAMETERS['d3'], \n",
    "                     b_=PARAMETERS['b_'], \n",
    "                     u1=PARAMETERS['u1'], \n",
    "                     u2=PARAMETERS['u2'], \n",
    "                     u3=PARAMETERS['u3'], \n",
    "                     cell_model=PARAMETERS['cell_model']\n",
    "                     )\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loss\n",
    "'''\n",
    "def l2_loss(x, y, d):\n",
    "    d = d.reshape(x.shape)\n",
    "    y = y.reshape(x.shape)\n",
    "    x = torch.sigmoid(x)\n",
    "    out = ((x - y*d**2)**2).sum()\n",
    "    return out\n",
    "\n",
    "def bce_loss(x, y, d):\n",
    "    y = y.reshape(x.shape)\n",
    "    return F.binary_cross_entropy_with_logits(x, y)\n",
    "\n",
    "def dice_loss(x, y, d):\n",
    "    d = d.reshape(x.shape)\n",
    "    y = y.reshape(x.shape)\n",
    "    x = torch.sigmoid(x)\n",
    "    intersection = (x * y*d**2).sum(dim=2).sum(dim=2)\n",
    "    x_sum = (x*d**2).sum(dim=2).sum(dim=2)\n",
    "    y_sum = (y*d**2).sum(dim=2).sum(dim=2)\n",
    "    dice_loss = 1 - (2*intersection / (x_sum + y_sum))\n",
    "    return dice_loss.mean()\n",
    "\n",
    "def combo_loss(x, y, d, bce_weight=0.5):\n",
    "    combo_loss = bce_weight * bce_loss(x, y, d) + (1 - bce_weight) * dice_loss(x, y, d)\n",
    "    return combo_loss\n",
    "\n",
    "def l2_combo_loss(x, y, d):\n",
    "    l2_combo_loss = l2_loss(x, y, d) * bce_loss(x, y, d)\n",
    "    return l2_combo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Metric\n",
    "'''\n",
    "def IoU_metric(x, y):\n",
    "    y = y.reshape(x.shape)\n",
    "    x = torch.sigmoid(x)\n",
    "    intersection = (x * y).sum(dim=2).sum(dim=2)\n",
    "    x_sum = x.sum(dim=2).sum(dim=2)\n",
    "    y_sum = y.sum(dim=2).sum(dim=2)\n",
    "    IoU_metric = intersection / (x_sum + y_sum - intersection)\n",
    "    return IoU_metric.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** epoch:  0 **********\n",
      "train l2_norm:  0.34664621407335455\n",
      "val l2_norm:  0.39889481166998547\n",
      "********** epoch:  1 **********\n",
      "train l2_norm:  0.39583976431326434\n",
      "val l2_norm:  0.4000908633073171\n",
      "********** epoch:  2 **********\n",
      "train l2_norm:  0.41504816846414044\n",
      "val l2_norm:  0.4296718239784241\n",
      "********** epoch:  3 **********\n",
      "train l2_norm:  0.4600742662494833\n",
      "val l2_norm:  0.4620610525210698\n",
      "********** epoch:  4 **********\n",
      "train l2_norm:  0.4813744547692212\n",
      "val l2_norm:  0.4651027222474416\n",
      "********** epoch:  5 **********\n",
      "train l2_norm:  0.512876033782959\n",
      "val l2_norm:  0.49371211727460224\n",
      "********** epoch:  6 **********\n",
      "train l2_norm:  0.5189668170430444\n",
      "val l2_norm:  0.5055987238883972\n",
      "********** epoch:  7 **********\n",
      "train l2_norm:  0.5340443388982252\n",
      "val l2_norm:  0.5224811832110087\n",
      "********** epoch:  8 **********\n",
      "train l2_norm:  0.5406104570085352\n",
      "val l2_norm:  0.5242035090923309\n",
      "********** epoch:  9 **********\n",
      "train l2_norm:  0.5440439473498951\n",
      "val l2_norm:  0.5281785229841868\n",
      "********** epoch:  10 **********\n",
      "train l2_norm:  0.5459393289956179\n",
      "val l2_norm:  0.5278899272282919\n",
      "********** epoch:  11 **********\n",
      "train l2_norm:  0.551702699877999\n",
      "val l2_norm:  0.5314107040564219\n",
      "********** epoch:  12 **********\n",
      "train l2_norm:  0.555537074804306\n",
      "val l2_norm:  0.536547581354777\n",
      "********** epoch:  13 **********\n",
      "train l2_norm:  0.5594972019845789\n",
      "val l2_norm:  0.5365058382352194\n",
      "********** epoch:  14 **********\n",
      "train l2_norm:  0.5643599981611426\n",
      "val l2_norm:  0.5422582825024923\n",
      "********** epoch:  15 **********\n",
      "train l2_norm:  0.5638446536931124\n",
      "val l2_norm:  0.5466840863227844\n",
      "********** epoch:  16 **********\n",
      "train l2_norm:  0.5712808153846047\n",
      "val l2_norm:  0.5463162263234457\n",
      "********** epoch:  17 **********\n",
      "train l2_norm:  0.5714299136942084\n",
      "val l2_norm:  0.5568009118239085\n",
      "********** epoch:  18 **********\n",
      "train l2_norm:  0.5768722647970373\n",
      "val l2_norm:  0.5563015341758728\n",
      "********** epoch:  19 **********\n",
      "train l2_norm:  0.5807467753236945\n",
      "val l2_norm:  0.5591875513394674\n",
      "********** epoch:  20 **********\n",
      "train l2_norm:  0.5836985490538857\n",
      "val l2_norm:  0.5605797370274862\n",
      "********** epoch:  21 **********\n",
      "train l2_norm:  0.5856157324530862\n",
      "val l2_norm:  0.5663357079029083\n",
      "********** epoch:  22 **********\n",
      "train l2_norm:  0.5894422368569807\n",
      "val l2_norm:  0.5672274728616079\n",
      "********** epoch:  23 **********\n",
      "train l2_norm:  0.5912409885363146\n",
      "val l2_norm:  0.5702883998552958\n",
      "********** epoch:  24 **********\n",
      "train l2_norm:  0.5941590829329058\n",
      "val l2_norm:  0.5746131440003713\n",
      "********** epoch:  25 **********\n",
      "train l2_norm:  0.595846726135774\n",
      "val l2_norm:  0.5735934476057688\n",
      "********** epoch:  26 **********\n",
      "train l2_norm:  0.5961077132008292\n",
      "val l2_norm:  0.5663663645585378\n",
      "********** epoch:  27 **********\n",
      "train l2_norm:  0.5950327461416071\n",
      "val l2_norm:  0.5647082527478536\n",
      "********** epoch:  28 **********\n",
      "train l2_norm:  0.595614184032787\n",
      "val l2_norm:  0.5660176078478495\n",
      "********** epoch:  29 **********\n",
      "train l2_norm:  0.597074264829809\n",
      "val l2_norm:  0.576968769232432\n",
      "********** epoch:  30 **********\n",
      "train l2_norm:  0.6044341000643644\n",
      "val l2_norm:  0.579041063785553\n",
      "********** epoch:  31 **********\n",
      "train l2_norm:  0.6036903397603468\n",
      "val l2_norm:  0.594606339931488\n",
      "********** epoch:  32 **********\n",
      "train l2_norm:  0.6188841760158539\n",
      "val l2_norm:  0.5791171292463938\n",
      "********** epoch:  33 **********\n",
      "train l2_norm:  0.603819652037187\n",
      "val l2_norm:  0.5917569498221079\n",
      "********** epoch:  34 **********\n",
      "train l2_norm:  0.6114495911381461\n",
      "val l2_norm:  0.5898094177246094\n",
      "********** epoch:  35 **********\n",
      "train l2_norm:  0.6092657582326368\n",
      "val l2_norm:  0.5806432068347931\n",
      "********** epoch:  36 **********\n",
      "train l2_norm:  0.6175814650275491\n",
      "val l2_norm:  0.5951696137587229\n",
      "********** epoch:  37 **********\n",
      "train l2_norm:  0.6117874004624106\n",
      "val l2_norm:  0.5960819919904073\n",
      "********** epoch:  38 **********\n",
      "train l2_norm:  0.6132595051418651\n",
      "val l2_norm:  0.6018951833248138\n",
      "********** epoch:  39 **********\n",
      "train l2_norm:  0.6217594065449454\n",
      "val l2_norm:  0.5950312316417694\n",
      "********** epoch:  40 **********\n",
      "train l2_norm:  0.6188471371477301\n",
      "val l2_norm:  0.600303570429484\n",
      "********** epoch:  41 **********\n",
      "train l2_norm:  0.6246867748824033\n",
      "val l2_norm:  0.6060341993967692\n",
      "********** epoch:  42 **********\n",
      "train l2_norm:  0.6304121776060625\n",
      "val l2_norm:  0.6115694940090179\n",
      "********** epoch:  43 **********\n",
      "train l2_norm:  0.6347419429909099\n",
      "val l2_norm:  0.6102710962295532\n",
      "********** epoch:  44 **********\n",
      "train l2_norm:  0.6344499452547594\n",
      "val l2_norm:  0.5974549452463785\n",
      "********** epoch:  45 **********\n",
      "train l2_norm:  0.6305895420637998\n",
      "val l2_norm:  0.5942499240239462\n",
      "********** epoch:  46 **********\n",
      "train l2_norm:  0.6338964809070934\n",
      "val l2_norm:  0.599690576394399\n",
      "********** epoch:  47 **********\n",
      "train l2_norm:  0.637218480760401\n",
      "val l2_norm:  0.6033113698164622\n",
      "********** epoch:  48 **********\n",
      "train l2_norm:  0.6440794142809781\n",
      "val l2_norm:  0.6104158262411753\n",
      "********** epoch:  49 **********\n",
      "train l2_norm:  0.6479413563554938\n",
      "val l2_norm:  0.6184839804967245\n",
      "********** epoch:  50 **********\n",
      "train l2_norm:  0.6492967822334983\n",
      "val l2_norm:  0.6215527057647705\n",
      "********** epoch:  51 **********\n",
      "train l2_norm:  0.6548232517459176\n",
      "val l2_norm:  0.6178460419178009\n",
      "********** epoch:  52 **********\n",
      "train l2_norm:  0.6575392322106794\n",
      "val l2_norm:  0.6330112715562185\n",
      "********** epoch:  53 **********\n",
      "train l2_norm:  0.6627099974588915\n",
      "val l2_norm:  0.6299301981925964\n",
      "********** epoch:  54 **********\n",
      "train l2_norm:  0.6666514819318597\n",
      "val l2_norm:  0.6363746722539266\n",
      "********** epoch:  55 **********\n",
      "train l2_norm:  0.6700931814583865\n",
      "val l2_norm:  0.6334059238433838\n",
      "********** epoch:  56 **********\n",
      "train l2_norm:  0.6720056967301802\n",
      "val l2_norm:  0.630903959274292\n",
      "********** epoch:  57 **********\n",
      "train l2_norm:  0.6750356744636189\n",
      "val l2_norm:  0.6428351004918417\n",
      "********** epoch:  58 **********\n",
      "train l2_norm:  0.6768314079804854\n",
      "val l2_norm:  0.6309034923712412\n",
      "********** epoch:  59 **********\n",
      "train l2_norm:  0.6809188533913005\n",
      "val l2_norm:  0.6325283249219259\n",
      "********** epoch:  60 **********\n",
      "train l2_norm:  0.6823395192623138\n",
      "val l2_norm:  0.6334674954414368\n",
      "********** epoch:  61 **********\n",
      "train l2_norm:  0.6825511374256827\n",
      "val l2_norm:  0.640384167432785\n",
      "********** epoch:  62 **********\n",
      "train l2_norm:  0.6824546320871874\n",
      "val l2_norm:  0.6341603895028433\n",
      "********** epoch:  63 **********\n",
      "train l2_norm:  0.6843760799277913\n",
      "val l2_norm:  0.6462967097759247\n",
      "********** epoch:  64 **********\n",
      "train l2_norm:  0.6884607076644897\n",
      "val l2_norm:  0.6404548088709513\n",
      "********** epoch:  65 **********\n",
      "train l2_norm:  0.6911226863210852\n",
      "val l2_norm:  0.6527562141418457\n",
      "********** epoch:  66 **********\n",
      "train l2_norm:  0.6955713087862189\n",
      "val l2_norm:  0.654648353656133\n",
      "********** epoch:  67 **********\n",
      "train l2_norm:  0.6943945938890631\n",
      "val l2_norm:  0.6572992404301962\n",
      "********** epoch:  68 **********\n",
      "train l2_norm:  0.6786417934027585\n",
      "val l2_norm:  0.642641524473826\n",
      "********** epoch:  69 **********\n",
      "train l2_norm:  0.6805993074720557\n",
      "val l2_norm:  0.6452888151009878\n",
      "********** epoch:  70 **********\n",
      "train l2_norm:  0.69465587626804\n",
      "val l2_norm:  0.6615040798981985\n",
      "********** epoch:  71 **********\n",
      "train l2_norm:  0.7036479332230308\n",
      "val l2_norm:  0.6663248042265574\n",
      "********** epoch:  72 **********\n",
      "train l2_norm:  0.7099866135553881\n",
      "val l2_norm:  0.6672221223513285\n",
      "********** epoch:  73 **********\n",
      "train l2_norm:  0.7111205729571256\n",
      "val l2_norm:  0.6658154825369517\n",
      "********** epoch:  74 **********\n",
      "train l2_norm:  0.7139005715196783\n",
      "val l2_norm:  0.6671700477600098\n",
      "********** epoch:  75 **********\n",
      "train l2_norm:  0.7161675556139513\n",
      "val l2_norm:  0.6730939447879791\n",
      "********** epoch:  76 **********\n",
      "train l2_norm:  0.717125041918321\n",
      "val l2_norm:  0.6734015643596649\n",
      "********** epoch:  77 **********\n",
      "train l2_norm:  0.7188788056373596\n",
      "val l2_norm:  0.6707373758157095\n",
      "********** epoch:  78 **********\n",
      "train l2_norm:  0.7218855727802623\n",
      "val l2_norm:  0.6721749504407247\n",
      "********** epoch:  79 **********\n",
      "train l2_norm:  0.7278368283401836\n",
      "val l2_norm:  0.6762034694353739\n",
      "********** epoch:  80 **********\n",
      "train l2_norm:  0.7322720045393164\n",
      "val l2_norm:  0.6765998601913452\n",
      "********** epoch:  81 **********\n",
      "train l2_norm:  0.7383516430854797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val l2_norm:  0.6752191781997681\n",
      "********** epoch:  82 **********\n",
      "train l2_norm:  0.742489836432717\n",
      "val l2_norm:  0.674097349246343\n",
      "********** epoch:  83 **********\n",
      "train l2_norm:  0.7456246722828258\n",
      "val l2_norm:  0.6768884658813477\n",
      "********** epoch:  84 **********\n",
      "train l2_norm:  0.7476735629818656\n",
      "val l2_norm:  0.6810869177182516\n",
      "********** epoch:  85 **********\n",
      "train l2_norm:  0.7497270405292511\n",
      "val l2_norm:  0.6825880308945974\n",
      "********** epoch:  86 **********\n",
      "train l2_norm:  0.7505278316411105\n",
      "val l2_norm:  0.6806908448537191\n",
      "********** epoch:  87 **********\n",
      "train l2_norm:  0.7548196667974646\n",
      "val l2_norm:  0.6856258809566498\n",
      "********** epoch:  88 **********\n",
      "train l2_norm:  0.7585835998708551\n",
      "val l2_norm:  0.6868453721205393\n",
      "********** epoch:  89 **********\n",
      "train l2_norm:  0.7635721347548745\n",
      "val l2_norm:  0.6876523395379385\n",
      "********** epoch:  90 **********\n",
      "train l2_norm:  0.7682002566077493\n",
      "val l2_norm:  0.686519722143809\n",
      "********** epoch:  91 **********\n",
      "train l2_norm:  0.7706942856311798\n",
      "val l2_norm:  0.6860339840253195\n",
      "********** epoch:  92 **********\n",
      "train l2_norm:  0.770942278883674\n",
      "val l2_norm:  0.6848679582277933\n",
      "********** epoch:  93 **********\n",
      "train l2_norm:  0.7728867557915774\n",
      "val l2_norm:  0.6848385632038116\n",
      "********** epoch:  94 **********\n",
      "train l2_norm:  0.7757013846527446\n",
      "val l2_norm:  0.6853171586990356\n",
      "********** epoch:  95 **********\n",
      "train l2_norm:  0.7832952575250105\n",
      "val l2_norm:  0.6896214485168457\n",
      "********** epoch:  96 **********\n",
      "train l2_norm:  0.7918427342718298\n",
      "val l2_norm:  0.6908456087112427\n",
      "********** epoch:  97 **********\n",
      "train l2_norm:  0.7964718558571555\n",
      "val l2_norm:  0.692016581694285\n",
      "********** epoch:  98 **********\n",
      "train l2_norm:  0.7993711504069242\n",
      "val l2_norm:  0.6934093634287516\n",
      "********** epoch:  99 **********\n",
      "train l2_norm:  0.799867261539806\n",
      "val l2_norm:  0.6949198544025421\n",
      "********** epoch:  100 **********\n",
      "train l2_norm:  0.8002654910087585\n",
      "val l2_norm:  0.6959663430849711\n",
      "********** epoch:  101 **********\n",
      "train l2_norm:  0.7991291636770422\n",
      "val l2_norm:  0.6966718137264252\n",
      "********** epoch:  102 **********\n",
      "train l2_norm:  0.7980960201133381\n",
      "val l2_norm:  0.6951420406500498\n",
      "********** epoch:  103 **********\n",
      "train l2_norm:  0.7982840402559801\n",
      "val l2_norm:  0.6922565698623657\n",
      "********** epoch:  104 **********\n",
      "train l2_norm:  0.8011486692862078\n",
      "val l2_norm:  0.691769927740097\n",
      "********** epoch:  105 **********\n",
      "train l2_norm:  0.8043150549585169\n",
      "val l2_norm:  0.6906619171301523\n",
      "********** epoch:  106 **********\n",
      "train l2_norm:  0.8037686320868406\n",
      "val l2_norm:  0.6836594740549723\n",
      "********** epoch:  107 **********\n",
      "train l2_norm:  0.8073406923900951\n",
      "val l2_norm:  0.691550483306249\n",
      "********** epoch:  108 **********\n",
      "train l2_norm:  0.8085808835246346\n",
      "val l2_norm:  0.6922057767709097\n",
      "********** epoch:  109 **********\n",
      "train l2_norm:  0.8133762099526145\n",
      "val l2_norm:  0.6884471376736959\n",
      "********** epoch:  110 **********\n",
      "train l2_norm:  0.8164018609307029\n",
      "val l2_norm:  0.6920480231444041\n",
      "********** epoch:  111 **********\n",
      "train l2_norm:  0.8190350830554962\n",
      "val l2_norm:  0.6953677038351694\n",
      "********** epoch:  112 **********\n",
      "train l2_norm:  0.8250319280407645\n",
      "val l2_norm:  0.6979718705018362\n",
      "********** epoch:  113 **********\n",
      "train l2_norm:  0.8306490480899811\n",
      "val l2_norm:  0.6952245533466339\n",
      "********** epoch:  114 **********\n",
      "train l2_norm:  0.833617860620672\n",
      "val l2_norm:  0.6933070321877798\n",
      "********** epoch:  115 **********\n",
      "train l2_norm:  0.8351153650067069\n",
      "val l2_norm:  0.6939907968044281\n",
      "********** epoch:  116 **********\n",
      "train l2_norm:  0.8340371792966669\n",
      "val l2_norm:  0.6933312316735586\n",
      "********** epoch:  117 **********\n",
      "train l2_norm:  0.8373931023207578\n",
      "val l2_norm:  0.6970450182755789\n",
      "********** epoch:  118 **********\n",
      "train l2_norm:  0.8376462242820046\n",
      "val l2_norm:  0.6959452033042908\n",
      "********** epoch:  119 **********\n",
      "train l2_norm:  0.8378243717280301\n",
      "val l2_norm:  0.6930339634418488\n",
      "********** epoch:  120 **********\n",
      "train l2_norm:  0.8347057375040922\n",
      "val l2_norm:  0.690536787112554\n",
      "********** epoch:  121 **********\n",
      "train l2_norm:  0.8336472809314728\n",
      "val l2_norm:  0.6845188637574514\n",
      "********** epoch:  122 **********\n",
      "train l2_norm:  0.8317579870874231\n",
      "val l2_norm:  0.6850312252839407\n",
      "********** epoch:  123 **********\n",
      "train l2_norm:  0.828487751158801\n",
      "val l2_norm:  0.69482421875\n",
      "********** epoch:  124 **********\n",
      "train l2_norm:  0.8283881680531935\n",
      "val l2_norm:  0.6963332096735636\n",
      "********** epoch:  125 **********\n",
      "train l2_norm:  0.8305031250823628\n",
      "val l2_norm:  0.6950809359550476\n",
      "********** epoch:  126 **********\n",
      "train l2_norm:  0.8352805836634203\n",
      "val l2_norm:  0.6955292820930481\n",
      "********** epoch:  127 **********\n",
      "train l2_norm:  0.8416450673883612\n",
      "val l2_norm:  0.695522258679072\n",
      "********** epoch:  128 **********\n",
      "train l2_norm:  0.8462934548204596\n",
      "val l2_norm:  0.689544677734375\n",
      "********** epoch:  129 **********\n",
      "train l2_norm:  0.8441080261360515\n",
      "val l2_norm:  0.6875656942526499\n",
      "********** epoch:  130 **********\n",
      "train l2_norm:  0.8440135473554785\n",
      "val l2_norm:  0.6914854844411215\n",
      "********** epoch:  131 **********\n",
      "train l2_norm:  0.8443720882589166\n",
      "val l2_norm:  0.6956519385178884\n",
      "********** epoch:  132 **********\n",
      "train l2_norm:  0.8458808741786263\n",
      "val l2_norm:  0.6981242199738821\n",
      "********** epoch:  133 **********\n",
      "train l2_norm:  0.8537588092413816\n",
      "val l2_norm:  0.7002270221710205\n",
      "********** epoch:  134 **********\n",
      "train l2_norm:  0.8573168516159058\n",
      "val l2_norm:  0.7006298005580902\n",
      "********** epoch:  135 **********\n",
      "train l2_norm:  0.8587337678129022\n",
      "val l2_norm:  0.6980247894922892\n",
      "********** epoch:  136 **********\n",
      "train l2_norm:  0.8571482625874606\n",
      "val l2_norm:  0.6927188237508138\n",
      "********** epoch:  137 **********\n",
      "train l2_norm:  0.855128597129475\n",
      "val l2_norm:  0.6961374680201212\n",
      "********** epoch:  138 **********\n",
      "train l2_norm:  0.853495492176576\n",
      "val l2_norm:  0.6988024910291036\n",
      "********** epoch:  139 **********\n",
      "train l2_norm:  0.8604450740597465\n",
      "val l2_norm:  0.697174479564031\n",
      "********** epoch:  140 **********\n",
      "train l2_norm:  0.8650743500752882\n",
      "val l2_norm:  0.6992546617984772\n",
      "********** epoch:  141 **********\n",
      "train l2_norm:  0.8739953528751027\n",
      "val l2_norm:  0.7008081078529358\n",
      "********** epoch:  142 **********\n",
      "train l2_norm:  0.8790590383789756\n",
      "val l2_norm:  0.7038149038950602\n",
      "********** epoch:  143 **********\n",
      "train l2_norm:  0.8790135085582733\n",
      "val l2_norm:  0.7083066503206888\n",
      "********** epoch:  144 **********\n",
      "train l2_norm:  0.877802542664788\n",
      "val l2_norm:  0.706577867269516\n",
      "********** epoch:  145 **********\n",
      "train l2_norm:  0.8785067715428092\n",
      "val l2_norm:  0.7066302597522736\n",
      "********** epoch:  146 **********\n",
      "train l2_norm:  0.8763765286315571\n",
      "val l2_norm:  0.7034720579783121\n",
      "********** epoch:  147 **********\n",
      "train l2_norm:  0.8773268434134397\n",
      "val l2_norm:  0.7022761205832163\n",
      "********** epoch:  148 **********\n",
      "train l2_norm:  0.8800258175893263\n",
      "val l2_norm:  0.6965949734052023\n",
      "********** epoch:  149 **********\n",
      "train l2_norm:  0.880276923829859\n",
      "val l2_norm:  0.6951491932074229\n",
      "********** epoch:  150 **********\n",
      "train l2_norm:  0.8776903044093739\n",
      "val l2_norm:  0.7014303902784983\n",
      "********** epoch:  151 **********\n",
      "train l2_norm:  0.8717394687912681\n",
      "val l2_norm:  0.6989484628041586\n",
      "********** epoch:  152 **********\n",
      "train l2_norm:  0.8640373593026941\n",
      "val l2_norm:  0.6977914075056711\n",
      "********** epoch:  153 **********\n",
      "train l2_norm:  0.8719337636774237\n",
      "val l2_norm:  0.7007230520248413\n",
      "********** epoch:  154 **********\n",
      "train l2_norm:  0.8823469823057001\n",
      "val l2_norm:  0.7026327153046926\n",
      "********** epoch:  155 **********\n",
      "train l2_norm:  0.8856262808496301\n",
      "val l2_norm:  0.7042589883009592\n",
      "********** epoch:  156 **********\n",
      "train l2_norm:  0.8849054439501329\n",
      "val l2_norm:  0.7062799433867136\n",
      "********** epoch:  157 **********\n",
      "train l2_norm:  0.8779752444137227\n",
      "val l2_norm:  0.7051599224408468\n",
      "********** epoch:  158 **********\n",
      "train l2_norm:  0.8719937720082023\n",
      "val l2_norm:  0.7022311588128408\n",
      "********** epoch:  159 **********\n",
      "train l2_norm:  0.8721490095962178\n",
      "val l2_norm:  0.7028284768263499\n",
      "********** epoch:  160 **********\n",
      "train l2_norm:  0.8774888813495636\n",
      "val l2_norm:  0.6949357887109121\n",
      "********** epoch:  161 **********\n",
      "train l2_norm:  0.878799481825395\n",
      "val l2_norm:  0.6930844386418661\n",
      "********** epoch:  162 **********\n",
      "train l2_norm:  0.8760894455692985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val l2_norm:  0.7014129559199015\n",
      "********** epoch:  163 **********\n",
      "train l2_norm:  0.8799727613275702\n",
      "val l2_norm:  0.7002058128515879\n",
      "********** epoch:  164 **********\n",
      "train l2_norm:  0.8835380565036427\n",
      "val l2_norm:  0.7061189512411753\n",
      "********** epoch:  165 **********\n",
      "train l2_norm:  0.8901549117131666\n",
      "val l2_norm:  0.7000593841075897\n",
      "********** epoch:  166 **********\n",
      "train l2_norm:  0.891741625287316\n",
      "val l2_norm:  0.695430705944697\n",
      "********** epoch:  167 **********\n",
      "train l2_norm:  0.8876714245839552\n",
      "val l2_norm:  0.69418004155159\n",
      "********** epoch:  168 **********\n",
      "train l2_norm:  0.8852688588879325\n",
      "val l2_norm:  0.6995388070742289\n",
      "********** epoch:  169 **********\n",
      "train l2_norm:  0.8985336558385328\n",
      "val l2_norm:  0.7031284173329672\n",
      "********** epoch:  170 **********\n",
      "train l2_norm:  0.9113755578344519\n",
      "val l2_norm:  0.7097700734933218\n",
      "********** epoch:  171 **********\n",
      "train l2_norm:  0.919434290040623\n",
      "val l2_norm:  0.7181886831919352\n",
      "********** epoch:  172 **********\n",
      "train l2_norm:  0.9234101176261902\n",
      "val l2_norm:  0.7172706226507822\n",
      "********** epoch:  173 **********\n",
      "train l2_norm:  0.9253151037476279\n",
      "val l2_norm:  0.7123347322146097\n",
      "********** epoch:  174 **********\n",
      "train l2_norm:  0.9262092167680914\n",
      "val l2_norm:  0.7073255379994711\n",
      "********** epoch:  175 **********\n",
      "train l2_norm:  0.9268850548700853\n",
      "val l2_norm:  0.7079001267751058\n",
      "********** epoch:  176 **********\n",
      "train l2_norm:  0.9255683991042051\n",
      "val l2_norm:  0.708366185426712\n",
      "********** epoch:  177 **********\n",
      "train l2_norm:  0.9264374998482791\n",
      "val l2_norm:  0.7095076938470205\n",
      "********** epoch:  178 **********\n",
      "train l2_norm:  0.928042016246102\n",
      "val l2_norm:  0.7049055496851603\n",
      "********** epoch:  179 **********\n",
      "train l2_norm:  0.9324565909125588\n",
      "val l2_norm:  0.712308665116628\n",
      "********** epoch:  180 **********\n",
      "train l2_norm:  0.9356983331116763\n",
      "val l2_norm:  0.7157735427220663\n",
      "********** epoch:  181 **********\n",
      "train l2_norm:  0.9373537356203253\n",
      "val l2_norm:  0.7173860967159271\n",
      "********** epoch:  182 **********\n",
      "train l2_norm:  0.9370509088039398\n",
      "val l2_norm:  0.7171442409356436\n",
      "********** epoch:  183 **********\n",
      "train l2_norm:  0.9361710385842756\n",
      "val l2_norm:  0.7143103579680125\n",
      "********** epoch:  184 **********\n",
      "train l2_norm:  0.9386149942874908\n",
      "val l2_norm:  0.7127310037612915\n",
      "********** epoch:  185 **********\n",
      "train l2_norm:  0.938110042702068\n",
      "val l2_norm:  0.7146250208218893\n",
      "********** epoch:  186 **********\n",
      "train l2_norm:  0.941647082567215\n",
      "val l2_norm:  0.7202394902706146\n",
      "********** epoch:  187 **********\n",
      "train l2_norm:  0.9466932903636586\n",
      "val l2_norm:  0.7210930983225504\n",
      "********** epoch:  188 **********\n",
      "train l2_norm:  0.9481494941494681\n",
      "val l2_norm:  0.7221484283606211\n",
      "********** epoch:  189 **********\n",
      "train l2_norm:  0.9512032568454742\n",
      "val l2_norm:  0.7215937972068787\n",
      "********** epoch:  190 **********\n",
      "train l2_norm:  0.9540427327156067\n",
      "val l2_norm:  0.7176985541979471\n",
      "********** epoch:  191 **********\n",
      "train l2_norm:  0.9562932334162972\n",
      "val l2_norm:  0.7180362741152445\n",
      "********** epoch:  192 **********\n",
      "train l2_norm:  0.9586274515498768\n",
      "val l2_norm:  0.7219677865505219\n",
      "********** epoch:  193 **********\n",
      "train l2_norm:  0.958962779153477\n",
      "val l2_norm:  0.7285028994083405\n",
      "********** epoch:  194 **********\n",
      "train l2_norm:  0.9588344693183899\n",
      "val l2_norm:  0.7275059521198273\n",
      "********** epoch:  195 **********\n",
      "train l2_norm:  0.9584927369247783\n",
      "val l2_norm:  0.7257277270158132\n",
      "********** epoch:  196 **********\n",
      "train l2_norm:  0.9608508348464966\n",
      "val l2_norm:  0.7223359843095144\n",
      "********** epoch:  197 **********\n",
      "train l2_norm:  0.9620702402158217\n",
      "val l2_norm:  0.7247266968091329\n",
      "********** epoch:  198 **********\n",
      "train l2_norm:  0.9604849354787306\n",
      "val l2_norm:  0.7237647275129954\n",
      "********** epoch:  199 **********\n",
      "train l2_norm:  0.9625684456391768\n",
      "val l2_norm:  0.727833112080892\n",
      "Maximum Valid metric:  0.7285028994083405\n"
     ]
    }
   ],
   "source": [
    "'''Train'''\n",
    "val_loss = []\n",
    "for epoch in range(NUM_EPOCHS):# NUM_EPOCHS = 125\n",
    "    print('*'*10, 'epoch: ', epoch, '*'*10)\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            loss_list = []\n",
    "            model.train()\n",
    "            for i, data in enumerate(data_loaders[phase]):\n",
    "                input, label, depth = data\n",
    "                input = input.to(device)\n",
    "                label = label.to(device)\n",
    "                depth = depth.to(device)\n",
    "                output = model(input)\n",
    "                loss = l2_combo_loss(output, label, depth)\n",
    "                metric = IoU_metric(output, label)\n",
    "                loss_list.append(metric.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            mean_loss = sum(loss_list) / len(loss_list)\n",
    "            print(\"train l2_norm: \", mean_loss)\n",
    "        elif phase == 'valid':\n",
    "            loss_list = []\n",
    "            model.eval()\n",
    "            for i, data in enumerate(data_loaders[phase]):\n",
    "                input, label, depth = data\n",
    "                input = input.to(device)\n",
    "                label = label.to(device)\n",
    "                depth = depth.to(device)\n",
    "                output = model(input)\n",
    "                loss = l2_combo_loss(output, label, depth)\n",
    "                metric = IoU_metric(output, label)\n",
    "                loss_list.append(metric.item())\n",
    "            mean_loss = sum(loss_list) / len(loss_list)\n",
    "            print(\"val l2_norm: \", mean_loss)\n",
    "            val_loss.append(mean_loss)\n",
    "print('Maximum Valid metric: ', max(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5109e-06, 4.1041e-13, 4.8416e-15, 1.5783e-03, 3.3738e-06, 6.2164e-11,\n",
       "        6.9071e-11, 1.5043e-11, 1.2278e-07, 5.5282e-06, 3.2199e-06, 4.3408e-06,\n",
       "        4.6614e-02, 9.9165e-01, 9.9984e-01, 9.9957e-01, 9.9926e-01, 9.9958e-01,\n",
       "        9.1037e-01, 9.2755e-04, 4.4366e-09, 3.7644e-11, 5.3088e-13, 1.5597e-11,\n",
       "        2.2032e-07, 5.2796e-02, 4.4261e-04, 1.0326e-06, 1.0478e-05, 3.5807e-02,\n",
       "        2.5394e-01, 1.6440e-03, 3.4225e-06, 3.6297e-04, 2.7492e-01, 7.0529e-01,\n",
       "        7.3408e-01, 6.2437e-01, 3.8995e-02, 2.1106e-06, 2.1283e-07, 2.8574e-06,\n",
       "        1.9644e-07, 1.1554e-06, 7.3777e-05, 6.7696e-05, 4.2420e-05, 7.7648e-08,\n",
       "        6.0372e-09, 9.3723e-06, 1.2430e-05, 8.7346e-11, 1.6024e-11, 4.2472e-01,\n",
       "        9.9972e-01, 1.0277e-07, 1.1610e-08, 8.2401e-08, 1.9060e-08, 2.4889e-08,\n",
       "        1.2522e-06, 9.3842e-04, 5.0050e-01, 7.4497e-01, 9.9974e-01, 1.0000e+00,\n",
       "        1.0000e+00, 1.0000e+00, 9.9998e-01, 5.7146e-02, 1.8432e-05, 1.4820e-03,\n",
       "        8.0038e-02, 7.3586e-01, 9.7660e-01, 8.5245e-01, 3.7212e-02, 3.3552e-03,\n",
       "        1.3649e-02, 2.0708e-07, 1.2960e-07, 5.3824e-05, 1.0917e-04, 5.1254e-05,\n",
       "        8.1951e-03, 7.2272e-01, 9.0564e-01, 9.9982e-01, 9.9998e-01, 9.9970e-01,\n",
       "        9.9778e-01, 9.9954e-01, 9.9996e-01, 1.0000e+00, 9.9635e-01, 4.2511e-01,\n",
       "        6.1011e-01, 5.5309e-01, 2.7534e-01, 3.9807e-03, 4.8590e-04, 3.2419e-02,\n",
       "        6.9415e-02, 9.8075e-01, 9.9561e-01, 9.9925e-01, 3.6505e-03, 6.5679e-04,\n",
       "        2.8429e-03, 7.6061e-06, 2.1346e-04, 2.1108e-05, 6.8373e-08, 2.6602e-13,\n",
       "        5.1213e-16, 1.4466e-13, 8.5419e-10, 5.6742e-06, 8.8953e-04, 9.0368e-02,\n",
       "        3.0651e-02, 2.1517e-04, 5.9133e-05, 2.6275e-01, 2.2167e-03, 1.2018e-02,\n",
       "        2.1126e-04, 3.7337e-07], device='cuda:1', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(output[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF733A1750>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil((output[0][0].cpu()>0).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF74998110>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil(F.sigmoid(output[0][1].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showw(object, i):\n",
    "    imgs = object[i].cpu()\n",
    "    img = F.sigmoid(imgs[2][1])\n",
    "    return to_pil(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_inp = []\n",
    "list_out = []\n",
    "for i, data in enumerate(test_loader):\n",
    "    input = data\n",
    "    input = input.to(device)\n",
    "    test_output = model(input)\n",
    "    list_inp.append(input)\n",
    "    list_out.append(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageSequence\n",
    "index = 3 \n",
    "for i in range(len(list_out)):\n",
    "    test_out = showw(list_out, i)\n",
    "    test_out.save(\"../r_unet/data/test_output/frame%d.png\" % index)\n",
    "    index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
