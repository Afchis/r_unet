{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_output', 'images_val', 'labels_val', 'test', 'labels', 'images']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import scipy.ndimage.morphology as morph\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "os.listdir('../r_unet/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Parameters\n",
    "'''\n",
    "\"\"\"\n",
    "cell_model = {\n",
    "    'Rnn' : ConvRnnCell(in_channels, out_channels), \n",
    "    'Gru' : ConvGruCell(in_channels, out_channels), \n",
    "    'Rrn' : ConvRrnCell(in_channels, out_channels), \n",
    "    'Sru' : ConvSruCell(in_channels, out_channels), \n",
    "    'Dru' : ConvDruCell(in_channels, out_channels)\n",
    "}\n",
    "\"\"\"\n",
    "RECURRENT = True\n",
    "PARAMETERS = {\n",
    "    'd1':False, \n",
    "    'd2':False, \n",
    "    'd3':False, \n",
    "    'b_':True, \n",
    "    'u1':False, \n",
    "    'u2':False, \n",
    "    'u3':False, \n",
    "    'cell_model':'Sru'\n",
    "}\n",
    "\n",
    "# arguments\n",
    "TIMESTEPS = 3\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 200\n",
    "INPUT_SIZE = 128\n",
    "INPUT_CHANNELS = 1\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# decive\n",
    "DEVICE = \"cuda:1\"\n",
    "device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way to the data folders\n",
    "FOLDER_DATA = \"../r_unet/data/images\"\n",
    "FOLDER_MASK = \"../r_unet/data/labels\"\n",
    "FOLDER_TEST = \"../r_unet/data/test\"\n",
    "FOLDER_DATA_VAL = \"../r_unet/data/images_val\"\n",
    "FOLDER_MASK_VAL = \"../r_unet/data/labels_val\"\n",
    "\n",
    "FILE_NAMES = sorted(os.listdir('../r_unet/data/images'))\n",
    "FILE_NAMES_VAL = sorted(os.listdir('../r_unet/data/images_val'))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                              transforms.Resize((INPUT_SIZE, INPUT_SIZE), interpolation = 0),\n",
    "                              transforms.ToTensor()\n",
    "                              ])\n",
    "\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataloader\n",
    "'''\n",
    "def get_labels(object):\n",
    "    label1 = (object==0).float()\n",
    "    depth1 = to_tensor(morph.distance_transform_edt(np.asarray(label1[0])))\n",
    "    label2 = (label1==0).float()\n",
    "    depth2 = to_tensor(morph.distance_transform_edt(np.asarray(label2[0])))\n",
    "    labels = torch.stack([label1, label2], dim=1).squeeze()\n",
    "    depths = torch.stack([depth1, depth2], dim=1).squeeze()\n",
    "    return labels, depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_data = FOLDER_DATA\n",
    "        self.folder_mask = FOLDER_MASK\n",
    "        self.file_names = FILE_NAMES\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        gif_list_depth = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + self.file_names[idx+i])))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            label, depth = get_labels(transform(Image.open(self.folder_mask + '/' + self.file_names[idx+i])))\n",
    "            gif_list.append(label)\n",
    "            gif_list_depth.append(depth)\n",
    "        gif_mask = torch.stack(gif_list)\n",
    "        gif_depth = torch.stack(gif_list_depth)\n",
    "        gif_list.clear()\n",
    "        gif_list_depth.clear()\n",
    "        return gif_data, gif_mask, gif_depth\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "\n",
    "\n",
    "class ValMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_data = FOLDER_DATA_VAL\n",
    "        self.folder_mask = FOLDER_MASK_VAL\n",
    "        self.file_names = FILE_NAMES_VAL\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        gif_list_depth = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + self.file_names[idx+i])))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            label, depth = get_labels(transform(Image.open(self.folder_mask + '/' + self.file_names[idx+i])))\n",
    "            gif_list.append(label)\n",
    "            gif_list_depth.append(depth)\n",
    "        gif_mask = torch.stack(gif_list)\n",
    "        gif_depth = torch.stack(gif_list_depth)\n",
    "        gif_list.clear()\n",
    "        gif_list_depth.clear()\n",
    "        return gif_data, gif_mask, gif_depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "\n",
    "\n",
    "class TestMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_test = FOLDER_TEST\n",
    "        self.file_names = FILE_NAMES + FILE_NAMES_VAL\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_test + '/' + self.file_names[idx+i])))\n",
    "        gif_test = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        return gif_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainMedData()\n",
    "valid_dataset = ValMedData()\n",
    "test_dataset = TestMedData()\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=1,\n",
    "                          shuffle=False)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=1,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=1,\n",
    "                         num_workers=1,\n",
    "                         shuffle=False)\n",
    "\n",
    "data_loaders = {\n",
    "    'train' : train_loader,\n",
    "    'valid' : valid_loader,\n",
    "    'test' : test_loader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'valid': len(valid_dataset),\n",
    "    'test': len(test_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Recurrent cell\n",
    "'''\n",
    "class ConvRnnCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRnnCell, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "             \n",
    "    def forward(self, x, hidden):\n",
    "        out = torch.cat([x, hidden],dim=1)\n",
    "        out = self.conv1(out)\n",
    "        hidden = out\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGruCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvGruCell, self).__init__()\n",
    "        self.conv_for_input = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_for_hidden = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_2x_update = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        self.conv_2x_reset = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_2x_update(input)\n",
    "        update_gate = self.sig((update_gate)) ### output after update gate\n",
    "        reset_gate = self.conv_2x_reset(input)\n",
    "        reset_gate = self.sig((reset_gate)) ### output after reset gate\n",
    "        \n",
    "        \n",
    "        memory_for_input = self.conv_for_input(x)\n",
    "        memory_for_hidden = self.conv_for_hidden(hidden)# просто хидден\n",
    "\n",
    "        memory_content = memory_for_input + (reset_gate * memory_for_hidden) ### output for reset gate(affects how the reset gate do work)\n",
    "        memory_content = self.relu(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRrnCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRrnCell, self).__init__()\n",
    "        self.conv_for_input = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_for_hidden = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_2x_update = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        self.conv_2x_reset = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_2x_update(input)\n",
    "        update_gate = self.sig((update_gate)) \n",
    "        \n",
    "        memory_for_input = self.conv_for_input(x)\n",
    "        memory_for_hidden = hidden\n",
    "\n",
    "        memory_content = memory_for_input + memory_for_hidden\n",
    "        memory_content = self.relu(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSruCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvSruCell, self).__init__()\n",
    "        self.update_gate = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.backbone = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        z = self.update_gate(x)\n",
    "        z = self.sig(z)\n",
    "        \n",
    "        h_ = self.backbone(x)\n",
    "        h_ = self.tanh(h_)\n",
    "        \n",
    "        h_prev = hidden * z\n",
    "        h = (1 - z) * h_\n",
    "        out = h + h_prev\n",
    "        return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDruCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvDruCell, self).__init__()\n",
    "        self.update_gate = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.reset_gate = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.backbone = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        z = self.update_gate(x)\n",
    "        z = self.sig(z)\n",
    "        \n",
    "        r = self.reset_gate(x)\n",
    "        r = self.sig(r)\n",
    "        rx = r * x\n",
    "        h_ = self.backbone(rx)\n",
    "        h_ = self.tanh(h_)\n",
    "        \n",
    "        h_prev = hidden * z\n",
    "        h = (1 - z) * h_\n",
    "        out = h + h_prev\n",
    "        return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model paths\n",
    "'''\n",
    "class ConvRnn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, ConvRnn_input_size, cell_model, reccurent=RECURRENT): # arg for ConvRnn layer\n",
    "        super(ConvRnn, self).__init__()\n",
    "        self.cell_dict = {\n",
    "            'Rnn' : ConvRnnCell(in_channels, out_channels), \n",
    "            'Gru' : ConvGruCell(in_channels, out_channels), \n",
    "            'Rrn' : ConvRrnCell(in_channels, out_channels), \n",
    "            'Sru' : ConvSruCell(in_channels, out_channels), \n",
    "            'Dru' : ConvDruCell(in_channels, out_channels)\n",
    "        }\n",
    "        self.rec = reccurent\n",
    "        self.cell_model = cell_model\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.timesteps = TIMESTEPS\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_size = ConvRnn_input_size\n",
    "        self.hidden_size = (self.batch_size, self.out_channels, self.input_size, self.input_size)\n",
    "        \n",
    "        self.ConvRnn_layer = self.cell_dict[self.cell_model]\n",
    "        self.init_hidden = torch.zeros(self.hidden_size).to(device)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_cells = None\n",
    "        x_list = []\n",
    "\n",
    "        x = x.reshape(self.batch_size, self.timesteps, self.in_channels, self.input_size, self.input_size)\n",
    "        x = x.permute(1, 0, 2, 3, 4)\n",
    "        if self.rec == True:\n",
    "            for i in range(self.timesteps):\n",
    "                if x_cells is None:\n",
    "                    x_cells, hidden = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_cells)\n",
    "                else:\n",
    "                    x_i, hidden = self.ConvRnn_layer(x[i], hidden)\n",
    "                    x_list.append(x_i)\n",
    "        elif self.rec == False:\n",
    "            for i in range(self.timesteps):\n",
    "                if x_cells is None:\n",
    "                    x_cells, _ = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_cells)\n",
    "                else:\n",
    "                    x_i, _ = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_i)\n",
    "        else:\n",
    "            print('RECURRENT can be only True or False')\n",
    "            quit()\n",
    "        x_cells = torch.stack(x_list)\n",
    "        x_cells = x_cells.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        x_cells = x_cells.reshape(-1, self.out_channels, self.input_size, self.input_size)\n",
    "        return x_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRnnRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels ,ConvRnn_input_size, cell_model):\n",
    "        super(ConvRnnRelu, self).__init__()\n",
    "        self.cell_model = cell_model\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_size = ConvRnn_input_size\n",
    "        self.convrnnrelu = nn.Sequential(ConvRnn(self.in_channels, self.out_channels, \n",
    "                                                 self.input_size, self.cell_model),\n",
    "                                         nn.ReLU()\n",
    "                                         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convrnnrelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRelu, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.convrelu = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "                                      nn.ReLU()\n",
    "                                      )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convrelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaxPool, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.maxpool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpAndCat(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(UpAndCat, self).__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x_up, x_cat):\n",
    "        out = self.up(x_up)\n",
    "        out = torch.cat([out, x_cat], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model head\n",
    "'''\n",
    "class UNetDesigner(nn.Module):    \n",
    "    def __init__(self, d1, d2, d3, b_, u1, u2, u3, cell_model,\n",
    "                 input_size=INPUT_SIZE, input_channels=INPUT_CHANNELS, num_classes=NUM_CLASSES):\n",
    "        super(UNetDesigner, self).__init__()\n",
    "        self.cell_model = cell_model\n",
    "        self.num_classes = NUM_CLASSES\n",
    "        self.d1, self.d2, self.d3, self.b, self.u1, self.u2, self.u3 = d1, d2, d3, b_, u1, u2, u3\n",
    "        self.input_size = input_size\n",
    "        self.input_chennels = input_channels\n",
    "        self.ch_list = [self.input_chennels, 32, 64, 128, 256]\n",
    "        self.input_x2 = int(self.input_size / 2)\n",
    "        self.input_x4 = int(self.input_size / 4)\n",
    "        self.input_x8 = int(self.input_size / 8)\n",
    "\n",
    "         ##### Down_1 layer ##### input_size = 128\n",
    "        if self.d1 == True:\n",
    "            self.down1 = nn.Sequential(ConvRnnRelu(self.ch_list[0], self.ch_list[1],    # Channels\n",
    "                                                   self.input_size, self.cell_model),               \n",
    "                                       ConvRelu(self.ch_list[1], self.ch_list[1])                   \n",
    "                                       )                                                # 1  -->32\n",
    "        else:                                                                           # 32 -->32\n",
    "            self.down1 = nn.Sequential(ConvRelu(self.ch_list[0], self.ch_list[1]),\n",
    "                                       ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                       )\n",
    "        self.down1_pool = MaxPool()\n",
    "\n",
    "         ##### Down_2 layer ##### input_size = 64\n",
    "        if self.d2 == True:\n",
    "            self.down2 = nn.Sequential(ConvRnnRelu(self.ch_list[1], self.ch_list[2],\n",
    "                                                   self.input_x2, self.cell_model),\n",
    "                                       ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                       )                                                # 32 -->64\n",
    "        else:                                                                           # 64 -->64\n",
    "            self.down2 = nn.Sequential(ConvRelu(self.ch_list[1], self.ch_list[2]),\n",
    "                                       ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                       )\n",
    "        self.down2_pool = MaxPool()\n",
    "\n",
    "         ##### Down_3 layer ##### input_size = 32\n",
    "        if self.d3 == True:\n",
    "            self.down3 = nn.Sequential(ConvRnnRelu(self.ch_list[2], self.ch_list[3], \n",
    "                                                   self.input_x4, self.cell_model),\n",
    "                                       ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                       )                                                # 64 -->128\n",
    "        else:                                                                           # 128-->128\n",
    "            self.down3 = nn.Sequential(ConvRelu(self.ch_list[2], self.ch_list[3]),\n",
    "                                       ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                       )\n",
    "        self.down3_pool = MaxPool()\n",
    "\n",
    "         ##### Bottom layer ##### input_size = 16\n",
    "        if self.b == True:\n",
    "            self.bottom = nn.Sequential(ConvRnnRelu(self.ch_list[3], self.ch_list[4], \n",
    "                                                    self.input_x8, self.cell_model),\n",
    "                                        ConvRelu(self.ch_list[4], self.ch_list[4])\n",
    "                                        )                                               # 128-->256\n",
    "        else:                                                                           # 256-->256\n",
    "            self.bottom = nn.Sequential(ConvRelu(self.ch_list[3], self.ch_list[4]),\n",
    "                                        ConvRelu(self.ch_list[4], self.ch_list[4])\n",
    "                                        )\n",
    "\n",
    "         ##### Up_3 layer #####\n",
    "        self.up_cat_3 = UpAndCat()\n",
    "        if self.u3 == True:\n",
    "            self.up_conv_3 = nn.Sequential(ConvRnnRelu(self.ch_list[4]+self.ch_list[3], \n",
    "                                                       self.ch_list[3], \n",
    "                                                       self.input_x4, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                           )                                            # 394-->128\n",
    "        else:                                                                           # 128-->128\n",
    "            self.up_conv_3 = nn.Sequential(ConvRelu(self.ch_list[4]+self.ch_list[3], \n",
    "                                                    self.ch_list[3]),\n",
    "                                           ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                           )\n",
    "\n",
    "         ##### Up_2 layer #####\n",
    "        self.up_cat_2 = UpAndCat()\n",
    "        if self.u2 == True:\n",
    "            self.up_conv_2 = nn.Sequential(ConvRnnRelu(self.ch_list[3]+self.ch_list[2], \n",
    "                                                       self.ch_list[2], \n",
    "                                                       self.input_x2, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                           )                                            # 192-->64\n",
    "        else:                                                                           # 64 -->64\n",
    "            self.up_conv_2 = nn.Sequential(ConvRelu(self.ch_list[3]+self.ch_list[2], \n",
    "                                                    self.ch_list[2]),\n",
    "                                           ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                           )\n",
    "\n",
    "         ##### Up_1 layer #####\n",
    "        self.up_cat_1 = UpAndCat()\n",
    "        if self.u1 == True:\n",
    "            self.up_conv_1 = nn.Sequential(ConvRnnRelu(self.ch_list[2]+self.ch_list[1], \n",
    "                                                       self.ch_list[1], \n",
    "                                                       self.input_size, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                           )                                            # 96 -->32\n",
    "        else:                                                                           # 32 -->32\n",
    "            self.up_conv_1 = nn.Sequential(ConvRelu(self.ch_list[2]+self.ch_list[1], \n",
    "                                                    self.ch_list[1]),\n",
    "                                           ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                           )\n",
    "\n",
    "         ##### Final layer #####\n",
    "        self.final = nn.Sequential(nn.Conv2d(self.ch_list[1], self.num_classes, kernel_size=1),\n",
    "\n",
    "                                   )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, self.input_chennels, self.input_size, self.input_size)\n",
    "        # print(x.shape)\n",
    "        down1_feat = self.down1(x)\n",
    "        pool1 = self.down1_pool(down1_feat)\n",
    "        # print(pool1.shape)\n",
    "        down2_feat = self.down2(pool1)\n",
    "        pool2 = self.down2_pool(down2_feat)\n",
    "        # print(pool2.shape)\n",
    "        down3_feat = self.down3(pool2)\n",
    "        pool3 = self.down3_pool(down3_feat)\n",
    "        # print(pool3.shape)\n",
    "        bottom_feat = self.bottom(pool3)\n",
    "        # print(bottom_feat.shape)\n",
    "        up_feat3 = self.up_cat_3(bottom_feat, down3_feat)\n",
    "        up_feat3 = self.up_conv_3(up_feat3)\n",
    "        \n",
    "        up_feat2 = self.up_cat_2(up_feat3, down2_feat)\n",
    "        up_feat2 = self.up_conv_2(up_feat2)\n",
    "        \n",
    "        up_feat1 = self.up_cat_1(up_feat2, down1_feat)\n",
    "        up_feat1 = self.up_conv_1(up_feat1)\n",
    "        \n",
    "        out = self.final(up_feat1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetDesigner(d1=PARAMETERS['d1'], \n",
    "                     d2=PARAMETERS['d2'], \n",
    "                     d3=PARAMETERS['d3'], \n",
    "                     b_=PARAMETERS['b_'], \n",
    "                     u1=PARAMETERS['u1'], \n",
    "                     u2=PARAMETERS['u2'], \n",
    "                     u3=PARAMETERS['u3'], \n",
    "                     cell_model=PARAMETERS['cell_model']\n",
    "                     )\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loss\n",
    "'''\n",
    "def l2_loss(x, y, d):\n",
    "    d = d.reshape(x.shape)\n",
    "    y = y.reshape(x.shape)\n",
    "    x = torch.sigmoid(x)\n",
    "    out = ((x - y*d**2)**2).sum()\n",
    "    return out\n",
    "\n",
    "def bce_loss(x, y, d):\n",
    "    y = y.reshape(x.shape)\n",
    "    return F.binary_cross_entropy_with_logits(x, y)\n",
    "\n",
    "def dice_loss(x, y, d):\n",
    "    d = d.reshape(x.shape)\n",
    "    y = y.reshape(x.shape)\n",
    "    x = torch.sigmoid(x)\n",
    "    intersection = (x * y*d**2).sum(dim=2).sum(dim=2)\n",
    "    x_sum = (x*d**2).sum(dim=2).sum(dim=2)\n",
    "    y_sum = (y*d**2).sum(dim=2).sum(dim=2)\n",
    "    dice_loss = 1 - (2*intersection / (x_sum + y_sum))\n",
    "    return dice_loss.mean()\n",
    "\n",
    "def combo_loss(x, y, d, bce_weight=0.5):\n",
    "    combo_loss = bce_weight * bce_loss(x, y, d) + (1 - bce_weight) * dice_loss(x, y, d)\n",
    "    return combo_loss\n",
    "\n",
    "def l2_combo_loss(x, y, d):\n",
    "    l2_combo_loss = l2_loss(x, y, d) * bce_loss(x, y, d)\n",
    "    return l2_combo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Metric\n",
    "'''\n",
    "def IoU_metric(x, y):\n",
    "    y = y.reshape(x.shape)\n",
    "    x = torch.sigmoid(x)\n",
    "    intersection = (x * y).sum(dim=2).sum(dim=2)\n",
    "    x_sum = x.sum(dim=2).sum(dim=2)\n",
    "    y_sum = y.sum(dim=2).sum(dim=2)\n",
    "    IoU_metric = intersection / (x_sum + y_sum - intersection)\n",
    "    return IoU_metric.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** epoch:  0 **********\n",
      "train l2_norm:  0.9656745276667855\n",
      "val l2_norm:  0.7288043399651846\n",
      "********** epoch:  1 **********\n",
      "train l2_norm:  0.9673907187851992\n",
      "val l2_norm:  0.7276498476664225\n",
      "********** epoch:  2 **********\n",
      "train l2_norm:  0.9691255986690521\n",
      "val l2_norm:  0.7244986991087595\n",
      "********** epoch:  3 **********\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-98bab5e26809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mmean_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adam does not support sparse gradients, please consider SparseAdam instead'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train\n",
    "'''\n",
    "val_loss = []\n",
    "for epoch in range(NUM_EPOCHS):# NUM_EPOCHS = 125\n",
    "    print('*'*10, 'epoch: ', epoch, '*'*10)\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            loss_list = []\n",
    "            model.train()\n",
    "            for i, data in enumerate(data_loaders[phase]):\n",
    "                input, label, depth = data\n",
    "                input = input.to(device)\n",
    "                label = label.to(device)\n",
    "                depth = depth.to(device)\n",
    "                output = model(input)\n",
    "                loss = l2_combo_loss(output, label, depth)\n",
    "                metric = IoU_metric(output, label)\n",
    "                loss_list.append(metric.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            mean_loss = sum(loss_list) / len(loss_list)\n",
    "            print(\"train l2_norm: \", mean_loss)\n",
    "        elif phase == 'valid':\n",
    "            loss_list = []\n",
    "            model.eval()\n",
    "            for i, data in enumerate(data_loaders[phase]):\n",
    "                input, label, depth = data\n",
    "                input = input.to(device)\n",
    "                label = label.to(device)\n",
    "                depth = depth.to(device)\n",
    "                output = model(input)\n",
    "                loss = l2_combo_loss(output, label, depth)\n",
    "                metric = IoU_metric(output, label)\n",
    "                loss_list.append(metric.item())\n",
    "            mean_loss = sum(loss_list) / len(loss_list)\n",
    "            print(\"val l2_norm: \", mean_loss)\n",
    "            val_loss.append(mean_loss)\n",
    "print('Maximum Valid metric: ', max(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5109e-06, 4.1041e-13, 4.8416e-15, 1.5783e-03, 3.3738e-06, 6.2164e-11,\n",
       "        6.9071e-11, 1.5043e-11, 1.2278e-07, 5.5282e-06, 3.2199e-06, 4.3408e-06,\n",
       "        4.6614e-02, 9.9165e-01, 9.9984e-01, 9.9957e-01, 9.9926e-01, 9.9958e-01,\n",
       "        9.1037e-01, 9.2755e-04, 4.4366e-09, 3.7644e-11, 5.3088e-13, 1.5597e-11,\n",
       "        2.2032e-07, 5.2796e-02, 4.4261e-04, 1.0326e-06, 1.0478e-05, 3.5807e-02,\n",
       "        2.5394e-01, 1.6440e-03, 3.4225e-06, 3.6297e-04, 2.7492e-01, 7.0529e-01,\n",
       "        7.3408e-01, 6.2437e-01, 3.8995e-02, 2.1106e-06, 2.1283e-07, 2.8574e-06,\n",
       "        1.9644e-07, 1.1554e-06, 7.3777e-05, 6.7696e-05, 4.2420e-05, 7.7648e-08,\n",
       "        6.0372e-09, 9.3723e-06, 1.2430e-05, 8.7346e-11, 1.6024e-11, 4.2472e-01,\n",
       "        9.9972e-01, 1.0277e-07, 1.1610e-08, 8.2401e-08, 1.9060e-08, 2.4889e-08,\n",
       "        1.2522e-06, 9.3842e-04, 5.0050e-01, 7.4497e-01, 9.9974e-01, 1.0000e+00,\n",
       "        1.0000e+00, 1.0000e+00, 9.9998e-01, 5.7146e-02, 1.8432e-05, 1.4820e-03,\n",
       "        8.0038e-02, 7.3586e-01, 9.7660e-01, 8.5245e-01, 3.7212e-02, 3.3552e-03,\n",
       "        1.3649e-02, 2.0708e-07, 1.2960e-07, 5.3824e-05, 1.0917e-04, 5.1254e-05,\n",
       "        8.1951e-03, 7.2272e-01, 9.0564e-01, 9.9982e-01, 9.9998e-01, 9.9970e-01,\n",
       "        9.9778e-01, 9.9954e-01, 9.9996e-01, 1.0000e+00, 9.9635e-01, 4.2511e-01,\n",
       "        6.1011e-01, 5.5309e-01, 2.7534e-01, 3.9807e-03, 4.8590e-04, 3.2419e-02,\n",
       "        6.9415e-02, 9.8075e-01, 9.9561e-01, 9.9925e-01, 3.6505e-03, 6.5679e-04,\n",
       "        2.8429e-03, 7.6061e-06, 2.1346e-04, 2.1108e-05, 6.8373e-08, 2.6602e-13,\n",
       "        5.1213e-16, 1.4466e-13, 8.5419e-10, 5.6742e-06, 8.8953e-04, 9.0368e-02,\n",
       "        3.0651e-02, 2.1517e-04, 5.9133e-05, 2.6275e-01, 2.2167e-03, 1.2018e-02,\n",
       "        2.1126e-04, 3.7337e-07], device='cuda:1', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(output[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF733A1750>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil((output[0][0].cpu()>0).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF74998110>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil(F.sigmoid(output[0][1].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showw(object, i):\n",
    "    imgs = object[i].cpu()\n",
    "    img = F.sigmoid(imgs[2][1])\n",
    "    return to_pil(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_inp = []\n",
    "list_out = []\n",
    "for i, data in enumerate(test_loader):\n",
    "    input = data\n",
    "    input = input.to(device)\n",
    "    test_output = model(input)\n",
    "    list_inp.append(input)\n",
    "    list_out.append(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageSequence\n",
    "index = 3 \n",
    "for i in range(len(list_out)):\n",
    "    test_out = showw(list_out, i)\n",
    "    test_out.save(\"../r_unet/data/test_output/frame%d.png\" % index)\n",
    "    index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
