{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images_val', 'labels_val', 'test', 'labels', 'images']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import scipy.ndimage.morphology as morph\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "os.listdir('../r_unet/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cell_model = {\n",
    "    'Rnn' : ConvRnnCell(in_channels, out_channels), \n",
    "    'Gru' : ConvGruCell(in_channels, out_channels), \n",
    "    'Rrn' : ConvRrnCell(in_channels, out_channels), \n",
    "    'Sru' : ConvSruCell(in_channels, out_channels), \n",
    "    'Dru' : ConvDruCell(in_channels, out_channels)\n",
    "}\n",
    "\"\"\"\n",
    "RECURRENT = True\n",
    "PARAMETERS = {\n",
    "    'd1':False, \n",
    "    'd2':False, \n",
    "    'd3':False, \n",
    "    'b_':True, \n",
    "    'u1':False, \n",
    "    'u2':False, \n",
    "    'u3':False, \n",
    "    'cell_model':'Sru'\n",
    "}\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "# arguments\n",
    "TIMESTEPS = 3\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 125\n",
    "INPUT_SIZE = 128\n",
    "INPUT_CHANNELS = 1\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                              transforms.Resize((INPUT_SIZE, INPUT_SIZE), interpolation = 0),\n",
    "                              transforms.ToTensor()\n",
    "                              ])\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# decive\n",
    "device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way to the data folders\n",
    "FOLDER_DATA = \"../r_unet/data/images\"\n",
    "FOLDER_MASK = \"../r_unet/data/labels\"\n",
    "FOLDER_TEST = \"../r_unet/data/test\"\n",
    "FOLDER_DATA_VAL = \"../r_unet/data/images_val\"\n",
    "FOLDER_MASK_VAL = \"../r_unet/data/labels_val\"\n",
    "\n",
    "FILE_NAMES = sorted(os.listdir('../r_unet/data/images'))\n",
    "FILE_NAMES_VAL = sorted(os.listdir('../r_unet/data/images_val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(object):\n",
    "    label1 = (object==0).float()\n",
    "    label2 = (label1==0).float()\n",
    "    labels = torch.stack([label1, label2], dim=1).squeeze()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_data = FOLDER_DATA\n",
    "        self.folder_mask = FOLDER_MASK\n",
    "        self.file_names = FILE_NAMES\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + self.file_names[idx+i])))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(get_labels(transform(Image.open(self.folder_mask + '/' + self.file_names[idx+i]))))\n",
    "        gif_mask = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            img = Image.open(self.folder_mask + '/' + self.file_names[idx+i])\n",
    "            img = img.resize((INPUT_SIZE, INPUT_SIZE), resample=Image.NEAREST)\n",
    "            gif_list.append(to_tensor(morph.distance_transform_edt(np.asarray(img)/255)))\n",
    "        gif_depth = torch.stack(gif_list)\n",
    "        return gif_data, gif_mask, gif_depth\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "\n",
    "\n",
    "class ValMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_data = FOLDER_DATA_VAL\n",
    "        self.folder_mask = FOLDER_MASK_VAL\n",
    "        self.file_names = FILE_NAMES_VAL\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_data + '/' + self.file_names[idx+i])))\n",
    "        gif_data = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(get_labels(transform(Image.open(self.folder_mask + '/' + self.file_names[idx+i]))))\n",
    "        gif_mask = torch.stack(gif_list).squeeze(dim=2)\n",
    "        gif_list.clear()\n",
    "        for i in range(self.time):\n",
    "            img = Image.open(self.folder_mask + '/' + self.file_names[idx+i])\n",
    "            img = img.resize((INPUT_SIZE, INPUT_SIZE), resample=Image.NEAREST)\n",
    "            gif_list.append(to_tensor(morph.distance_transform_edt(np.asarray(img)/255)))\n",
    "        gif_depth = torch.stack(gif_list)\n",
    "        return gif_data, gif_mask, gif_depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1\n",
    "\n",
    "\n",
    "class TestMedData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__\n",
    "        self.time = TIMESTEPS\n",
    "        self.folder_test = FOLDER_TEST\n",
    "        self.file_names = FILE_NAMES + FILE_NAMES_VAL\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gif_list = []\n",
    "        for i in range(self.time):\n",
    "            gif_list.append(transform(Image.open(self.folder_test + '/' + self.file_names[idx+i])))\n",
    "        gif_test = torch.stack(gif_list)\n",
    "        gif_list.clear()\n",
    "        return gif_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names) - self.time + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainMedData()\n",
    "valid_dataset = ValMedData()\n",
    "test_dataset = TestMedData()\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=1,\n",
    "                          shuffle=False)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=1,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=1,\n",
    "                         num_workers=1,\n",
    "                         shuffle=False)\n",
    "\n",
    "data_loaders = {\n",
    "    'train' : train_loader,\n",
    "    'valid' : valid_loader,\n",
    "    'test' : test_loader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'valid': len(valid_dataset),\n",
    "    'test': len(test_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRnnCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRnnCell, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "             \n",
    "    def forward(self, x, hidden):\n",
    "        out = torch.cat([x, hidden],dim=1)\n",
    "        out = self.conv1(out)\n",
    "        hidden = out\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGruCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvGruCell, self).__init__()\n",
    "        self.conv_for_input = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_for_hidden = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_2x_update = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        self.conv_2x_reset = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_2x_update(input)\n",
    "        update_gate = self.sig((update_gate)) ### output after update gate\n",
    "        reset_gate = self.conv_2x_reset(input)\n",
    "        reset_gate = self.sig((reset_gate)) ### output after reset gate\n",
    "        \n",
    "        \n",
    "        memory_for_input = self.conv_for_input(x)\n",
    "        memory_for_hidden = self.conv_for_hidden(hidden)# просто хидден\n",
    "\n",
    "        memory_content = memory_for_input + (reset_gate * memory_for_hidden) ### output for reset gate(affects how the reset gate do work)\n",
    "        memory_content = self.relu(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvUrnCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvUrnCell, self).__init__()\n",
    "        self.conv_for_input = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_for_hidden = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_2x_update = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        self.conv_2x_reset = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_2x_update(input)\n",
    "        update_gate = self.sig((update_gate)) ### output after update gate\n",
    "        reset_gate = self.conv_2x_reset(input)\n",
    "        reset_gate = self.sig((reset_gate)) ### output after reset gate\n",
    "        \n",
    "        \n",
    "        memory_for_input = self.conv_for_input(x)\n",
    "        memory_for_hidden = self.conv_for_hidden(hidden)# просто хидден\n",
    "\n",
    "        memory_content = memory_for_input + (reset_gate * memory_for_hidden) ### output for reset gate(affects how the reset gate do work)\n",
    "        memory_content = self.relu(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRrnCell(nn.Module):    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRrnCell, self).__init__()\n",
    "        self.conv_for_input = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_for_hidden = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_2x_update = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        self.conv_2x_reset = nn.Sequential(nn.Conv2d(in_channels+out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "     \n",
    "    def forward(self, x, hidden):\n",
    "        input = torch.cat([x, hidden],dim=1)\n",
    "\n",
    "        update_gate = self.conv_2x_update(input)\n",
    "        update_gate = self.sig((update_gate)) \n",
    "        \n",
    "        memory_for_input = self.conv_for_input(x)\n",
    "        memory_for_hidden = hidden\n",
    "\n",
    "        memory_content = memory_for_input + memory_for_hidden\n",
    "        memory_content = self.relu(memory_content)\n",
    "\n",
    "        hidden = (update_gate * hidden) + ((1 - update_gate) * memory_content) # torch.ones(input_size, hidden_size)\n",
    "\n",
    "        return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSruCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvSruCell, self).__init__()\n",
    "        self.update_gate = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.backbone = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        z = self.update_gate(x)\n",
    "        z = self.sig(z)\n",
    "        \n",
    "        h_ = self.backbone(x)\n",
    "        h_ = self.tanh(h_)\n",
    "        \n",
    "        h_prev = hidden * z\n",
    "        h = (1 - z) * h_\n",
    "        out = h + h_prev\n",
    "        return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDruCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvDruCell, self).__init__()\n",
    "        self.update_gate = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.reset_gate = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.backbone = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        z = self.update_gate(x)\n",
    "        z = self.sig(z)\n",
    "        \n",
    "        r = self.reset_gate(x)\n",
    "        r = self.sig(r)\n",
    "        rx = r * x\n",
    "        h_ = self.backbone(rx)\n",
    "        h_ = self.tanh(h_)\n",
    "        \n",
    "        h_prev = hidden * z\n",
    "        h = (1 - z) * h_\n",
    "        out = h + h_prev\n",
    "        return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRnn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, ConvRnn_input_size, cell_model, reccurent=RECURRENT): # arg for ConvRnn layer\n",
    "        super(ConvRnn, self).__init__()\n",
    "        self.cell_dict = {\n",
    "            'Rnn' : ConvRnnCell(in_channels, out_channels), \n",
    "            'Gru' : ConvGruCell(in_channels, out_channels), \n",
    "            'Rrn' : ConvRrnCell(in_channels, out_channels), \n",
    "            'Sru' : ConvSruCell(in_channels, out_channels), \n",
    "            'Dru' : ConvDruCell(in_channels, out_channels)\n",
    "        }\n",
    "        self.rec = reccurent\n",
    "        self.cell_model = cell_model\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.timesteps = TIMESTEPS\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_size = ConvRnn_input_size\n",
    "        self.hidden_size = (self.batch_size, self.out_channels, self.input_size, self.input_size)\n",
    "        \n",
    "        self.ConvRnn_layer = self.cell_dict[self.cell_model]\n",
    "        self.init_hidden = torch.zeros(self.hidden_size).to(device)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_cells = None\n",
    "        x_list = []\n",
    "\n",
    "        x = x.reshape(self.batch_size, self.timesteps, self.in_channels, self.input_size, self.input_size)\n",
    "        x = x.permute(1, 0, 2, 3, 4)\n",
    "        if self.rec == True:\n",
    "            for i in range(self.timesteps):\n",
    "                if x_cells is None:\n",
    "                    x_cells, hidden = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_cells)\n",
    "                else:\n",
    "                    x_i, hidden = self.ConvRnn_layer(x[i], hidden)\n",
    "                    x_list.append(x_i)\n",
    "        elif self.rec == False:\n",
    "            for i in range(self.timesteps):\n",
    "                if x_cells is None:\n",
    "                    x_cells, _ = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_cells)\n",
    "                else:\n",
    "                    x_i, _ = self.ConvRnn_layer(x[i], self.init_hidden)\n",
    "                    x_list.append(x_i)\n",
    "        else:\n",
    "            print('RECURRENT can be only True or False')\n",
    "            quit()\n",
    "        x_cells = torch.stack(x_list)\n",
    "        x_cells = x_cells.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        x_cells = x_cells.reshape(-1, self.out_channels, self.input_size, self.input_size)\n",
    "        return x_cells  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRnnRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels ,ConvRnn_input_size, cell_model):\n",
    "        super(ConvRnnRelu, self).__init__()\n",
    "        self.cell_model = cell_model\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_size = ConvRnn_input_size\n",
    "        self.convrnnrelu = nn.Sequential(ConvRnn(self.in_channels, self.out_channels, \n",
    "                                                 self.input_size, self.cell_model),\n",
    "                                         nn.ReLU()\n",
    "                                         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convrnnrelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvRelu, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.convrelu = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding=1),\n",
    "                                      nn.ReLU()\n",
    "                                      )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convrelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaxPool, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.maxpool(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpAndCat(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(UpAndCat, self).__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x_up, x_cat):\n",
    "        out = self.up(x_up)\n",
    "        out = torch.cat([out, x_cat], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDesigner(nn.Module):    \n",
    "    def __init__(self, d1, d2, d3, b_, u1, u2, u3, cell_model,\n",
    "                 input_size=INPUT_SIZE, input_channels=INPUT_CHANNELS, num_classes=NUM_CLASSES):\n",
    "        super(UNetDesigner, self).__init__()\n",
    "        self.cell_model = cell_model\n",
    "        self.num_classes = NUM_CLASSES\n",
    "        self.d1, self.d2, self.d3, self.b, self.u1, self.u2, self.u3 = d1, d2, d3, b_, u1, u2, u3\n",
    "        self.input_size = input_size\n",
    "        self.input_chennels = input_channels\n",
    "        self.ch_list = [self.input_chennels, 32, 64, 128, 256]\n",
    "        self.input_x2 = int(self.input_size / 2)\n",
    "        self.input_x4 = int(self.input_size / 4)\n",
    "        self.input_x8 = int(self.input_size / 8)\n",
    "\n",
    "         ##### Down_1 layer ##### input_size = 128\n",
    "        if self.d1 == True:\n",
    "            self.down1 = nn.Sequential(ConvRnnRelu(self.ch_list[0], self.ch_list[1],    # Channels\n",
    "                                                   self.input_size, self.cell_model),               \n",
    "                                       ConvRelu(self.ch_list[1], self.ch_list[1])                   \n",
    "                                       )                                                # 1  -->32\n",
    "        else:                                                                           # 32 -->32\n",
    "            self.down1 = nn.Sequential(ConvRelu(self.ch_list[0], self.ch_list[1]),\n",
    "                                       ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                       )\n",
    "        self.down1_pool = MaxPool()\n",
    "\n",
    "         ##### Down_2 layer ##### input_size = 64\n",
    "        if self.d2 == True:\n",
    "            self.down2 = nn.Sequential(ConvRnnRelu(self.ch_list[1], self.ch_list[2],\n",
    "                                                   self.input_x2, self.cell_model),\n",
    "                                       ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                       )                                                # 32 -->64\n",
    "        else:                                                                           # 64 -->64\n",
    "            self.down2 = nn.Sequential(ConvRelu(self.ch_list[1], self.ch_list[2]),\n",
    "                                       ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                       )\n",
    "        self.down2_pool = MaxPool()\n",
    "\n",
    "         ##### Down_3 layer ##### input_size = 32\n",
    "        if self.d3 == True:\n",
    "            self.down3 = nn.Sequential(ConvRnnRelu(self.ch_list[2], self.ch_list[3], \n",
    "                                                   self.input_x4, self.cell_model),\n",
    "                                       ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                       )                                                # 64 -->128\n",
    "        else:                                                                           # 128-->128\n",
    "            self.down3 = nn.Sequential(ConvRelu(self.ch_list[2], self.ch_list[3]),\n",
    "                                       ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                       )\n",
    "        self.down3_pool = MaxPool()\n",
    "\n",
    "         ##### Bottom layer ##### input_size = 16\n",
    "        if self.b == True:\n",
    "            self.bottom = nn.Sequential(ConvRnnRelu(self.ch_list[3], self.ch_list[4], \n",
    "                                                    self.input_x8, self.cell_model),\n",
    "                                        ConvRelu(self.ch_list[4], self.ch_list[4])\n",
    "                                        )                                               # 128-->256\n",
    "        else:                                                                           # 256-->256\n",
    "            self.bottom = nn.Sequential(ConvRelu(self.ch_list[3], self.ch_list[4]),\n",
    "                                        ConvRelu(self.ch_list[4], self.ch_list[4])\n",
    "                                        )\n",
    "\n",
    "         ##### Up_3 layer #####\n",
    "        self.up_cat_3 = UpAndCat()\n",
    "        if self.u3 == True:\n",
    "            self.up_conv_3 = nn.Sequential(ConvRnnRelu(self.ch_list[4]+self.ch_list[3], \n",
    "                                                       self.ch_list[3], \n",
    "                                                       self.input_x4, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                           )                                            # 394-->128\n",
    "        else:                                                                           # 128-->128\n",
    "            self.up_conv_3 = nn.Sequential(ConvRelu(self.ch_list[4]+self.ch_list[3], \n",
    "                                                    self.ch_list[3]),\n",
    "                                           ConvRelu(self.ch_list[3], self.ch_list[3])\n",
    "                                           )\n",
    "\n",
    "         ##### Up_2 layer #####\n",
    "        self.up_cat_2 = UpAndCat()\n",
    "        if self.u2 == True:\n",
    "            self.up_conv_2 = nn.Sequential(ConvRnnRelu(self.ch_list[3]+self.ch_list[2], \n",
    "                                                       self.ch_list[2], \n",
    "                                                       self.input_x2, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                           )                                            # 192-->64\n",
    "        else:                                                                           # 64 -->64\n",
    "            self.up_conv_2 = nn.Sequential(ConvRelu(self.ch_list[3]+self.ch_list[2], \n",
    "                                                    self.ch_list[2]),\n",
    "                                           ConvRelu(self.ch_list[2], self.ch_list[2])\n",
    "                                           )\n",
    "\n",
    "         ##### Up_1 layer #####\n",
    "        self.up_cat_1 = UpAndCat()\n",
    "        if self.u1 == True:\n",
    "            self.up_conv_1 = nn.Sequential(ConvRnnRelu(self.ch_list[2]+self.ch_list[1], \n",
    "                                                       self.ch_list[1], \n",
    "                                                       self.input_size, self.cell_model),\n",
    "                                           ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                           )                                            # 96 -->32\n",
    "        else:                                                                           # 32 -->32\n",
    "            self.up_conv_1 = nn.Sequential(ConvRelu(self.ch_list[2]+self.ch_list[1], \n",
    "                                                    self.ch_list[1]),\n",
    "                                           ConvRelu(self.ch_list[1], self.ch_list[1])\n",
    "                                           )\n",
    "\n",
    "         ##### Final layer #####\n",
    "        self.final = nn.Sequential(nn.Conv2d(self.ch_list[1], self.num_classes, kernel_size=1),\n",
    "                                   nn.Sigmoid(),\n",
    "                                   )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, self.input_chennels, self.input_size, self.input_size)\n",
    "        # print(x.shape)\n",
    "        down1_feat = self.down1(x)\n",
    "        pool1 = self.down1_pool(down1_feat)\n",
    "        # print(pool1.shape)\n",
    "        down2_feat = self.down2(pool1)\n",
    "        pool2 = self.down2_pool(down2_feat)\n",
    "        # print(pool2.shape)\n",
    "        down3_feat = self.down3(pool2)\n",
    "        pool3 = self.down3_pool(down3_feat)\n",
    "        # print(pool3.shape)\n",
    "        bottom_feat = self.bottom(pool3)\n",
    "        # print(bottom_feat.shape)\n",
    "        up_feat3 = self.up_cat_3(bottom_feat, down3_feat)\n",
    "        up_feat3 = self.up_conv_3(up_feat3)\n",
    "        \n",
    "        up_feat2 = self.up_cat_2(up_feat3, down2_feat)\n",
    "        up_feat2 = self.up_conv_2(up_feat2)\n",
    "        \n",
    "        up_feat1 = self.up_cat_1(up_feat2, down1_feat)\n",
    "        up_feat1 = self.up_conv_1(up_feat1)\n",
    "        \n",
    "        out = self.final(up_feat1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetDesigner(d1=PARAMETERS['d1'], \n",
    "                     d2=PARAMETERS['d2'], \n",
    "                     d3=PARAMETERS['d3'], \n",
    "                     b_=PARAMETERS['b_'], \n",
    "                     u1=PARAMETERS['u1'], \n",
    "                     u2=PARAMETERS['u2'], \n",
    "                     u3=PARAMETERS['u3'], \n",
    "                     cell_model=PARAMETERS['cell_model']\n",
    "                     )\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm(x, y):\n",
    "    y = y.reshape(x.shape)\n",
    "    return (((x - y)**2).sum(dim=2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, depth, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "    #print(pred.shape, target.shape, depth.shape)\n",
    "    intersection = (pred * target * depth).sum(dim=2).sum(dim=2)\n",
    "    \n",
    "    loss = (1 - ((2. * intersection + smooth) / ((pred*depth).sum(dim=2).sum(dim=2) + (target*depth).sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** epoch:  0 **********\n",
      "train l2_norm:  18990.615678267044\n",
      "val l2_norm:  15698.726236979166\n",
      "********** epoch:  1 **********\n",
      "train l2_norm:  16510.79620916193\n",
      "val l2_norm:  14657.794921875\n",
      "********** epoch:  2 **********\n",
      "train l2_norm:  14935.797629616478\n",
      "val l2_norm:  13585.516927083334\n",
      "********** epoch:  3 **********\n",
      "train l2_norm:  13308.35165127841\n",
      "val l2_norm:  11717.088216145834\n",
      "********** epoch:  4 **********\n",
      "train l2_norm:  12503.256569602272\n",
      "val l2_norm:  12362.881184895834\n",
      "********** epoch:  5 **********\n",
      "train l2_norm:  11425.166015625\n",
      "val l2_norm:  11791.952473958334\n",
      "********** epoch:  6 **********\n",
      "train l2_norm:  10983.971013849432\n",
      "val l2_norm:  11540.871256510416\n",
      "********** epoch:  7 **********\n",
      "train l2_norm:  10833.14071377841\n",
      "val l2_norm:  10608.913899739584\n",
      "********** epoch:  8 **********\n",
      "train l2_norm:  10901.50106534091\n",
      "val l2_norm:  10933.08056640625\n",
      "********** epoch:  9 **********\n",
      "train l2_norm:  10600.523171164772\n",
      "val l2_norm:  11088.182779947916\n",
      "********** epoch:  10 **********\n",
      "train l2_norm:  10312.13809481534\n",
      "val l2_norm:  10395.893229166666\n",
      "********** epoch:  11 **********\n",
      "train l2_norm:  10400.465287642046\n",
      "val l2_norm:  10629.542317708334\n",
      "********** epoch:  12 **********\n",
      "train l2_norm:  10134.537153764204\n",
      "val l2_norm:  10606.324869791666\n",
      "********** epoch:  13 **********\n",
      "train l2_norm:  10105.029341264204\n",
      "val l2_norm:  10728.611165364584\n",
      "********** epoch:  14 **********\n",
      "train l2_norm:  9891.54696377841\n",
      "val l2_norm:  10365.261881510416\n",
      "********** epoch:  15 **********\n",
      "train l2_norm:  9697.692338423296\n",
      "val l2_norm:  10110.79443359375\n",
      "********** epoch:  16 **********\n",
      "train l2_norm:  9696.752796519886\n",
      "val l2_norm:  10432.15966796875\n",
      "********** epoch:  17 **********\n",
      "train l2_norm:  9548.38623046875\n",
      "val l2_norm:  9931.050130208334\n",
      "********** epoch:  18 **********\n",
      "train l2_norm:  9382.343483664772\n",
      "val l2_norm:  9913.218912760416\n",
      "********** epoch:  19 **********\n",
      "train l2_norm:  9262.200017755682\n",
      "val l2_norm:  9731.1826171875\n",
      "********** epoch:  20 **********\n",
      "train l2_norm:  9143.371759588068\n",
      "val l2_norm:  9286.76025390625\n",
      "********** epoch:  21 **********\n",
      "train l2_norm:  9296.381458629261\n",
      "val l2_norm:  9939.728352864584\n",
      "********** epoch:  22 **********\n",
      "train l2_norm:  9021.763716264204\n",
      "val l2_norm:  9535.357747395834\n",
      "********** epoch:  23 **********\n",
      "train l2_norm:  8883.67666903409\n",
      "val l2_norm:  9391.212565104166\n",
      "********** epoch:  24 **********\n",
      "train l2_norm:  8783.100119850853\n",
      "val l2_norm:  10016.921875\n",
      "********** epoch:  25 **********\n",
      "train l2_norm:  8931.535955255682\n",
      "val l2_norm:  9568.021809895834\n",
      "********** epoch:  26 **********\n",
      "train l2_norm:  8712.302445845171\n",
      "val l2_norm:  9366.589518229166\n",
      "********** epoch:  27 **********\n",
      "train l2_norm:  8678.702414772728\n",
      "val l2_norm:  9338.95703125\n",
      "********** epoch:  28 **********\n",
      "train l2_norm:  8561.918834339489\n",
      "val l2_norm:  8824.235188802084\n",
      "********** epoch:  29 **********\n",
      "train l2_norm:  8378.338401100853\n",
      "val l2_norm:  8707.315266927084\n",
      "********** epoch:  30 **********\n",
      "train l2_norm:  8621.208873401989\n",
      "val l2_norm:  9468.008138020834\n",
      "********** epoch:  31 **********\n",
      "train l2_norm:  8394.98184481534\n",
      "val l2_norm:  9136.52978515625\n",
      "********** epoch:  32 **********\n",
      "train l2_norm:  8329.732421875\n",
      "val l2_norm:  8872.247721354166\n",
      "********** epoch:  33 **********\n",
      "train l2_norm:  8157.394597833807\n",
      "val l2_norm:  8844.125\n",
      "********** epoch:  34 **********\n",
      "train l2_norm:  8106.297452059659\n",
      "val l2_norm:  8423.29052734375\n",
      "********** epoch:  35 **********\n",
      "train l2_norm:  7956.280517578125\n",
      "val l2_norm:  8430.574055989584\n",
      "********** epoch:  36 **********\n",
      "train l2_norm:  7920.396928267045\n",
      "val l2_norm:  8348.317220052084\n",
      "********** epoch:  37 **********\n",
      "train l2_norm:  7804.446755149148\n",
      "val l2_norm:  8672.704264322916\n",
      "********** epoch:  38 **********\n",
      "train l2_norm:  7894.455100319602\n",
      "val l2_norm:  8844.179850260416\n",
      "********** epoch:  39 **********\n",
      "train l2_norm:  7690.484974254261\n",
      "val l2_norm:  8647.683756510416\n",
      "********** epoch:  40 **********\n",
      "train l2_norm:  7689.552667791193\n",
      "val l2_norm:  8846.671549479166\n",
      "********** epoch:  41 **********\n",
      "train l2_norm:  7577.800847833807\n",
      "val l2_norm:  8616.6865234375\n",
      "********** epoch:  42 **********\n",
      "train l2_norm:  7512.218905362216\n",
      "val l2_norm:  8764.707845052084\n",
      "********** epoch:  43 **********\n",
      "train l2_norm:  7436.367587002841\n",
      "val l2_norm:  8840.343424479166\n",
      "********** epoch:  44 **********\n",
      "train l2_norm:  7405.759410511364\n",
      "val l2_norm:  8902.0673828125\n",
      "********** epoch:  45 **********\n",
      "train l2_norm:  7357.41943359375\n",
      "val l2_norm:  8996.200520833334\n",
      "********** epoch:  46 **********\n",
      "train l2_norm:  7270.366432883523\n",
      "val l2_norm:  8835.1357421875\n",
      "********** epoch:  47 **********\n",
      "train l2_norm:  7268.875599254261\n",
      "val l2_norm:  8497.1279296875\n",
      "********** epoch:  48 **********\n",
      "train l2_norm:  7215.984796697443\n",
      "val l2_norm:  8409.46923828125\n",
      "********** epoch:  49 **********\n",
      "train l2_norm:  7176.160755504261\n",
      "val l2_norm:  8243.086100260416\n",
      "********** epoch:  50 **********\n",
      "train l2_norm:  7107.736239346591\n",
      "val l2_norm:  8129.822916666667\n",
      "********** epoch:  51 **********\n",
      "train l2_norm:  6972.844793146307\n",
      "val l2_norm:  8074.119059244792\n",
      "********** epoch:  52 **********\n",
      "train l2_norm:  6946.394642223011\n",
      "val l2_norm:  8025.461669921875\n",
      "********** epoch:  53 **********\n",
      "train l2_norm:  6819.84541459517\n",
      "val l2_norm:  8036.121337890625\n",
      "********** epoch:  54 **********\n",
      "train l2_norm:  6709.330011541193\n",
      "val l2_norm:  7922.832194010417\n",
      "********** epoch:  55 **********\n",
      "train l2_norm:  6570.173406427557\n",
      "val l2_norm:  7950.698974609375\n",
      "********** epoch:  56 **********\n",
      "train l2_norm:  6448.775790127841\n",
      "val l2_norm:  8016.0771484375\n",
      "********** epoch:  57 **********\n",
      "train l2_norm:  6344.131902521307\n",
      "val l2_norm:  8218.2177734375\n",
      "********** epoch:  58 **********\n",
      "train l2_norm:  6278.04707475142\n",
      "val l2_norm:  8166.118082682292\n",
      "********** epoch:  59 **********\n",
      "train l2_norm:  6252.768821022727\n",
      "val l2_norm:  8196.901041666666\n",
      "********** epoch:  60 **********\n",
      "train l2_norm:  6187.004749644886\n",
      "val l2_norm:  7971.996500651042\n",
      "********** epoch:  61 **********\n",
      "train l2_norm:  6096.457208806818\n",
      "val l2_norm:  7936.874837239583\n",
      "********** epoch:  62 **********\n",
      "train l2_norm:  6018.937766335227\n",
      "val l2_norm:  7898.453857421875\n",
      "********** epoch:  63 **********\n",
      "train l2_norm:  5887.645396839489\n",
      "val l2_norm:  7928.576171875\n",
      "********** epoch:  64 **********\n",
      "train l2_norm:  5755.852361505682\n",
      "val l2_norm:  7893.627278645833\n",
      "********** epoch:  65 **********\n",
      "train l2_norm:  5632.30732865767\n",
      "val l2_norm:  7956.1865234375\n",
      "********** epoch:  66 **********\n",
      "train l2_norm:  5547.160289417614\n",
      "val l2_norm:  7990.604817708333\n",
      "********** epoch:  67 **********\n",
      "train l2_norm:  5463.977516867898\n",
      "val l2_norm:  8115.198893229167\n",
      "********** epoch:  68 **********\n",
      "train l2_norm:  5375.62373490767\n",
      "val l2_norm:  8120.654052734375\n",
      "********** epoch:  69 **********\n",
      "train l2_norm:  5325.543568004261\n",
      "val l2_norm:  8058.02783203125\n",
      "********** epoch:  70 **********\n",
      "train l2_norm:  5309.500355113636\n",
      "val l2_norm:  8082.684244791667\n",
      "********** epoch:  71 **********\n",
      "train l2_norm:  5302.88134765625\n",
      "val l2_norm:  8092.797281901042\n",
      "********** epoch:  72 **********\n",
      "train l2_norm:  5328.602672230114\n",
      "val l2_norm:  8173.261555989583\n",
      "********** epoch:  73 **********\n",
      "train l2_norm:  5284.013006036932\n",
      "val l2_norm:  8076.974690755208\n",
      "********** epoch:  74 **********\n",
      "train l2_norm:  5199.072265625\n",
      "val l2_norm:  8079.264567057292\n",
      "********** epoch:  75 **********\n",
      "train l2_norm:  5088.81327681108\n",
      "val l2_norm:  8357.951334635416\n",
      "********** epoch:  76 **********\n",
      "train l2_norm:  5007.856600674716\n",
      "val l2_norm:  8231.751383463541\n",
      "********** epoch:  77 **********\n",
      "train l2_norm:  4935.788685191761\n",
      "val l2_norm:  8392.195882161459\n",
      "********** epoch:  78 **********\n",
      "train l2_norm:  4995.712468927557\n",
      "val l2_norm:  8342.415364583334\n",
      "********** epoch:  79 **********\n",
      "train l2_norm:  5035.113370028409\n",
      "val l2_norm:  8426.49365234375\n",
      "********** epoch:  80 **********\n",
      "train l2_norm:  5059.303488991477\n",
      "val l2_norm:  8502.86181640625\n",
      "********** epoch:  81 **********\n",
      "train l2_norm:  5057.755859375\n",
      "val l2_norm:  8286.845947265625\n",
      "********** epoch:  82 **********\n",
      "train l2_norm:  4948.4337158203125\n",
      "val l2_norm:  8364.160970052084\n",
      "********** epoch:  83 **********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train l2_norm:  4805.25028852983\n",
      "val l2_norm:  8324.56201171875\n",
      "********** epoch:  84 **********\n",
      "train l2_norm:  4784.873135653409\n",
      "val l2_norm:  8375.40869140625\n",
      "********** epoch:  85 **********\n",
      "train l2_norm:  4698.5412264737215\n",
      "val l2_norm:  8290.611490885416\n",
      "********** epoch:  86 **********\n",
      "train l2_norm:  4698.207497336648\n",
      "val l2_norm:  8439.350911458334\n",
      "********** epoch:  87 **********\n",
      "train l2_norm:  4739.6248779296875\n",
      "val l2_norm:  8564.085123697916\n",
      "********** epoch:  88 **********\n",
      "train l2_norm:  4594.885076349432\n",
      "val l2_norm:  8296.74462890625\n",
      "********** epoch:  89 **********\n",
      "train l2_norm:  4621.9351140802555\n",
      "val l2_norm:  8254.40283203125\n",
      "********** epoch:  90 **********\n",
      "train l2_norm:  4642.075838955966\n",
      "val l2_norm:  8308.345540364584\n",
      "********** epoch:  91 **********\n",
      "train l2_norm:  4570.3560347123575\n",
      "val l2_norm:  8353.723470052084\n",
      "********** epoch:  92 **********\n",
      "train l2_norm:  4492.1572598544035\n",
      "val l2_norm:  8213.673177083334\n",
      "********** epoch:  93 **********\n",
      "train l2_norm:  4490.905428799716\n",
      "val l2_norm:  8203.406005859375\n",
      "********** epoch:  94 **********\n",
      "train l2_norm:  4520.7019153941765\n",
      "val l2_norm:  8207.336263020834\n",
      "********** epoch:  95 **********\n",
      "train l2_norm:  4440.1699551669035\n",
      "val l2_norm:  8408.373697916666\n",
      "********** epoch:  96 **********\n",
      "train l2_norm:  4586.8881503018465\n",
      "val l2_norm:  8221.833414713541\n",
      "********** epoch:  97 **********\n",
      "train l2_norm:  4521.8723255504265\n",
      "val l2_norm:  8026.010986328125\n",
      "********** epoch:  98 **********\n",
      "train l2_norm:  4347.6936146129265\n",
      "val l2_norm:  8109.043375651042\n",
      "********** epoch:  99 **********\n",
      "train l2_norm:  4304.3349720348015\n",
      "val l2_norm:  8152.379069010417\n",
      "********** epoch:  100 **********\n",
      "train l2_norm:  4238.375266335227\n",
      "val l2_norm:  8212.117838541666\n",
      "********** epoch:  101 **********\n",
      "train l2_norm:  4201.128884055398\n",
      "val l2_norm:  8206.711181640625\n",
      "********** epoch:  102 **********\n",
      "train l2_norm:  4150.317982066761\n",
      "val l2_norm:  8224.718994140625\n",
      "********** epoch:  103 **********\n",
      "train l2_norm:  3963.4131414240055\n",
      "val l2_norm:  8330.812174479166\n",
      "********** epoch:  104 **********\n",
      "train l2_norm:  3831.6801535866475\n",
      "val l2_norm:  8322.614827473959\n",
      "********** epoch:  105 **********\n",
      "train l2_norm:  3748.5505149147725\n",
      "val l2_norm:  8387.753336588541\n",
      "********** epoch:  106 **********\n",
      "train l2_norm:  3714.009421608665\n",
      "val l2_norm:  8359.20849609375\n",
      "********** epoch:  107 **********\n",
      "train l2_norm:  3718.6169877485795\n",
      "val l2_norm:  8392.123860677084\n",
      "********** epoch:  108 **********\n",
      "train l2_norm:  3680.822265625\n",
      "val l2_norm:  8496.02197265625\n",
      "********** epoch:  109 **********\n",
      "train l2_norm:  3705.443204012784\n",
      "val l2_norm:  8404.11474609375\n",
      "********** epoch:  110 **********\n",
      "train l2_norm:  3640.635320490057\n",
      "val l2_norm:  8573.920003255209\n",
      "********** epoch:  111 **********\n",
      "train l2_norm:  3579.221912730824\n",
      "val l2_norm:  8698.67236328125\n",
      "********** epoch:  112 **********\n",
      "train l2_norm:  3581.918301669034\n",
      "val l2_norm:  8686.980875651041\n",
      "********** epoch:  113 **********\n",
      "train l2_norm:  3488.628184925426\n",
      "val l2_norm:  8659.079427083334\n",
      "********** epoch:  114 **********\n",
      "train l2_norm:  3447.7567804509945\n",
      "val l2_norm:  8826.533528645834\n",
      "********** epoch:  115 **********\n",
      "train l2_norm:  3423.933271928267\n",
      "val l2_norm:  8975.553466796875\n",
      "********** epoch:  116 **********\n",
      "train l2_norm:  3419.7944113991475\n",
      "val l2_norm:  8985.049072265625\n",
      "********** epoch:  117 **********\n",
      "train l2_norm:  3440.644298206676\n",
      "val l2_norm:  8971.883951822916\n",
      "********** epoch:  118 **********\n",
      "train l2_norm:  3516.68369362571\n",
      "val l2_norm:  8881.5205078125\n",
      "********** epoch:  119 **********\n",
      "train l2_norm:  3461.8892711292615\n",
      "val l2_norm:  8852.072265625\n",
      "********** epoch:  120 **********\n",
      "train l2_norm:  3364.798029119318\n",
      "val l2_norm:  8762.550537109375\n",
      "********** epoch:  121 **********\n",
      "train l2_norm:  3318.9130859375\n",
      "val l2_norm:  9065.40576171875\n",
      "********** epoch:  122 **********\n",
      "train l2_norm:  3208.575850053267\n",
      "val l2_norm:  9196.748860677084\n",
      "********** epoch:  123 **********\n",
      "train l2_norm:  3143.437255859375\n",
      "val l2_norm:  9054.500732421875\n",
      "********** epoch:  124 **********\n",
      "train l2_norm:  3134.127763227983\n",
      "val l2_norm:  9109.816080729166\n",
      "Minimum Valid Loss:  7893.627278645833\n"
     ]
    }
   ],
   "source": [
    "val_loss = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('*'*10, 'epoch: ', epoch, '*'*10)\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            loss_list = []\n",
    "            model.train()\n",
    "            for i, data in enumerate(data_loaders[phase]):\n",
    "                input, label, depth = data\n",
    "                input = input.to(device)\n",
    "                label = label.to(device)\n",
    "                depth = depth.to(device)\n",
    "                output = model(input)\n",
    "                loss = l2_norm(output, label)\n",
    "                loss_list.append(loss.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            mean_loss = sum(loss_list) / len(loss_list)\n",
    "            print(\"train l2_norm: \", mean_loss)\n",
    "        elif phase == 'valid':\n",
    "            loss_list = []\n",
    "            model.eval()\n",
    "            for i, data in enumerate(data_loaders[phase]):\n",
    "                input, label, depth = data\n",
    "                input = input.to(device)\n",
    "                label = label.to(device)\n",
    "                depth = depth.to(device)\n",
    "                output = model(input)\n",
    "                loss = l2_norm(output, label)\n",
    "                loss_list.append(loss.item())\n",
    "            mean_loss = sum(loss_list) / len(loss_list)\n",
    "            print(\"val l2_norm: \", mean_loss)\n",
    "            val_loss.append(mean_loss)\n",
    "print('Minimum Valid Loss: ', min(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 128, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAioUlEQVR4nI17eYAUxfX/q+6ea0+WXVhY7hsRxAMvFAyeaIzRaDTyjUSNSlDxIPHAI16oiVeMhIiGqKgcoiIaFRHlUiAglxzLDcvex+zu7JzdXfU+8/uje2Zndhfzq392truq3qdevXr1rqaxbJ+bgLX5pdu31H4oKHdu+ZEwAEBWNO6Zv7ol9nqvPO/g9VU2g2tPucPc8CPD/nMuc9NWZa25/56BHk34Lnyx0dq51mbTlla4xZL1hXm6x+cRWt7SoATA0S8lgHDlv65kwBzlu6gewJdEv0zQQwxfBEDjUiKiYXG7iZHREpsKxVJANSoAPxhC99YDWCkAEwBHWm1kNbaOnZZjUM7383/xTILXefPGlC62fhxgiGYA0qzo8SPv1vR5EsAGIiqUFALE+gSbRET10lZsZc/YaJwNAHYTwBOItDgATKaIlOiqcXTjnzdcerqzCBW3wB8XERHR3QA4crogIgFAHexLpK2afTFZUHTjp+Xn0SF3CgkA7VyIG2UMAJX3PP0A0RcxAGDq0TV5ADgUbX029daZJmTFrxU+BqyZRET+HQAe9uSX+DciCWJ8TAxcLkIZg1T7fCFNVwDAx+4bd7UEK4YyKJrRo0OrUeDOTxu07hHzThIH41K2hePvz911YIyOZBIECAIwWWxsH8YZ6wtpwn1htyUAMNRtdJHMBpCIKQCwEp/tD3dBHQDqPPpAIkdiYsEI2/WPDXEASIoB2E6vtdM390ZT03At5ba/AJhZerXqjtMnk8lk8gQscdv7Xs0w0/MA4FYApkYWBYhoKI0gIqIkpLXnkPIJcprYQl9SqgmEa1saZthjyiirCZH55wTtxrxkq5eIiNrc7nnP7M8tImzUAMbNdGWdy/7EwcyD0IeyeCqt7zVq7bz65P/mQYgqlVKAPTo1o8rXTiVU3gM1M0AFv829Nc7IFgCgjcZkT8NNWm4WpJ+ir7J6FhpvR6S0z52ffvLEEEVq+nqeQ1czeG/uvzvLdi+q7PDkASrP+j+LfkiBExnSnAmA+Wp/hbnr7WszHglFGhUO1m8DwKb4XScJtnT/7uwnMa0wS1VlL5+nnr7R7LQKAEoCsI1z5lTEM3eYAkQWulEdAwA932nccq373VlsUaPczp0AuBj4BMcQAEw9+CSyNoY0ugVKaAwATM0dR/BIMSjnIjNDM75OM6PZfTohAOxE13oqVNi61u3izi8MYsU0xgagvqR4xxFtxsmycs7w++pTgmlRfgf6HQFkXE7MYDNzv6T4wVH0KXw2FWli+1D6U12SYG8n6ZzYZBIcarFVtOllbNNLJ/Zu6K67h9lHoZwO5zuZJEo6P5JE2NL+AhUtnJTc3lUXl2lERIglnQe30laqEW8uVgA48TrFXOCq6Q6PIPJOp7MBJVV6VeOpS9a6zXzr3gtPOdj+v9q9rrUtazfeEQoAEjUxAAi/r2v/JsO9BW3rWS0IAGxvnCg8d7/00aNDSyj7tq+kOcCJ9Y2Krnh9XwY9XqkLokDGqbDE83EbiLwysxGwbsgrnF9NgdT+qPt8TwNA1Si/6OXs+V+yF8xXUPSnAACwMs6AepaMDeXTdU8Gpq1aEIB9wXMfN9tmvu8NFafe7uQc9RhFQhsynsSn77gLDxGcq5mlFUu0tQ0XDPykws08gzPIsAFImpDxtMSfkNYn/pEvBJum0eAY29TLHbmdaFJoxVlCUFCllbHWg+XinYdWDBREIq9nmecnaGdBSAIgl39+kXFwInTRY98MyztaSkQiEGRJ99cAwGadrmgREQARst0JANR6hIeIiAp2tL2d0+fNkv8NACkAFvUHANge0ZqeEEFdmZHzqGBCyIwVaXeyosSyyTXHx+s5EhClAFQmAG65ncT3adtgTeDLTms9IRMep8USsKNCaLuApLt3lie4VNOOAAC6i3OVJGC7UTx1bTgBXiWiQIISGXPJOB3I+PcOQdSrKtESMy077KqYzjLRWmkCrJFrHvhzvsvo6CdtvrtA3Tf9yA8EsLZXNhysbZHcL/Daj2OpzVkGswrV7N9FCTNjqXUrcklcIQG265Q7bSYCBoD4/Q/u2ZpLASLqr/jI+qrMw5xL57tg/k+UPPPqI9QvJ18cbHxyeGGvu3bPJRIe4bGYAXDd+u8jtQMpy09ggG8Tot/rrcrB1cEMYOb4RNICBtEdbM/2NAMtByLt55BbLiDN+amm9+w34YZFxOrboQFNkGe0ToYOoFzXmwCFqtnNzGYx9dvdwVMAHhJEOcGuZUARXbznkzE5myXAxV6pZMy2mTnevPkfs/9264L7PfSqw2P7chJ5txNg7ZtV1m82s3qutCAGQHbz14an9Br22obXR3TTe+uk9d/W8XbjJfk9urjxVMwmigOoJkf/GQMPH76lu5FhPlIf3XChFxGJ/gSErx17XRwAq9UBMSnC8oAgom4Dcg3N86sqhrzJoxcuqYpmrzje2TQGEDMoBAD17r2ykZ4n0rTu24LbHn1l1k03nJrrH5Kru1aDQVS8jKCGDLl1Z4TBdovio4HAsAKiZmbzwNGq+roYA0BsRsA3dkkHL7BEi3UGsMI9/M84t4haRDl7AA46vg0D8t+5eaIFQQC7iYbUSpJ/8e1ngG1OKABLDfJcLoEMtc5QFbF5/qEdvDHTJ851DQibAcA88NEMnfIYAB6gwlpVPmQgOTZ1Y/t2xQuH5xYf2c+QASpZJG0K3rvC3b9WBeB6+mPKb2inxdaeZ3v5OslBWUm3q1/ffvCb25/eva++oqaIiEjzfQigKe0hLENq7W67RnwqLfuDsX+Z1oOM6/JHUiIl42YtA4ryOvMVQLDxSW1fR7Fv8WsOFc3ruhqkDynNDatDgu5RMUHC//dQBwCKShRDCaH7dSIio93tONKgwNuoo8XlMhkqL39LBx5IKo4rVk0f9Code0Y3j07kyblsW0HB61Mov+EjMZYRN99zdsfdTzYvJAXYGq19O2aFYgDSN75ZIxkc7OQGpNuiLKFTAI7SR46BG6NArckNOb7qqFShiWeMCPgCRhyA3fqqAmCuLm+WDEAem14JwKJbGUCtlQGA4yYAKE83tF9dWS2hO7aNY/pKm7fme253BZOKbMDW/AyAF4vTbiSRAACuf7EuYTdHzHDcZoDtA8MAYIejJfZyBgDlblNYNJ4AAN9Po9MAoI72E90XCipbfSAW30/PW+DjtBAA2DgXilzL4aNlx++7+RtpSZNlAkC9iADIo11wfZUUADsd0yjs2xV1AHxEUFX6v8We6xjW4RGa8ApvvrYloVQP4bKjBaAc5/eT35evrdu68Otq0zHFleZ/7jKi9x9YeCzk6BUHQGxnWstcr9ecAMGxHv4cV0SZ6HxHIpu7n7VGvtmvyjJj2noXQBtA+wEA1qg7bfAtPaKxsMvhXRoROatlBrjCAXC4Ir3OldpbJwAQ6bX05J4MFfl2A7Vbq2WlwGahoK7SHHW3nwaqbeTAa7n8OICCA4ByXdZDYl37mWT51HCXA/G0yx7LnXoCU0d5Fh8u9Q7I9xkeA4BybnW/Ju1cAqR2snvUimmycBbJocdagcjwBIDjziQ3ZoUbrCn1jirx+1OqK8n8TdFTNpKc4dE4L5NqdslW79SNjdE3kiDa4Lwz81v3xgqJhtJWVxu9QKt8brAkUh1uafF8VZ4k3stERPg8kBlG8fiLMix/pYAYkV7kdClydqrd4jhE02z5zvMVDAwKtPIKBoAoWZBiDu8kwD0hQvTJ9TpDmnYDAMfbbGWHAeBYzuSsK+W8UAYAjjdMIo2B147I5vCnpbNc+qn3Z1ORJoTxCgDM9fTsN7wZql4IAD0rvyLdBaCKaNI5pT2dGT91fC1LmjLUBEBpvq2Z9GsnRNIAJEP1EZcmGOqkRgCcPyz7/j1IZWx+Yd8vjOr4njZeExCicCzRGoAHvX0puWvGFWRMuHr2QsBW9pGyVgCwmGMffhFVbArdyhKwtZ+bKQCmBMaKo3U2kHjMAmAV6sZ9h8vLD9fXWgzwTvJxXfhkQHkE5TU0r5p7zZJlfY3eY03zTc/Q8ZqrBHaQfkO+HtAZoXeblutvAIAJLGuCUolrRQf5jucFXQDxxmiNQY/LKgm2Zdv26mUlmw+UCdIEkee674PBO8TA+JdNagyAUY9OPdomFW/za733rNME0eTFU4bpNQDaupHWxOByTZiySkZFPwCIJLZeFmHz+N0FpR1sCluk3M+KY6tJa2RY9XEGEF9w/XwZ2760OXxl74sLhSCi4uq6oFJrFHBG2DJVQkVvqD5eqJfQ869slG1fveHvWb5OI/JNOq4AQNMjzEH/O+8wcEHBiFGX+4i0klkzsre1TVvuAOCD+7oJx1Z1r9yaKqvqi/W2agQAJeXEbvOWWQy2JT89PcL4UCuJMHAa9YNaefjopV4hiMShHeN9iwEArbpXonFA66d+D9GgqO2j2y1LhWWWFkis96SEMNHc29vgYHEexP5b9/m6eLvO2pv/Ur373h7IAL4SxkEgSh9xpMRDInDxKhtAgq/QJMA/I0N4Fl3W6+PPh+vabYubRtFaZtkhftaojgWkC4DbijxNAKAOOtvU2GCFMu0PddGIarCD72Z3jdQ7UUGtNcZVbRmMld7TbQ/Rcyo3pyKg5R7fO+zJDWUavZyxuFSrsJYWWikAUyjwIwBUNn7wi/lHDoebOsTDYef7v3IneKkaDHw0xV4082ERq+gg2vtfyKM2AE9QgAo+uq6seHgudf+yY34hCaD+wIChxx0A5uPkOfgyAEQk7AUvVcQ6Rxv1HAAsweaF/qkfL7wm5w4F/kaEX+8QN4r3E5UA8AJdBWDBlb0EeXe3dLRok0kgERqnLSQA3Po40Vf8hulwSe1Q7YG0dGM9H2htUSr+gqvIS7dGy8/w9vuTluUh8gojHwDgcYDN1kis6ZTfcQZ8Slo1AYBdSPkWm9UJBiLSeqQZquMIWO8ayjwrDtnky40DaJx+2eSbNjU2nf2kngXAekDzWABAPgDqmVvyKTfaKYuRTCYBptLX4yQBHCFfKiiw43vwQyW7OpIHgMkFey9nmEu9DneajjZWM/iKXMpyXtXmM4wAgK/ocYcjZ9GEcFunyZIAouT9l6JDABfSbqSyHkkADfVdAYBHu3uDuSZwn0tJAUDU8FFTloJn9aUwth3XKAIAiE1xTOAuWglRHNTAidnUPZIC4PCyyxHNZV5BpKdCTk4fqeUUtFmNWQPixRoRTXB+V19Ml3c5XWIUkeeYpR1pK33MG8zNzrd0mXvp9q7JgCncFE4ySUki/amBqnTFPxsy+iXtmTlE2t0so1btjFnlS3u2ZU8EpRLf5QfKaZWZnEkVTxDNy1h/dsCjC+TneTY1bl2wPd7KrADEYHl07w2OKoq/s2PNymPX6roW6NFNCCEMz9SYWjO4w9qbd48XZJAO4DgB9PdFmQDghLQAdHEYAbQYhhBENK2m4ssmljK+6sKLyroV5BTpmqFphkfXhK9vz549CisQ/+7DAws5+Hs9O8S+666C3JMnTqRTkQQIoH/vjWYB+OkEVMyn2wB+6HG9JohIz/X3+e/+5b+9oJBIGzb/F2fdbTJU9BryA2C5ubjKVE8Un29KTknNj321CgBKrEMSTJhKz6vsqP9PAuBEQW4NAEzWAPx4v1/0eeXM7mPaLHP/1DOfLY8ps625PmG/SwJgxp1+APzW4PZ7Td7gc8IK4iiw5UKyKJ/RBYDOlMOT887fZSsrf3IFALg3uSpb1N0oMETBhaeXnTTpWENLdfA/3XRvATn+34NXAUC9ljGP/ioDQL0j2fSWG0763wAqT+3xmmSowd27AUmsdQCE/Y0Mtqo3XVcyxit0fcCnERX98N1JhXQvANQfAYBKcjKCANSfA/VzAEAnqgBA+rVd0u8MYM/gs74yAfBIjw4AI8kGEqELhBN3RXNvot41StkMQPXvL5YAAFcAUMVicZQtK8Hh9x/0fB4fGWOe72aoyO/O/78lQIZWTd+pIPss7bmV1bVEvjmLhPCd5aSF+CTRv72vMnTN+3sJYBNjPdG6WEIy2Fzwwc2Fzz0/aEyZh7To/goA9KuU6f//IYBY8yVbc6YhNmmkj+iO3hqRodNfwwwEDZqYcYHtEV5dF2cw1If2NOoVY7tyf2vi66U2Zk/8zT2bbiOqB6oiAGhB2vfoTJ6lZWfpInt0/Uvnx2ETkXd5OB75oanpgE7kG+UncbAio+N7viE5Po20Oy8oLKEcAA9pxT80vhUBvn7UG8PcdhuCLssY1nH5dlVLKJ6Zyws9MtWX/6vuhpgdB8dM2fb1zcPPrN3fqzTnE+CP7f14HBU8l58f0IhIFwAwxrYBpRDq4dMTKi8DgCfrrs5GIKuOVEXWZXBWBUdqfQcXP97ngAUlZWzpE09MvunCJW01MQYPaKd/hHrFuK5X/kDdGFc7B4BTGhPe/K6HKG92gLwpp88m4UdWyxIAa5/Ntf/IMM+Oit4WMyr1L3f//ealB5c1cpsNVnEAP3jTdkEjTVAKkIONc2JSWQBH6hh4gEgnEsehkS8FoIKEaHRKcrpsVZZS9cdcHshEYriIMgO4V88bdyS6Y+DoY3EFQCkVuu9nJ9cmgnYrIMuEE/F/yOjXFJdVdXOGaP0+S8wg6lFMBGAGpfOB/6EbDRq5vFNAPtWCCQVAMliZ9TvfGEi/d7CqPO17CY6ekvMmAOxrDm54anmZ0F9uXnHuz8c9UbDIamv8+nz9jjN1ItJHiqcY2Gnsji+hRQCIcnR3s8oJXJhTdsKaGDfIy0qGK8/yaWKiG2mJFFMQAHCXMTSuGnM8/u5X+yZMM8h7UmDIpI29xP298kl70lbgc3RyXOfz6IaqXF8fp2rmn7qjPVoJbP5M23IiACnWsNnyqNc3MX0ifhQep45D/qGbIKLlcvMgX4vc8uHHxRNittpLdeXTAufVSgA7NDHQ4dr+tocpQG1/JwAgeiRUy0gQInalLn4XjnXJhXbfrCGvz8gn3H/CDz1Nf95sAgC/9ovQTslA4sU4wFCDKwDEPWcO1waGAEDl06b01LZjbgHAQOruI/JOo2NXBwf5F86aoms/7wJCe0RrbcGVV21yVjJT9+i0dsI1DRKQ63w7nICUcwe8OV8CsEd7ZgzZwwCwi24GUPPGglPuCLItfJIHEQB8TPUVY/0kaNWiNfQzBvC2d8JPseDwrDtzNwIAKg2h962Uclsv3bfpUF8904UwXRkdp7mu5UukMW8TlOPzrilvND2TAdAwBd4vxLgIYBHzHmpy+FNw10+UX8iz/zpkoATQcFP7wxF6ceDlrnp/61WWBeBh0sKrfIWHgBgDvJhWAHjaJ3K76zfp50sgRkCUwi6NoYWREyP4wBhcEuh5ZV04wxHiWUV6ytzLUqKRPJZHGDb1UYlAEBKuc6ZRnQpu/iMRFTXMLdK8hScTkKB/pca9YWTXKGWxQExpmTL4aIdL6zNa3wGAk6HNn/dQfs9+vbWo6l0PsHIvtQj99k/5AUGbPmAG1MKiQQRYeYVpKoO0zxVbXe5EUMxTdsdbm2MekeqQ+fzenmc9dkaBoV/co7eWNYvu/UPBSYNO2+/+y23EkFtOfyr1nqlgG3OXpTg/ikttdAQQr90jtnSknwSPHlMrAXXdhR4qzmJjN23z8B6Dnk2ng5l+iEo0ercwAEh5VC/qdqzrWqDzHSc0CwAfaMKeHNnpOU6+qgUA+LOR9KfMSXoN04afP+jxQ1Zaw9EXALAh/8YEALnr7NE/TPA+8c4/O4cHvqWZwPEOhKpqFPDvMbKDQQeUuPViWzWRmYzfd2qDMFbFlYy2pSi4wevFuTlPKOZQ7qQfLteM0zstXy6hXFvxBVuya9cca/+kDzoC2EZrnXFDKEsErqpbodMVbx6xLLAbkCNAKuaI+UDe9cHoAl14imsdx4zn7k8P5M+EqAJ4li9L1Fod9N+VZAMApokogCTgS4dwAeDNnO/Xz/f2XjrilTYG2HYBTJ0aZ7lqN1QsVkhlk2POUKhYfbpqzO5l7GJAzluRDcB521rQAYDyUAhAMolu5LVSRo487OnJwEQ9NO/Wq+uiZmMKgJabULHbTQAhIn/eyQpAA1ixla6uiw8r+AKAdZqVBcB5rXrXcrZomESbHAAeoptSqrpptPZXABMozLDLf3HtIguATQBNauHWgS/JxDtED+86U6dSc49nwrOzV1cXf+KObfjjz9YkGOoRTsVRnEMA1Dx66f8tRQfZbBlCnqYDDcAQIjr/gCtvsYeLfgSvJscTUucOrpbxnRMJNt2VwFNiiJfIz1AVg4QYdl0QaOmRW5w3YNF/q5Vqm3nV8igDHK921bDLAuDXgyesjbPMVkNVP/SgS8bm5RMR0dmhVNq0+lmzYZb+W3dRoVdCrds1g8D0fqJV0wDseh4A7Bc8OQqA2vnH5rpAzrBhc47va3GPLS8BgJ36xBQp+a+t21qb4zKTB2CpJtPT20uJaPRQIVa6FK3HS0cPKjueksgfN1qyO/kITH1/NUZIABH3yGwWFcpc/bJGgV4l/4hU/mZqfVpv1W+TX/7G191205d2RnWI8yeZBKJHFml0x5y7Hv7n7+clIrnGXKt89caPzycib9mKdP+9wYO5hmJCC42syylBMom6VEZrv6g8+lix1mdNVh0wAKizHt2TYUJnFNjEqtLxlIPXEfVNhbISx8uISAhNaH9r3PB2MA1ARnVxGRQhSp/IbmvrAFyQTqnl+OddVfxwFwqZ39aGZ9bLtf9M9E1lf+u8RPlL2405bvpo8zfHEq99syYSbmkfwT2JjIZWUvXUhHtCEyXYEJYbHKoXgZJw++SRlvTPFhIZvlqGMbTLuDJogfeO0IhyX7M76PKGhqdnVu0+ms5O1jZuKCYizWZK2HSA7/pw1JmzcykgXQCmyE2ZJlLFN9/bHriUQgzowmrhRE7uuSXP9CIiMlaEsnjHbAY/29yYgTdeIIg0Ld/b8/k6Qit9bs7tP0UQtcfdQzTO/V0dtmqe3NPuP1r5BtHp2ZvTFj/y20DfqPw7EZ3Tad/shF23bXcmJtV3WvDFlbYFqF45hD8XAqhYSL5Qe5cmcjPYppRW3daWowddlqqbxx56VZCWwQSunzdWGK3xnV0blG13HgcgrfY9scetTf8e9TPNfvFFSWSGqbygPZYZJKf2qC1i27X/HVzQvzjivKjKe7vfDH4a+frWVN8Py6a3Vphq4KfZ4VVIp3D1U70vEekeza1j5VN8cnyq0/LyTfR44buDixeOus+baV2Po90A5GfvfLLsnT7bI1YiZXmy82UDh/oT5Y265A/rn+lH9GtLJvaVHW7nCbit/syTlhxkcGJqvWsQuDXrtZpbEphM4l0ijUYx8Kzo+0j3jF3zU0nc4pYbB8+ed06PG+qbWqNdsPeigNfJfP8SgNV6zSqHDEuz8ZPBhtBmxDfOb42+0G204bnMTYUAgCpp1yOFRIImA8Ap4ubeKeqx0UT1AFDx4IfB139d2by1JdLV9vLjl1gS/GPgEQV7XvmZw1wCtXcGAiWldWBlhmrLx+/5drJhTLFirSkhqEqfb9aIiPabAFrptgKHyNOzDvrqUh2syMYYq3s/zLSq0q15gOdvFcpuKnksbMm4etC5dtm8ZUB528Hf7VAqXEBEBS3P9inp7r9+x+HVE4vmMwDY7FaXf0ZERAkbQJRW9v0aAI71+fkL49MCax4OMVDbdaX4LKF1K/AX5+bkSQD4bHArAMj7c1ulrHuw4isf0UsmgKYGmz8dfO0oIuFcadx64Pvalr2RYc73FgwkMYumNPQHkDhaWjxgVfrqaQzb3GXEHJCfjzKK/QMvacVW/TQAvEcfrwDM6WsDWPnL4ZrWlDHSPmYnHAuIYc/QhD/PPTMfUCII2GTc2DQiHLWhBhiXpFWtMp2Ifae4IauaX/yjZcHd4xQAPkNcJ7nmKu/QGBDvwwDwj1J9aofiOzhGqGS1UZB3odk20Fk+3SJuOpXo5N0No3/VAnChdn77JeBkSlO2R3qeBDi68phZtdEpqlSflwjvKcdU1T5OFDwCALjN73MF100/OK2ZleS6XKea+x6iagA0HcAWKnix4jNfRNnd6KJsTV/fqWw1CgC8c1MitcRW8N9WmQBkzYCBtUoBZg79sa298CudUvzz7+aGg2cJzysAEsK4BkjVEZHXBuec/2geTevANtn1J0TBpsYtjmKJXnbVf2/YjZ9LAIjJWOWeRvV3z9XcIfDGAP/FGzi9qSlHeOfGrLWeCY3vtYEVAUAF+RT4JP201V19QpY29TKmq0nY531gs7KD/cXjSxJAcLi70son8scVnrW+Q9yNrbaGt07rsVeh1RfQNL3/ExFuKRoJMNkvrhBE4ri0hb+z3GQgyHpkhg/dG3raKLx32TeOyXlYSykLrgoUn3EdZ8tu/NmeGgnRfUv4cm/ZW5tNQLVeTHcBip4iooWNxcXHn6ETfUHX1SY0DMsTRC+kIMsio+dtbsVjQmjn/Du7t3rJ6Dvk4iGnXDJ3+qSZqYdvG0/GrSj1zq8GEBr+QEGHmC0AIJpC0A7G+Xup8At9j7vmZVf5xe9v8vb+YkMcwN8onapUtpTg8Jz+xjUSAMv3fteuHKyZfZcrRcV9VwFqXb/1eSO7AHB5+ldWGG89UUFfzVjq8Ow32ugiGzBbzDGVQO19l3cTbzsILNMM3k9E4tQKCYBj/9mO9LEKDei9zgoTaugwf7d1fLN/eGf6/F4XoLCMKF8B/zGE9zgAe9Jv4gBQNbOu75OHKySAqz1FW5VSLZX73zvP8DDsvccsVkdf7Dek3YUBnw2su58Aoo9i8k3TGNYFrU5R7PD7OZQONR/1iO63vPDaeBuAmnu25yFyK2Gg+vuKX/yXTkRU3Ki4ecH3tmq6tPhKM9ODWg9AErBWe0QlHg3pxzsSAzp8+QZr3WAizy8HH7TdQzfTS0R/ABiMsF5IN6YH9hZE9HNL2bGDcVZQNYeeG9ivi0/jCGB95p9G3LvJ1+UhzCj+s8MvkvbCqUAx3ZjaSAVge+EHjp9emvpgBcBW8s7c445lAPxyN/8piS4SUwTrCqKCgP2bCVlWB0ubkRUsUsF3SZTpAuhGXukCSDCARieEzmfToJSkmk5syknXyuDmd/5K2nbuKkVOKPWRKBgbNzK/pEgvnwEgvjrKAGoFBXkl5dV6ie50ziYzmAHTZoXW/3r10kpHaKqExxGGQwyOv1FoeE4RIc7K0KYBxEuvMLS+DQ95XHnLrDZi02bAPr6k9yKGrdPgyLffX0zkN8j/ZqqPXfXe7+a3ffbg4x6iMSNGAsCeItKPOryYwmhZeeeoP60K/doxDzIAWOWTXg2dR3z26vk33VbYL8MraOf6voNSSaX4ZM1zsZ/+YJsRKZ8gEoI8xwGA7yciyrn6lj+ohBDN2Cdsnh7QfZNGPLw3AkAVXnvbNZN6nzSubter7vWcot/vHiIi/RKy/vZObK9OnctMANhPX90crI4q1fZUjlGwDAAQyiXyt3/w5nlLAdICWrTTAHNUgMj44KlckbMKACJulWfu4vZL3uF+j3ETHFeY5tZuiv9AbjFx9jeiKjrF2/3XIx8//p+Ndc/r4m0ACJLmFYIo7/SeOpEWcSNqqJqRswYw9yiJxvdOyT27FQA/7X6dK87pWMejot+MaUQyCVBULkGz6PoeUtfrvqKimeO9BToRGXE05Dj1JUa7nezKk/W+h4wvDmxvM2Ed/LZf0YJEo7P6Xa3muflDWzKnTVv5ySSqNW98ICcv0im7JSMNIKLrz1uzdXlZNMfWNI9H5WilccovMYT4rae9ZzJJRKRfUETqyl99u9FW0eVfF1m3BnomiXp/x6MLvd8dH31ri9M7uvKTj6d9nUyPxYL/B/kf9Go/9+hLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FFF7625EE10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil(output[0][1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
